# .github/workflows/publish.yml
name: Build & Publish

on:
  release:
    types: [ published ]     # clicking "Publish Release" triggers real PyPI
  workflow_dispatch:         # manual button in the Actions tab

jobs:
  # Run full test suite before publishing
  run-tests:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: true        # Stop immediately if any test fails
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.11', '3.13']
        exclude:
          # macOS only needs one Python version for platform compatibility
          - os: macos-latest
            python-version: '3.11'
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v6

      - name: Free disk space
        uses: ./.github/actions/free-disk-space

      - uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install test deps
        shell: bash
        run: |
          python -m pip install --upgrade pip setuptools wheel
          if [ "$RUNNER_OS" == "macOS" ]; then
            # Skip all DL backends on macOS (platform compatibility check only)
            grep -v -E '^(jax|jaxlib|flax|tensorflow|torch|tabpfn|keras)' requirements-test.txt > requirements-test-macos.txt
            python -m pip install numpy -r requirements-test-macos.txt
          elif [ "$RUNNER_OS" == "Windows" ]; then
            # Skip JAX ecosystem on Windows (orbax-checkpoint pulls uvloop which is Unix-only)
            grep -v -E '^(jax|jaxlib|flax)' requirements-test.txt > requirements-test-win.txt
            python -m pip install numpy -r requirements-test-win.txt
          else
            python -m pip install numpy -r requirements-test.txt
          fi

      - name: Install package (editable, no-deps â€” deps already from requirements-test.txt)
        run: python -m pip install -e . --no-deps

      - name: Run full pytest + coverage
        shell: bash
        run: |
          MARK=()
          if [ "$RUNNER_OS" == "macOS" ]; then
            MARK=(-m "not tensorflow and not torch and not keras and not jax and not stress")
          fi

          if [ "$RUNNER_OS" == "macOS" ]; then
            # macOS: run serially (fork() is unsafe on macOS, xdist workers deadlock)
            python -m pytest -v --timeout=120 \
              "${MARK[@]}" \
              --cov=nirs4all --cov-append --cov-report=xml \
              tests/
          else
            # Serial subset with known write-contention under heavy xdist load
            python -m pytest -v \
              tests/integration/pipeline/test_merge_mixed.py \
              tests/integration/pipeline/test_merge_per_branch.py \
              --cov=nirs4all --cov-append

            # Parallel remainder
            python -m pytest -v -n auto --dist worksteal tests/ \
              --ignore=tests/integration/pipeline/test_merge_mixed.py \
              --ignore=tests/integration/pipeline/test_merge_per_branch.py \
              --cov=nirs4all --cov-append --cov-report=xml
          fi

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  # Build and verify documentation
  build-docs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Free disk space
        uses: ./.github/actions/free-disk-space

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install documentation dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          python -m pip install -r docs/readthedocs.requirements.txt

      - name: Install nirs4all package
        run: python -m pip install -e .

      - name: Build documentation
        run: |
          cd docs
          sphinx-build -b html source _build/html --keep-going

      - name: Upload documentation artifacts
        uses: actions/upload-artifact@v7
        with:
          name: documentation-html
          path: docs/_build/html/
          retention-days: 7

  # Build distribution packages (after tests pass)
  build:
    needs: [run-tests, build-docs]
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v6

      - name: Free disk space
        uses: ./.github/actions/free-disk-space

      - uses: actions/setup-python@v6
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Verify version consistency
        if: github.event_name == 'release'
        shell: bash
        run: |
          PYPROJECT_VERSION=$(python -c "
          import tomllib
          with open('pyproject.toml', 'rb') as f:
              print(tomllib.load(f)['project']['version'])
          ")
          TAG_VERSION="${{ github.event.release.tag_name }}"
          TAG_VERSION="${TAG_VERSION#v}"
          if [[ "$PYPROJECT_VERSION" != "$TAG_VERSION" ]]; then
            echo "::error::Version mismatch: pyproject.toml=$PYPROJECT_VERSION tag=$TAG_VERSION"
            exit 1
          fi
          echo "Version verified: $PYPROJECT_VERSION"

      - name: Build dists
        run: |
          python -m pip install --upgrade build
          python -m build --sdist --wheel --outdir dist

      - uses: actions/upload-artifact@v7
        with:
          name: dist
          path: dist

  # Publish to PyPI (only after build succeeds, which requires tests + docs)
  publish-pypi:
    needs: build
    runs-on: ubuntu-latest
    environment: pypi
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: actions/download-artifact@v6
        with:
          name: dist
          path: dist

      - name: Upload to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1

  # Build and push Docker image to GHCR (runs in parallel with build/publish-pypi)
  publish-docker:
    needs: [run-tests]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v6

      - uses: docker/setup-buildx-action@v3

      - uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract version tag
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}
          tags: |
            type=semver,pattern={{version}}
            type=raw,value=latest

      - uses: docker/build-push-action@v6
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Notify about conda-forge feedstock update (after PyPI publish)
  notify-conda-forge:
    needs: publish-pypi
    runs-on: ubuntu-latest
    if: github.event_name == 'release'
    steps:
      - uses: actions/checkout@v6

      - uses: actions/setup-python@v6
        with:
          python-version: '3.12'

      - name: Fetch SHA256 and generate conda-forge update instructions
        shell: bash
        run: |
          VERSION="${{ github.event.release.tag_name }}"
          VERSION="${VERSION#v}"

          # Wait for PyPI to index the new version (up to 5 minutes)
          SHA256=""
          for i in $(seq 1 10); do
            SHA256=$(curl -sL "https://pypi.org/pypi/nirs4all/$VERSION/json" | \
              python3 -c "import sys,json; d=json.load(sys.stdin); \
              print([u['digests']['sha256'] for u in d['urls'] if u['filename'].endswith('.tar.gz')][0])" 2>/dev/null) && break
            echo "Waiting for PyPI to index version $VERSION (attempt $i/10)..."
            sleep 30
          done

          echo "## Conda-forge Update" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [[ -z "$SHA256" ]]; then
            echo "::warning::Could not fetch SHA256 from PyPI for version $VERSION"
            echo "Could not fetch SHA256 automatically. Update manually:" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
            echo "python scripts/sync_conda_recipe.py --sha $VERSION" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "The regro-cf-autotick-bot should automatically create a PR to the feedstock." >> $GITHUB_STEP_SUMMARY
            echo "If it doesn't within 24h, manually update:" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "- **Version**: \`$VERSION\`" >> $GITHUB_STEP_SUMMARY
            echo "- **SHA256**: \`$SHA256\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Or run:" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
            echo "python scripts/sync_conda_recipe.py --sha $VERSION" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

            # Also update meta.yaml in the repo for reference
            python scripts/sync_conda_recipe.py --sha "$VERSION" || true
          fi
