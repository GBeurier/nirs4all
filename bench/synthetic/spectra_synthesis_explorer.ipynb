{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectra Synthesis Explorer\n",
    "\n",
    "Interactive notebook for testing, evaluating, and exploring NIRS spectra synthesis.\n",
    "\n",
    "**Features:**\n",
    "1. Load and display real datasets (nirs4all compatible)\n",
    "2. Configure synthesis with all parameters inline\n",
    "3. Optimize parameters to match real spectra\n",
    "4. Analyze spectral properties (median, high-frequency, scatter, drift)\n",
    "5. Compute similarity metrics and train discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nirs4all loaded from: None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add nirs4all to path\n",
    "delete_root = Path.cwd().parent.parent.parent\n",
    "if str(delete_root) not in sys.path:\n",
    "    sys.path.insert(0, str(delete_root))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For comparison tools (from bench)\n",
    "from comparator import SyntheticRealComparator, compute_spectral_properties\n",
    "from scipy import signal, stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from visualizer import SyntheticSpectraVisualizer\n",
    "\n",
    "import nirs4all\n",
    "from nirs4all.data import DatasetConfigs, SpectroDataset\n",
    "from nirs4all.data.synthetic import ComponentLibrary, NIRBand, SpectralComponent, SyntheticNIRSGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(f\"nirs4all loaded from: {nirs4all.__file__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load Real Dataset\n",
    "\n",
    "Load a real NIRS dataset for comparison. Supports:\n",
    "- nirs4all DatasetConfigs folders (with spectra.csv)\n",
    "- Direct CSV/parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nm\n",
      "Dataset: x_bank_Beef_Marbling_RandomSplit\n",
      "Shape: (833, 331) (samples x wavelengths)\n",
      "Wavelength range: 740.0 - 1070.0 nm\n",
      "Absorbance range: [0.1327, 1070.0000]\n",
      "Mean: 1.5853 +/- 31.4950\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURE: Path to your real dataset\n",
    "# ============================================================================\n",
    "DATASET_PATH = delete_root / \"NIRS DB\" / \"x_bank\"  # Change this to your dataset\n",
    "DATASET_NAME = \"Beef_Marbling_RandomSplit\"\n",
    "\n",
    "# Load dataset using nirs4all\n",
    "def load_real_dataset(path: Path, name: str):\n",
    "    \"\"\"Load real dataset from path using nirs4all DatasetConfigs.\"\"\"\n",
    "    path = Path(path)\n",
    "    csv_path = path / (name + \".csv\")\n",
    "\n",
    "    config = {\n",
    "        \"x_train\": str(csv_path),\n",
    "        \"delimiter\": \",\",\n",
    "        \"has_header\": True,\n",
    "        \"header_unit\": \"nm\",\n",
    "    }\n",
    "\n",
    "    # Use DatasetConfigs (now supports root-level params)\n",
    "    configs = DatasetConfigs(config)\n",
    "    dataset = configs.get_datasets()[0]\n",
    "    X = dataset.x({}, layout='2d')\n",
    "    print(dataset.header_unit(0))  # Example usage of new method\n",
    "    wavelengths = dataset.wavelengths_nm(0)  # Method call with source index\n",
    "    if wavelengths is None:\n",
    "        wavelengths = np.arange(X.shape[1])\n",
    "    return X, wavelengths, dataset.name\n",
    "\n",
    "# Load the dataset\n",
    "X_real, wavelengths_real, dataset_name = load_real_dataset(DATASET_PATH, DATASET_NAME)\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Shape: {X_real.shape} (samples x wavelengths)\")\n",
    "print(f\"Wavelength range: {wavelengths_real.min():.1f} - {wavelengths_real.max():.1f} nm\")\n",
    "print(f\"Absorbance range: [{X_real.min():.4f}, {X_real.max():.4f}]\")\n",
    "print(f\"Mean: {X_real.mean():.4f} +/- {X_real.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize real dataset\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Sample spectra\n",
    "n_display = min(100, X_real.shape[0])\n",
    "sample_idx = np.random.choice(X_real.shape[0], n_display, replace=False)\n",
    "for idx in sample_idx:\n",
    "    axes[0].plot(wavelengths_real, X_real[idx], alpha=0.3, linewidth=0.5)\n",
    "axes[0].set_xlabel('Wavelength (nm)')\n",
    "axes[0].set_ylabel('Absorbance')\n",
    "axes[0].set_title(f'Real Spectra (n={n_display})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Mean and envelope\n",
    "mean_spec = X_real.mean(axis=0)\n",
    "std_spec = X_real.std(axis=0)\n",
    "axes[1].fill_between(wavelengths_real, mean_spec - 2*std_spec, mean_spec + 2*std_spec, alpha=0.3, label='Mean +/- 2*std')\n",
    "axes[1].plot(wavelengths_real, mean_spec, 'b-', linewidth=2, label='Mean')\n",
    "axes[1].plot(wavelengths_real, np.median(X_real, axis=0), 'r--', linewidth=1.5, label='Median')\n",
    "axes[1].set_xlabel('Wavelength (nm)')\n",
    "axes[1].set_ylabel('Absorbance')\n",
    "axes[1].set_title('Spectral Envelope')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Absorbance distribution\n",
    "axes[2].hist(X_real.flatten(), bins=1000, density=True, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "axes[2].set_xlabel('Absorbance')\n",
    "axes[2].set_ylabel('Density')\n",
    "axes[2].set_title('Absorbance Distribution')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Real Dataset: {dataset_name}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Analyze Real Spectra Properties\n",
    "\n",
    "Extract key spectral properties to guide synthesis parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_spectral_properties(X, wavelengths, name=\"dataset\"):\n",
    "    \"\"\"Comprehensive analysis of spectral properties.\"\"\"\n",
    "    n_samples, n_wavelengths = X.shape\n",
    "    wl_range = np.ptp(wavelengths)\n",
    "\n",
    "    # Basic statistics\n",
    "    mean_spectrum = X.mean(axis=0)\n",
    "    median_spectrum = np.median(X, axis=0)\n",
    "    std_spectrum = X.std(axis=0)\n",
    "\n",
    "    # Global slope analysis (per 1000nm)\n",
    "    x_norm = (wavelengths - wavelengths.min()) / wl_range\n",
    "    slopes = []\n",
    "    for i in range(n_samples):\n",
    "        coeffs = np.polyfit(x_norm, X[i], 1)\n",
    "        slopes.append(coeffs[0] * 5.0 / wl_range)\n",
    "    slopes = np.array(slopes)\n",
    "\n",
    "    # High-frequency noise analysis (first difference)\n",
    "    first_diff = np.diff(X, axis=1)\n",
    "    noise_estimate = first_diff.std() / np.sqrt(2)\n",
    "    noise_per_wavelength = first_diff.std(axis=0) / np.sqrt(2)\n",
    "\n",
    "    # Curvature analysis (second derivative)\n",
    "    curvatures = []\n",
    "    for i in range(min(100, n_samples)):\n",
    "        window = min(21, n_wavelengths // 10 * 2 + 1)\n",
    "        if window >= 3:\n",
    "            smoothed = signal.savgol_filter(X[i], window, 2)\n",
    "            d2 = np.gradient(np.gradient(smoothed))\n",
    "            curvatures.append(np.mean(np.abs(d2)))\n",
    "    mean_curvature = np.mean(curvatures) if curvatures else 0\n",
    "\n",
    "    # PCA analysis\n",
    "    pca = PCA(n_components=min(20, n_samples, n_wavelengths))\n",
    "    pca.fit(X)\n",
    "    cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components_95 = int(np.searchsorted(cumvar, 0.95) + 1)\n",
    "\n",
    "    # Distribution statistics\n",
    "    skewness = stats.skew(X.flatten())\n",
    "    kurtosis = stats.kurtosis(X.flatten())\n",
    "\n",
    "    # SNR estimate\n",
    "    snr = std_spectrum.mean() / (noise_estimate + 1e-10)\n",
    "\n",
    "    props = {\n",
    "        'name': name,\n",
    "        'n_samples': n_samples,\n",
    "        'n_wavelengths': n_wavelengths,\n",
    "        'wavelength_range': (wavelengths.min(), wavelengths.max()),\n",
    "        'global_mean': X.mean(),\n",
    "        'global_std': X.std(),\n",
    "        'absorbance_range': (X.min(), X.max()),\n",
    "        'mean_slope': slopes.mean(),\n",
    "        'slope_std': slopes.std(),\n",
    "        'noise_estimate': noise_estimate,\n",
    "        'snr': snr,\n",
    "        'mean_curvature': mean_curvature,\n",
    "        'pca_n_components_95': n_components_95,\n",
    "        'skewness': skewness,\n",
    "        'kurtosis': kurtosis,\n",
    "        'mean_spectrum': mean_spectrum,\n",
    "        'median_spectrum': median_spectrum,\n",
    "        'std_spectrum': std_spectrum,\n",
    "        'noise_per_wavelength': noise_per_wavelength,\n",
    "        'slopes': slopes,\n",
    "        'pca_variance': pca.explained_variance_ratio_,\n",
    "        'pca_loadings': pca.components_[:3],\n",
    "    }\n",
    "\n",
    "    return props\n",
    "\n",
    "# Analyze real data\n",
    "real_props = analyze_spectral_properties(X_real, wavelengths_real, dataset_name)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"SPECTRAL PROPERTIES: {real_props['name']}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Samples: {real_props['n_samples']}, Wavelengths: {real_props['n_wavelengths']}\")\n",
    "print(f\"Wavelength range: {real_props['wavelength_range'][0]:.1f} - {real_props['wavelength_range'][1]:.1f} nm\")\n",
    "print(\"\")\n",
    "print(f\"Global mean: {real_props['global_mean']:.4f}\")\n",
    "print(f\"Global std: {real_props['global_std']:.4f}\")\n",
    "print(f\"Absorbance range: [{real_props['absorbance_range'][0]:.4f}, {real_props['absorbance_range'][1]:.4f}]\")\n",
    "print(\"\")\n",
    "print(f\"Mean slope: {real_props['mean_slope']:.4f} per 1000nm\")\n",
    "print(f\"Slope std: {real_props['slope_std']:.4f}\")\n",
    "print(\"\")\n",
    "print(f\"Noise estimate (1st diff): {real_props['noise_estimate']:.5f}\")\n",
    "print(f\"SNR: {real_props['snr']:.1f}\")\n",
    "print(f\"Mean curvature: {real_props['mean_curvature']:.6f}\")\n",
    "print(\"\")\n",
    "print(f\"PCA components for 95%: {real_props['pca_n_components_95']}\")\n",
    "print(f\"Skewness: {real_props['skewness']:.3f}\")\n",
    "print(f\"Kurtosis: {real_props['kurtosis']:.3f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Synthesis Configuration\n",
    "\n",
    "Configure all synthesis parameters inline. Adjust these to match your real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SYNTHESIS PARAMETERS - All configurable in one place\n",
    "# ============================================================================\n",
    "\n",
    "def generate_synthetic_spectra(\n",
    "    # === Sample configuration ===\n",
    "    n_samples: int = real_props['n_samples'],\n",
    "    random_state: int = 42,\n",
    "\n",
    "    # === Wavelength grid ===\n",
    "    wavelength_start: float = real_props['wavelength_range'][0],  # Start wavelength in nm\n",
    "    wavelength_end: float = real_props['wavelength_range'][1],    # End wavelength in nm\n",
    "    wavelength_step: float = 2.0,      # Wavelength resolution in nm\n",
    "\n",
    "    # === Component configuration ===\n",
    "    components: list = None,  # Predefined components\n",
    "    concentration_method: str = \"dirichlet\",  # 'dirichlet', 'uniform', 'lognormal', 'correlated'\n",
    "    dirichlet_alpha: float = 2.0,  # Concentration distribution shape (higher = more uniform)\n",
    "\n",
    "    # === Path length variation ===\n",
    "    path_length_std: float = 0.05,  # Std of optical path length factor (multiplicative)\n",
    "\n",
    "    # === Baseline effects ===\n",
    "    baseline_amplitude: float = 0.02,  # Polynomial baseline drift amplitude\n",
    "\n",
    "    # === Global slope (common in NIR) ===\n",
    "    global_slope_mean: float = 0.05,   # Mean slope per 1000nm (typical upward trend)\n",
    "    global_slope_std: float = 0.03,    # Variation in slope between samples\n",
    "\n",
    "    # === Scatter effects (SNV/MSC-like before correction) ===\n",
    "    scatter_alpha_std: float = 0.05,   # Multiplicative scatter variation\n",
    "    scatter_beta_std: float = 0.01,    # Additive scatter offset\n",
    "    tilt_std: float = 0.01,            # Wavelength-dependent tilt\n",
    "\n",
    "    # === Wavelength calibration ===\n",
    "    shift_std: float = 0.5,            # Wavelength shift in nm\n",
    "    stretch_std: float = 0.001,        # Wavelength stretch factor\n",
    "\n",
    "    # === Instrumental effects ===\n",
    "    instrumental_fwhm: float = 8.0,    # Spectral resolution broadening (FWHM in nm)\n",
    "\n",
    "    # === Noise model ===\n",
    "    noise_base: float = 0.005,         # Base noise level (constant)\n",
    "    noise_signal_dep: float = 0.01,    # Signal-dependent noise (heteroscedastic)\n",
    "\n",
    "    # === Artifacts ===\n",
    "    artifact_prob: float = 0.02,       # Probability of spike/dead band artifacts\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic NIRS spectra with full parameter control.\n",
    "\n",
    "    Returns:\n",
    "        X: Spectra array (n_samples, n_wavelengths)\n",
    "        wavelengths: Wavelength grid\n",
    "        metadata: Generation parameters and additional info\n",
    "    \"\"\"\n",
    "    # Build component library\n",
    "    if components is None:\n",
    "        components = [\"water\", \"protein\", \"lipid\", \"starch\", \"cellulose\"]\n",
    "    library = ComponentLibrary.from_predefined(components, random_state=random_state)\n",
    "\n",
    "    # Create generator with custom parameters\n",
    "    generator = SyntheticNIRSGenerator(\n",
    "        wavelength_start=wavelength_start,\n",
    "        wavelength_end=wavelength_end,\n",
    "        wavelength_step=wavelength_step,\n",
    "        component_library=library,\n",
    "        complexity=\"realistic\",  # Base complexity (will override params)\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # Override parameters with our settings\n",
    "    generator.params.update({\n",
    "        \"path_length_std\": path_length_std,\n",
    "        \"baseline_amplitude\": baseline_amplitude,\n",
    "        \"scatter_alpha_std\": scatter_alpha_std,\n",
    "        \"scatter_beta_std\": scatter_beta_std,\n",
    "        \"tilt_std\": tilt_std,\n",
    "        \"global_slope_mean\": global_slope_mean,\n",
    "        \"global_slope_std\": global_slope_std,\n",
    "        \"shift_std\": shift_std,\n",
    "        \"stretch_std\": stretch_std,\n",
    "        \"instrumental_fwhm\": instrumental_fwhm,\n",
    "        \"noise_base\": noise_base,\n",
    "        \"noise_signal_dep\": noise_signal_dep,\n",
    "        \"artifact_prob\": artifact_prob,\n",
    "    })\n",
    "\n",
    "    # Generate spectra\n",
    "    alpha = np.ones(len(components)) * dirichlet_alpha\n",
    "    X, Y, E, metadata = generator.generate(\n",
    "        n_samples=n_samples,\n",
    "        concentration_method=concentration_method,\n",
    "        return_metadata=True,\n",
    "    )\n",
    "\n",
    "    # Store parameters in metadata\n",
    "    metadata['params'] = generator.params.copy()\n",
    "    metadata['concentrations'] = Y\n",
    "    metadata['component_spectra'] = E\n",
    "\n",
    "    return X, generator.wavelengths, metadata\n",
    "\n",
    "print(\"Synthesis function defined. Ready to generate spectra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GENERATE SYNTHETIC SPECTRA - Adjust parameters here to match real data\n",
    "# ============================================================================\n",
    "\n",
    "# Use real data properties to set initial parameters\n",
    "wl_start, wl_end = real_props['wavelength_range']\n",
    "wl_step = (wl_end - wl_start) / (real_props['n_wavelengths'] - 1)\n",
    "\n",
    "X_synth, wavelengths_synth, synth_metadata = generate_synthetic_spectra(\n",
    "    # Match real data grid\n",
    "    n_samples=500,\n",
    "    random_state=42,\n",
    "    wavelength_start=wl_start,\n",
    "    wavelength_end=wl_end,\n",
    "    wavelength_step=wl_step,\n",
    "\n",
    "    # Component settings\n",
    "    components=[\"water\", \"protein\", \"lipid\", \"starch\", \"cellulose\"],\n",
    "    concentration_method=\"dirichlet\",\n",
    "    dirichlet_alpha=2.0,\n",
    "\n",
    "    # --- TUNE THESE TO MATCH REAL DATA ---\n",
    "    # Start from real data properties and adjust\n",
    "    path_length_std=0.05,\n",
    "    baseline_amplitude=0.02,\n",
    "\n",
    "    # Global slope (from real data analysis)\n",
    "    global_slope_mean=real_props['mean_slope'],  # Use measured slope\n",
    "    global_slope_std=real_props['slope_std'],\n",
    "\n",
    "    # Scatter effects\n",
    "    scatter_alpha_std=0.05,\n",
    "    scatter_beta_std=0.01,\n",
    "    tilt_std=0.01,\n",
    "\n",
    "    # Wavelength calibration\n",
    "    shift_std=0.5,\n",
    "    stretch_std=0.001,\n",
    "\n",
    "    # Instrumental\n",
    "    instrumental_fwhm=8.0,\n",
    "\n",
    "    # Noise (from real data analysis)\n",
    "    noise_base=real_props['noise_estimate'] * 0.5,  # Base noise\n",
    "    noise_signal_dep=real_props['noise_estimate'] * 0.5,  # Signal-dependent\n",
    "\n",
    "    artifact_prob=0.02,\n",
    ")\n",
    "\n",
    "print(f\"Generated {X_synth.shape[0]} synthetic spectra\")\n",
    "print(f\"Shape: {X_synth.shape}\")\n",
    "print(f\"Wavelength range: {wavelengths_synth.min():.1f} - {wavelengths_synth.max():.1f} nm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize synthetic spectra\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Sample spectra\n",
    "n_display = min(100, X_synth.shape[0])\n",
    "sample_idx = np.random.choice(X_synth.shape[0], n_display, replace=False)\n",
    "for idx in sample_idx:\n",
    "    axes[0].plot(wavelengths_synth, X_synth[idx], alpha=0.3, linewidth=0.5, color='orange')\n",
    "axes[0].set_xlabel('Wavelength (nm)')\n",
    "axes[0].set_ylabel('Absorbance')\n",
    "axes[0].set_title(f'Synthetic Spectra (n={n_display})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Mean and envelope\n",
    "mean_synth = X_synth.mean(axis=0)\n",
    "std_synth = X_synth.std(axis=0)\n",
    "axes[1].fill_between(wavelengths_synth, mean_synth - 2*std_synth, mean_synth + 2*std_synth, alpha=0.3, color='orange')\n",
    "axes[1].plot(wavelengths_synth, mean_synth, color='darkorange', linewidth=2, label='Mean')\n",
    "axes[1].plot(wavelengths_synth, np.median(X_synth, axis=0), 'r--', linewidth=1.5, label='Median')\n",
    "axes[1].set_xlabel('Wavelength (nm)')\n",
    "axes[1].set_ylabel('Absorbance')\n",
    "axes[1].set_title('Spectral Envelope')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Component library\n",
    "E = synth_metadata['component_spectra']\n",
    "for i, (name, spectrum) in enumerate(zip(synth_metadata['component_names'], E, strict=False)):\n",
    "    norm_spec = (spectrum - spectrum.min()) / (spectrum.max() - spectrum.min() + 1e-10)\n",
    "    axes[2].plot(wavelengths_synth, norm_spec + i * 1.2, linewidth=1.5, label=name)\n",
    "axes[2].set_xlabel('Wavelength (nm)')\n",
    "axes[2].set_ylabel('Normalized Absorbance (stacked)')\n",
    "axes[2].set_title('Component Library')\n",
    "axes[2].legend(loc='upper right')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Synthetic Data', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Compare Synthetic vs Real\n",
    "\n",
    "Side-by-side comparison of spectral properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze synthetic data\n",
    "synth_props = analyze_spectral_properties(X_synth, wavelengths_synth, \"synthetic\")\n",
    "\n",
    "# Print comparison table\n",
    "print(\"=\" * 70)\n",
    "print(\"PROPERTY COMPARISON: Real vs Synthetic\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Property':<25} {'Real':>15} {'Synthetic':>15} {'Diff %':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "def fmt_diff(real_val, synth_val):\n",
    "    if abs(real_val) > 1e-10:\n",
    "        diff_pct = (synth_val - real_val) / abs(real_val) * 100\n",
    "        return f\"{diff_pct:+.1f}%\"\n",
    "    return \"N/A\"\n",
    "\n",
    "comparisons = [\n",
    "    ('Global mean', real_props['global_mean'], synth_props['global_mean']),\n",
    "    ('Global std', real_props['global_std'], synth_props['global_std']),\n",
    "    ('Mean slope', real_props['mean_slope'], synth_props['mean_slope']),\n",
    "    ('Slope std', real_props['slope_std'], synth_props['slope_std']),\n",
    "    ('Noise estimate', real_props['noise_estimate'], synth_props['noise_estimate']),\n",
    "    ('SNR', real_props['snr'], synth_props['snr']),\n",
    "    ('Mean curvature', real_props['mean_curvature'], synth_props['mean_curvature']),\n",
    "    ('PCA 95% components', real_props['pca_n_components_95'], synth_props['pca_n_components_95']),\n",
    "    ('Skewness', real_props['skewness'], synth_props['skewness']),\n",
    "    ('Kurtosis', real_props['kurtosis'], synth_props['kurtosis']),\n",
    "]\n",
    "\n",
    "for name, real_val, synth_val in comparisons:\n",
    "    diff = fmt_diff(real_val, synth_val)\n",
    "    print(f\"{name:<25} {real_val:>15.5f} {synth_val:>15.5f} {diff:>12}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# 1. Mean spectra overlay\n",
    "axes[0, 0].plot(wavelengths_real, real_props['mean_spectrum'], 'b-', linewidth=2, label='Real')\n",
    "axes[0, 0].plot(wavelengths_synth, synth_props['mean_spectrum'], 'orange', linestyle='--', linewidth=2, label='Synthetic')\n",
    "axes[0, 0].fill_between(wavelengths_real,\n",
    "                         real_props['mean_spectrum'] - real_props['std_spectrum'],\n",
    "                         real_props['mean_spectrum'] + real_props['std_spectrum'],\n",
    "                         alpha=0.2, color='blue')\n",
    "axes[0, 0].fill_between(wavelengths_synth,\n",
    "                         synth_props['mean_spectrum'] - synth_props['std_spectrum'],\n",
    "                         synth_props['mean_spectrum'] + synth_props['std_spectrum'],\n",
    "                         alpha=0.2, color='orange')\n",
    "axes[0, 0].set_xlabel('Wavelength (nm)')\n",
    "axes[0, 0].set_ylabel('Absorbance')\n",
    "axes[0, 0].set_title('Mean Spectra +/- Std')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Slope distributions\n",
    "axes[0, 1].hist(real_props['slopes'], bins=30, alpha=0.6, color='blue', label='Real', density=True)\n",
    "axes[0, 1].hist(synth_props['slopes'], bins=30, alpha=0.6, color='orange', label='Synthetic', density=True)\n",
    "axes[0, 1].set_xlabel('Slope (per 1000nm)')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].set_title('Slope Distributions')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Noise comparison\n",
    "# Interpolate if wavelengths differ\n",
    "if len(wavelengths_real) != len(wavelengths_synth) or not np.allclose(wavelengths_real, wavelengths_synth):\n",
    "    noise_synth_interp = np.interp(wavelengths_real[:-1], wavelengths_synth[:-1], synth_props['noise_per_wavelength'])\n",
    "else:\n",
    "    noise_synth_interp = synth_props['noise_per_wavelength']\n",
    "\n",
    "axes[0, 2].plot(wavelengths_real[:-1], real_props['noise_per_wavelength'], 'b-', linewidth=1, label='Real', alpha=0.7)\n",
    "axes[0, 2].plot(wavelengths_real[:-1], noise_synth_interp, 'orange', linewidth=1, label='Synthetic', alpha=0.7)\n",
    "axes[0, 2].axhline(real_props['noise_estimate'], color='blue', linestyle='--', alpha=0.5)\n",
    "axes[0, 2].axhline(synth_props['noise_estimate'], color='orange', linestyle='--', alpha=0.5)\n",
    "axes[0, 2].set_xlabel('Wavelength (nm)')\n",
    "axes[0, 2].set_ylabel('Noise (std)')\n",
    "axes[0, 2].set_title('Wavelength-dependent Noise')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. PCA comparison\n",
    "axes[1, 0].plot(range(1, len(real_props['pca_variance']) + 1),\n",
    "                np.cumsum(real_props['pca_variance']) * 100, 'bo-', linewidth=2, label='Real')\n",
    "axes[1, 0].plot(range(1, len(synth_props['pca_variance']) + 1),\n",
    "                np.cumsum(synth_props['pca_variance']) * 100, 'o-', color='orange', linewidth=2, label='Synthetic')\n",
    "axes[1, 0].axhline(95, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Principal Component')\n",
    "axes[1, 0].set_ylabel('Cumulative Variance (%)')\n",
    "axes[1, 0].set_title('PCA Cumulative Variance')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Std per wavelength\n",
    "std_synth_interp = np.interp(wavelengths_real, wavelengths_synth, synth_props['std_spectrum']) if len(wavelengths_real) != len(wavelengths_synth) else synth_props['std_spectrum']\n",
    "\n",
    "axes[1, 1].plot(wavelengths_real, real_props['std_spectrum'], 'b-', linewidth=1.5, label='Real')\n",
    "axes[1, 1].plot(wavelengths_real, std_synth_interp, color='orange', linewidth=1.5, label='Synthetic')\n",
    "axes[1, 1].set_xlabel('Wavelength (nm)')\n",
    "axes[1, 1].set_ylabel('Standard Deviation')\n",
    "axes[1, 1].set_title('Sample Variation per Wavelength')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Absorbance distributions\n",
    "axes[1, 2].hist(X_real.flatten(), bins=100, density=True, alpha=0.6, color='blue', label='Real')\n",
    "axes[1, 2].hist(X_synth.flatten(), bins=100, density=True, alpha=0.6, color='orange', label='Synthetic')\n",
    "axes[1, 2].set_xlabel('Absorbance')\n",
    "axes[1, 2].set_ylabel('Density')\n",
    "axes[1, 2].set_title('Absorbance Distributions')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Real vs Synthetic Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Compute Similarity Metrics\n",
    "\n",
    "Quantitative assessment of how well synthetic matches real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_metrics(X_real, X_synth, wavelengths_real, wavelengths_synth):\n",
    "    \"\"\"\n",
    "    Compute comprehensive similarity metrics between real and synthetic spectra.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Interpolate if wavelengths differ\n",
    "    if len(wavelengths_real) != len(wavelengths_synth) or not np.allclose(wavelengths_real, wavelengths_synth):\n",
    "        X_synth_interp = np.array([np.interp(wavelengths_real, wavelengths_synth, spec) for spec in X_synth])\n",
    "    else:\n",
    "        X_synth_interp = X_synth\n",
    "\n",
    "    # 1. Mean spectrum correlation\n",
    "    mean_real = X_real.mean(axis=0)\n",
    "    mean_synth = X_synth_interp.mean(axis=0)\n",
    "    metrics['mean_spectrum_correlation'] = np.corrcoef(mean_real, mean_synth)[0, 1]\n",
    "\n",
    "    # 2. Mean spectrum RMSE\n",
    "    metrics['mean_spectrum_rmse'] = np.sqrt(np.mean((mean_real - mean_synth) ** 2))\n",
    "\n",
    "    # 3. Std spectrum correlation\n",
    "    std_real = X_real.std(axis=0)\n",
    "    std_synth = X_synth_interp.std(axis=0)\n",
    "    metrics['std_spectrum_correlation'] = np.corrcoef(std_real, std_synth)[0, 1]\n",
    "\n",
    "    # 4. Global statistics comparison\n",
    "    metrics['mean_diff_pct'] = (X_synth.mean() - X_real.mean()) / (abs(X_real.mean()) + 1e-10) * 100\n",
    "    metrics['std_diff_pct'] = (X_synth.std() - X_real.std()) / (X_real.std() + 1e-10) * 100\n",
    "\n",
    "    # 5. Slope distribution similarity (KS test)\n",
    "    slopes_real = []\n",
    "    slopes_synth = []\n",
    "    wl_range_real = np.ptp(wavelengths_real)\n",
    "    x_norm_real = (wavelengths_real - wavelengths_real.min()) / wl_range_real\n",
    "\n",
    "    for spec in X_real:\n",
    "        coeffs = np.polyfit(x_norm_real, spec, 1)\n",
    "        slopes_real.append(coeffs[0] * 1000.0 / wl_range_real)\n",
    "\n",
    "    for spec in X_synth_interp:\n",
    "        coeffs = np.polyfit(x_norm_real, spec, 1)\n",
    "        slopes_synth.append(coeffs[0] * 1000.0 / wl_range_real)\n",
    "\n",
    "    ks_stat, ks_pval = stats.ks_2samp(slopes_real, slopes_synth)\n",
    "    metrics['slope_ks_statistic'] = ks_stat\n",
    "    metrics['slope_ks_pvalue'] = ks_pval\n",
    "\n",
    "    # 6. Noise comparison\n",
    "    noise_real = np.diff(X_real, axis=1).std() / np.sqrt(2)\n",
    "    noise_synth = np.diff(X_synth_interp, axis=1).std() / np.sqrt(2)\n",
    "    metrics['noise_ratio'] = noise_synth / (noise_real + 1e-10)\n",
    "\n",
    "    # 7. PCA structure comparison\n",
    "    pca_real = PCA(n_components=min(10, X_real.shape[0], X_real.shape[1]))\n",
    "    pca_synth = PCA(n_components=min(10, X_synth_interp.shape[0], X_synth_interp.shape[1]))\n",
    "    pca_real.fit(X_real)\n",
    "    pca_synth.fit(X_synth_interp)\n",
    "\n",
    "    n_common = min(len(pca_real.explained_variance_ratio_), len(pca_synth.explained_variance_ratio_))\n",
    "    metrics['pca_variance_correlation'] = np.corrcoef(\n",
    "        pca_real.explained_variance_ratio_[:n_common],\n",
    "        pca_synth.explained_variance_ratio_[:n_common]\n",
    "    )[0, 1]\n",
    "\n",
    "    # 8. Absorbance distribution similarity (Wasserstein distance)\n",
    "    metrics['wasserstein_distance'] = stats.wasserstein_distance(\n",
    "        X_real.flatten()[:10000],  # Sample to limit computation\n",
    "        X_synth_interp.flatten()[:10000]\n",
    "    )\n",
    "\n",
    "    # 9. Overall similarity score (0-100)\n",
    "    scores = [\n",
    "        metrics['mean_spectrum_correlation'] * 100,\n",
    "        metrics['std_spectrum_correlation'] * 100,\n",
    "        max(0, 100 - abs(metrics['mean_diff_pct'])),\n",
    "        max(0, 100 - abs(metrics['std_diff_pct'])),\n",
    "        max(0, 100 - abs(1 - metrics['noise_ratio']) * 100),\n",
    "        metrics['pca_variance_correlation'] * 100 if not np.isnan(metrics['pca_variance_correlation']) else 50,\n",
    "    ]\n",
    "    metrics['overall_similarity_score'] = np.mean(scores)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Compute metrics\n",
    "similarity_metrics = compute_similarity_metrics(X_real, X_synth, wavelengths_real, wavelengths_synth)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SIMILARITY METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean spectrum correlation:    {similarity_metrics['mean_spectrum_correlation']:.4f}\")\n",
    "print(f\"Mean spectrum RMSE:           {similarity_metrics['mean_spectrum_rmse']:.5f}\")\n",
    "print(f\"Std spectrum correlation:     {similarity_metrics['std_spectrum_correlation']:.4f}\")\n",
    "print(\"\")\n",
    "print(f\"Global mean difference:       {similarity_metrics['mean_diff_pct']:+.2f}%\")\n",
    "print(f\"Global std difference:        {similarity_metrics['std_diff_pct']:+.2f}%\")\n",
    "print(\"\")\n",
    "print(f\"Slope KS statistic:           {similarity_metrics['slope_ks_statistic']:.4f}\")\n",
    "print(f\"Slope KS p-value:             {similarity_metrics['slope_ks_pvalue']:.4f}\")\n",
    "print(\"\")\n",
    "print(f\"Noise ratio (synth/real):     {similarity_metrics['noise_ratio']:.3f}\")\n",
    "print(f\"PCA variance correlation:     {similarity_metrics['pca_variance_correlation']:.4f}\")\n",
    "print(f\"Wasserstein distance:         {similarity_metrics['wasserstein_distance']:.5f}\")\n",
    "print(\"\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"OVERALL SIMILARITY SCORE:     {similarity_metrics['overall_similarity_score']:.1f}/100\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Parameter Optimization\n",
    "\n",
    "Automated optimization of synthesis parameters to match real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution, minimize\n",
    "\n",
    "\n",
    "def objective_function(params, X_real, wavelengths_real, real_props):\n",
    "    \"\"\"\n",
    "    Objective function for parameter optimization.\n",
    "    Lower is better.\n",
    "    \"\"\"\n",
    "    # Unpack parameters\n",
    "    (\n",
    "        path_length_std,\n",
    "        baseline_amplitude,\n",
    "        global_slope_mean,\n",
    "        global_slope_std,\n",
    "        scatter_alpha_std,\n",
    "        noise_base,\n",
    "        noise_signal_dep,\n",
    "    ) = params\n",
    "\n",
    "    wl_start, wl_end = real_props['wavelength_range']\n",
    "    wl_step = (wl_end - wl_start) / (real_props['n_wavelengths'] - 1)\n",
    "\n",
    "    try:\n",
    "        # Generate synthetic data with current parameters\n",
    "        X_synth, wavelengths_synth, _ = generate_synthetic_spectra(\n",
    "            n_samples=400,  # Smaller for speed\n",
    "            random_state=42,\n",
    "            wavelength_start=wl_start,\n",
    "            wavelength_end=wl_end,\n",
    "            wavelength_step=wl_step,\n",
    "            path_length_std=path_length_std,\n",
    "            baseline_amplitude=baseline_amplitude,\n",
    "            global_slope_mean=global_slope_mean,\n",
    "            global_slope_std=global_slope_std,\n",
    "            scatter_alpha_std=scatter_alpha_std,\n",
    "            noise_base=noise_base,\n",
    "            noise_signal_dep=noise_signal_dep,\n",
    "        )\n",
    "\n",
    "        # Compute similarity metrics\n",
    "        metrics = compute_similarity_metrics(X_real, X_synth, wavelengths_real, wavelengths_synth)\n",
    "\n",
    "        # Objective: maximize similarity (minimize negative score)\n",
    "        return -metrics['overall_similarity_score']\n",
    "\n",
    "    except Exception as e:\n",
    "        return 1000  # Penalty for failed generations\n",
    "\n",
    "# Initial parameters (from real data analysis)\n",
    "initial_params = [\n",
    "    0.05,                          # path_length_std\n",
    "    0.02,                          # baseline_amplitude\n",
    "    real_props['mean_slope'],      # global_slope_mean\n",
    "    real_props['slope_std'],       # global_slope_std\n",
    "    0.05,                          # scatter_alpha_std\n",
    "    real_props['noise_estimate'] * 0.5,  # noise_base\n",
    "    real_props['noise_estimate'] * 0.5,  # noise_signal_dep\n",
    "]\n",
    "\n",
    "# Parameter bounds\n",
    "bounds = [\n",
    "    (0.01, 0.15),    # path_length_std\n",
    "    (0.001, 0.1),    # baseline_amplitude\n",
    "    (-0.2, 0.3),     # global_slope_mean\n",
    "    (0.001, 0.1),    # global_slope_std\n",
    "    (0.01, 0.15),    # scatter_alpha_std\n",
    "    (0.0001, 0.05),  # noise_base\n",
    "    (0.0001, 0.05),  # noise_signal_dep\n",
    "]\n",
    "\n",
    "print(\"Starting parameter optimization...\")\n",
    "print(f\"Initial score: {-objective_function(initial_params, X_real, wavelengths_real, real_props):.1f}/100\")\n",
    "print(\"\")\n",
    "print(\"This may take a few minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization (differential evolution for global optimization)\n",
    "result = differential_evolution(\n",
    "    objective_function,\n",
    "    bounds=bounds,\n",
    "    args=(X_real, wavelengths_real, real_props),\n",
    "    maxiter=30,\n",
    "    seed=42,\n",
    "    polish=True,\n",
    "    disp=True,\n",
    "    workers=1,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OPTIMIZATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final score: {-result.fun:.1f}/100\")\n",
    "print(\"\")\n",
    "print(\"Optimized parameters:\")\n",
    "param_names = [\n",
    "    'path_length_std',\n",
    "    'baseline_amplitude',\n",
    "    'global_slope_mean',\n",
    "    'global_slope_std',\n",
    "    'scatter_alpha_std',\n",
    "    'noise_base',\n",
    "    'noise_signal_dep',\n",
    "]\n",
    "for name, init_val, opt_val in zip(param_names, initial_params, result.x, strict=False):\n",
    "    print(f\"  {name:<20}: {init_val:.5f} -> {opt_val:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate with optimized parameters\n",
    "wl_start, wl_end = real_props['wavelength_range']\n",
    "wl_step = (wl_end - wl_start) / (real_props['n_wavelengths'] - 1)\n",
    "\n",
    "X_opt, wavelengths_opt, opt_metadata = generate_synthetic_spectra(\n",
    "    n_samples=500,\n",
    "    random_state=42,\n",
    "    wavelength_start=wl_start,\n",
    "    wavelength_end=wl_end,\n",
    "    wavelength_step=wl_step,\n",
    "    path_length_std=result.x[0],\n",
    "    baseline_amplitude=result.x[1],\n",
    "    global_slope_mean=result.x[2],\n",
    "    global_slope_std=result.x[3],\n",
    "    scatter_alpha_std=result.x[4],\n",
    "    noise_base=result.x[5],\n",
    "    noise_signal_dep=result.x[6],\n",
    ")\n",
    "\n",
    "# Compute final metrics\n",
    "opt_metrics = compute_similarity_metrics(X_real, X_opt, wavelengths_real, wavelengths_opt)\n",
    "\n",
    "print(f\"\\nFinal similarity score: {opt_metrics['overall_similarity_score']:.1f}/100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Initial vs Optimized\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Mean spectra comparison\n",
    "axes[0].plot(wavelengths_real, X_real.mean(axis=0), 'b-', linewidth=2, label='Real')\n",
    "axes[0].plot(wavelengths_synth, X_synth.mean(axis=0), '--', color='orange', linewidth=2, label='Initial')\n",
    "axes[0].plot(wavelengths_opt, X_opt.mean(axis=0), '--', color='green', linewidth=2, label='Optimized')\n",
    "axes[0].set_xlabel('Wavelength (nm)')\n",
    "axes[0].set_ylabel('Absorbance')\n",
    "axes[0].set_title('Mean Spectra Comparison')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Std comparison\n",
    "axes[1].plot(wavelengths_real, X_real.std(axis=0), 'b-', linewidth=1.5, label='Real')\n",
    "axes[1].plot(wavelengths_synth, X_synth.std(axis=0), '--', color='orange', linewidth=1.5, label='Initial')\n",
    "axes[1].plot(wavelengths_opt, X_opt.std(axis=0), '--', color='green', linewidth=1.5, label='Optimized')\n",
    "axes[1].set_xlabel('Wavelength (nm)')\n",
    "axes[1].set_ylabel('Standard Deviation')\n",
    "axes[1].set_title('Sample Variation Comparison')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Score comparison\n",
    "scores = [\n",
    "    similarity_metrics['overall_similarity_score'],\n",
    "    opt_metrics['overall_similarity_score']\n",
    "]\n",
    "colors = ['orange', 'green']\n",
    "axes[2].bar(['Initial', 'Optimized'], scores, color=colors, edgecolor='black')\n",
    "axes[2].set_ylabel('Similarity Score')\n",
    "axes[2].set_title('Optimization Improvement')\n",
    "axes[2].set_ylim(0, 100)\n",
    "for i, score in enumerate(scores):\n",
    "    axes[2].text(i, score + 2, f'{score:.1f}', ha='center', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Initial vs Optimized Synthesis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Discriminator Test\n",
    "\n",
    "Train a classifier to distinguish real from synthetic. A good synthetic dataset should be hard to discriminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(X_real, X_synth, wavelengths_real, wavelengths_synth, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Train a classifier to discriminate between real and synthetic spectra.\n",
    "\n",
    "    Returns:\n",
    "        accuracy: Classification accuracy (lower is better for synthesis quality)\n",
    "        auc: ROC-AUC score (0.5 means indistinguishable)\n",
    "        importance: Feature importance from classifier\n",
    "    \"\"\"\n",
    "    # Interpolate if wavelengths differ\n",
    "    if len(wavelengths_real) != len(wavelengths_synth) or not np.allclose(wavelengths_real, wavelengths_synth):\n",
    "        X_synth_interp = np.array([np.interp(wavelengths_real, wavelengths_synth, spec) for spec in X_synth])\n",
    "    else:\n",
    "        X_synth_interp = X_synth\n",
    "\n",
    "    # Balance classes\n",
    "    n_samples = min(len(X_real), len(X_synth_interp))\n",
    "    idx_real = np.random.choice(len(X_real), n_samples, replace=False)\n",
    "    idx_synth = np.random.choice(len(X_synth_interp), n_samples, replace=False)\n",
    "\n",
    "    # Create dataset\n",
    "    X = np.vstack([X_real[idx_real], X_synth_interp[idx_synth]])\n",
    "    y = np.array([0] * n_samples + [1] * n_samples)  # 0=real, 1=synthetic\n",
    "\n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Train classifiers\n",
    "    results = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "    results['rf'] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "        'auc': roc_auc_score(y_test, y_prob_rf),\n",
    "        'importance': rf.feature_importances_,\n",
    "        'model': rf,\n",
    "    }\n",
    "\n",
    "    # Gradient Boosting\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred_gb = gb.predict(X_test)\n",
    "    y_prob_gb = gb.predict_proba(X_test)[:, 1]\n",
    "    results['gb'] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred_gb),\n",
    "        'auc': roc_auc_score(y_test, y_prob_gb),\n",
    "        'importance': gb.feature_importances_,\n",
    "        'model': gb,\n",
    "    }\n",
    "\n",
    "    return results, wavelengths_real\n",
    "\n",
    "print(\"Training discriminators...\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test initial synthesis\n",
    "disc_initial, wl = train_discriminator(X_real, X_synth, wavelengths_real, wavelengths_synth)\n",
    "\n",
    "# Test optimized synthesis\n",
    "disc_optimized, _ = train_discriminator(X_real, X_opt, wavelengths_real, wavelengths_opt)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DISCRIMINATOR RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\")\n",
    "print(\"                              INITIAL          OPTIMIZED\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Random Forest Accuracy:       {disc_initial['rf']['accuracy']:.3f}            {disc_optimized['rf']['accuracy']:.3f}\")\n",
    "print(f\"Random Forest AUC:            {disc_initial['rf']['auc']:.3f}            {disc_optimized['rf']['auc']:.3f}\")\n",
    "print(f\"Gradient Boosting Accuracy:   {disc_initial['gb']['accuracy']:.3f}            {disc_optimized['gb']['accuracy']:.3f}\")\n",
    "print(f\"Gradient Boosting AUC:        {disc_initial['gb']['auc']:.3f}            {disc_optimized['gb']['auc']:.3f}\")\n",
    "print(\"\")\n",
    "print(\"Interpretation:\")\n",
    "print(\"  - Accuracy near 0.50 = indistinguishable (ideal)\")\n",
    "print(\"  - AUC near 0.50 = indistinguishable (ideal)\")\n",
    "print(\"  - Lower is better for synthesis quality\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance (what wavelengths reveal synthetic vs real)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Initial synthesis\n",
    "axes[0].plot(wl, disc_initial['rf']['importance'], 'b-', linewidth=1, alpha=0.7, label='Random Forest')\n",
    "axes[0].plot(wl, disc_initial['gb']['importance'], 'r-', linewidth=1, alpha=0.7, label='Gradient Boosting')\n",
    "axes[0].set_xlabel('Wavelength (nm)')\n",
    "axes[0].set_ylabel('Feature Importance')\n",
    "axes[0].set_title(f'Initial Synthesis (Acc: {disc_initial[\"rf\"][\"accuracy\"]:.2f})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Optimized synthesis\n",
    "axes[1].plot(wl, disc_optimized['rf']['importance'], 'b-', linewidth=1, alpha=0.7, label='Random Forest')\n",
    "axes[1].plot(wl, disc_optimized['gb']['importance'], 'r-', linewidth=1, alpha=0.7, label='Gradient Boosting')\n",
    "axes[1].set_xlabel('Wavelength (nm)')\n",
    "axes[1].set_ylabel('Feature Importance')\n",
    "axes[1].set_title(f'Optimized Synthesis (Acc: {disc_optimized[\"rf\"][\"accuracy\"]:.2f})')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Discriminator Feature Importance (wavelengths that distinguish real vs synthetic)', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHigh importance regions indicate where synthetic spectra differ most from real.\")\n",
    "print(\"Use this to identify which spectral features need tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SYNTHESIS QUALITY SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\")\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Real samples: {X_real.shape[0]}\")\n",
    "print(f\"Synthetic samples: {X_opt.shape[0]}\")\n",
    "print(\"\")\n",
    "print(\"METRICS COMPARISON:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Metric':<30} {'Initial':>15} {'Optimized':>15}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Similarity Score':<30} {similarity_metrics['overall_similarity_score']:>15.1f} {opt_metrics['overall_similarity_score']:>15.1f}\")\n",
    "print(f\"{'Mean Spectrum Correlation':<30} {similarity_metrics['mean_spectrum_correlation']:>15.4f} {opt_metrics['mean_spectrum_correlation']:>15.4f}\")\n",
    "print(f\"{'Std Spectrum Correlation':<30} {similarity_metrics['std_spectrum_correlation']:>15.4f} {opt_metrics['std_spectrum_correlation']:>15.4f}\")\n",
    "print(f\"{'Noise Ratio':<30} {similarity_metrics['noise_ratio']:>15.3f} {opt_metrics['noise_ratio']:>15.3f}\")\n",
    "print(f\"{'Discriminator Accuracy':<30} {disc_initial['rf']['accuracy']:>15.3f} {disc_optimized['rf']['accuracy']:>15.3f}\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\")\n",
    "print(\"OPTIMIZED PARAMETERS:\")\n",
    "print(\"-\" * 70)\n",
    "for name, val in zip(param_names, result.x, strict=False):\n",
    "    print(f\"  {name:<25}: {val:.6f}\")\n",
    "print(\"\")\n",
    "print(\"RECOMMENDATIONS:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Generate recommendations based on metrics\n",
    "if opt_metrics['noise_ratio'] < 0.8:\n",
    "    print(\"  - Increase noise_base or noise_signal_dep (synthetic is too clean)\")\n",
    "elif opt_metrics['noise_ratio'] > 1.2:\n",
    "    print(\"  - Decrease noise_base or noise_signal_dep (synthetic is too noisy)\")\n",
    "\n",
    "if disc_optimized['rf']['accuracy'] > 0.7:\n",
    "    print(\"  - Synthetic is still distinguishable. Consider:\")\n",
    "    # Find highest importance wavelengths\n",
    "    importance = disc_optimized['rf']['importance']\n",
    "    top_idx = np.argsort(importance)[-3:]\n",
    "    top_wl = wl[top_idx]\n",
    "    print(f\"    - Investigating wavelengths: {', '.join([f'{w:.0f}' for w in top_wl])} nm\")\n",
    "    print(\"    - Adjusting component spectra or adding more realistic effects\")\n",
    "elif disc_optimized['rf']['accuracy'] < 0.6:\n",
    "    print(\"  - Excellent! Synthetic spectra are nearly indistinguishable from real.\")\n",
    "else:\n",
    "    print(\"  - Good quality. Minor adjustments may improve further.\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export optimized parameters for reuse\n",
    "optimized_config = {\n",
    "    'wavelength_start': wl_start,\n",
    "    'wavelength_end': wl_end,\n",
    "    'wavelength_step': wl_step,\n",
    "    'path_length_std': result.x[0],\n",
    "    'baseline_amplitude': result.x[1],\n",
    "    'global_slope_mean': result.x[2],\n",
    "    'global_slope_std': result.x[3],\n",
    "    'scatter_alpha_std': result.x[4],\n",
    "    'noise_base': result.x[5],\n",
    "    'noise_signal_dep': result.x[6],\n",
    "    'similarity_score': opt_metrics['overall_similarity_score'],\n",
    "    'discriminator_accuracy': disc_optimized['rf']['accuracy'],\n",
    "}\n",
    "\n",
    "print(\"Optimized configuration (copy for reuse):\")\n",
    "print(\"\")\n",
    "print(\"optimized_config = {\")\n",
    "for k, v in optimized_config.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"    '{k}': {v:.6f},\")\n",
    "    else:\n",
    "        print(f\"    '{k}': {v},\")\n",
    "print(\"}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
