{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7a6657",
   "metadata": {},
   "source": [
    "## ⚠️ Important Configuration Note\n",
    "\n",
    "**NIRS4ALL Pipeline Configuration Format:**\n",
    "\n",
    "All configurations in this notebook use the correct NIRS4ALL pipeline format:\n",
    "\n",
    "```python\n",
    "config = {\n",
    "    \"pipeline\": [\n",
    "        # CV splitter (if needed)\n",
    "        ShuffleSplit(n_splits=3, test_size=0.25),\n",
    "        \n",
    "        # Model configuration\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_average\", \n",
    "                \"use_full_train_for_final\": True,  # Optional\n",
    "                \"n_trials\": 10,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 15)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "The key points:\n",
    "- Use `\"pipeline\"` as the top-level key (not \"name\" or \"steps\")\n",
    "- Pipeline is a **list** of transformers, splitters, and models\n",
    "- Model configurations are **dictionaries** within the pipeline list\n",
    "- `finetune_params` contains all optimization settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af21d027",
   "metadata": {},
   "source": [
    "# NIRS4ALL Finetuning Strategies Demo\n",
    "\n",
    "This notebook demonstrates all the different finetuning strategies and cross-validation modes available in NIRS4ALL.\n",
    "\n",
    "**Features Demonstrated:**\n",
    "- Cross-validation modes: `simple`, `per_fold`, `nested`\n",
    "- Parameter strategies: `per_fold_best`, `global_best`, `global_average`\n",
    "- Full training option: `use_full_train_for_final`\n",
    "- Different model types and parameter spaces\n",
    "\n",
    "All examples use small synthetic datasets for fast execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ccae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Demo dataset: 80 samples, 30 features\n",
      "🎯 Target range: -4.45 to 10.94\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "from nirs4all.pipeline.config import PipelineConfigs\n",
    "\n",
    "# Generate synthetic dataset for demonstrations\n",
    "np.random.seed(42)\n",
    "\n",
    "def create_demo_dataset():\n",
    "    \"\"\"Create small synthetic dataset for fast demos.\"\"\"\n",
    "    n_samples = 80\n",
    "    n_features = 30\n",
    "\n",
    "    # Create synthetic spectra\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "\n",
    "    # Add spectral-like structure\n",
    "    wavelengths = np.linspace(1000, 2000, n_features)\n",
    "    for i in range(n_samples):\n",
    "        X[i] += 0.3 * np.sin(wavelengths / 150) + 0.2 * np.cos(wavelengths / 200)\n",
    "\n",
    "    # Create target with relationship to spectra\n",
    "    y = (np.sum(X[:, 5:15], axis=1) +\n",
    "         0.5 * np.sum(X[:, 20:25], axis=1) +\n",
    "         0.3 * np.random.randn(n_samples))\n",
    "\n",
    "    return {\n",
    "        'X': X,\n",
    "        'y': y,\n",
    "        'folds': 3,\n",
    "        'train': 0.7,\n",
    "        'val': 0.15,\n",
    "        'test': 0.15,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "demo_data_config = create_demo_dataset()\n",
    "print(f\"📊 Demo dataset: {demo_data_config['X'].shape[0]} samples, {demo_data_config['X'].shape[1]} features\")\n",
    "print(f\"🎯 Target range: {demo_data_config['y'].min():.2f} to {demo_data_config['y'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33cc8d4",
   "metadata": {},
   "source": [
    "## 1. Cross-Validation Modes\n",
    "\n",
    "NIRS4ALL supports three CV modes with different levels of rigor and computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e415392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 1. SIMPLE CV - Optimize on combined data, train on folds\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_simple_demo_1206ac on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 1: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 1_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\1_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: synthetic_test_dataset\n",
      "Features (samples=80, sources=1):\n",
      "- Source 0: (80, 1, 30), processings=['raw'], min=-3.627, max=3.893, mean=0.06, var=1.071)\n",
      "Targets: (samples=80, targets=1, processings=['numeric'])\n",
      "- numeric: min=-4.451, max=10.943, mean=2.378\n",
      "Indexes:\n",
      "- \"train\", ['raw']: 56 samples\n",
      "- \"test\", ['raw']: 24 samples\n",
      "Folds: [(42, 14), (42, 14), (42, 14)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔍 Simple CV: Finetuning on full training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-09-26 15:06:53,557] A new study created in memory with name: no-name-32f12f4a-4da6-4e00-99b6-245e75db5b4c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Optimizing 1 parameters with random search (5 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,563] Trial 0 finished with value: 2.831748843780041 and parameters: {'n_components': 1}. Best is trial 0 with value: 2.831748843780041.\n",
      "[I 2025-09-26 15:06:53,568] Trial 1 finished with value: 0.13372231918262292 and parameters: {'n_components': 5}. Best is trial 1 with value: 0.13372231918262292.\n",
      "[I 2025-09-26 15:06:53,575] Trial 2 finished with value: 0.04757569019788793 and parameters: {'n_components': 8}. Best is trial 2 with value: 0.04757569019788793.\n",
      "[I 2025-09-26 15:06:53,580] Trial 3 finished with value: 2.831748843780041 and parameters: {'n_components': 1}. Best is trial 2 with value: 0.04757569019788793.\n",
      "[I 2025-09-26 15:06:53,586] Trial 4 finished with value: 0.09074267040675044 and parameters: {'n_components': 6}. Best is trial 2 with value: 0.04757569019788793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Best parameters found: {'n_components': 8}\n",
      "🔄 Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "✅ Simple CV completed successfully\n",
      "💾 Saved 2_finetuned_PLSRegression_1.pkl to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_finetuned_PLSRegression_1.pkl\n",
      "💾 Saved 2_predictions_finetuned_2.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_predictions_finetuned_2.csv\n",
      "💾 Saved 2_trained_PLSRegression_3_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_trained_PLSRegression_3_simple_cv_fold1.pkl\n",
      "💾 Saved 2_predictions_trained_4_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_predictions_trained_4_simple_cv_fold1.csv\n",
      "💾 Saved 2_trained_PLSRegression_5_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_trained_PLSRegression_5_simple_cv_fold2.pkl\n",
      "💾 Saved 2_predictions_trained_6_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_predictions_trained_6_simple_cv_fold2.csv\n",
      "💾 Saved 2_trained_PLSRegression_7_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_trained_PLSRegression_7_simple_cv_fold3.pkl\n",
      "💾 Saved 2_predictions_trained_8_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_predictions_trained_8_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_simple_demo_1206ac completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Simple CV completed in 0.2s\n",
      "📊 Generated 4 prediction sets\n",
      "🔑 Prediction keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2']\n"
     ]
    }
   ],
   "source": [
    "# 1. SIMPLE CV: Fastest, least rigorous\n",
    "print(\"🚀 1. SIMPLE CV - Optimize on combined data, train on folds\")\n",
    "\n",
    "simple_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),  # Create CV folds\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",  # 🎯 SIMPLE MODE\n",
    "                \"param_strategy\": \"per_fold_best\",\n",
    "                \"n_trials\": 5,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "from nirs4all.dataset.loader import create_synthetic_dataset\n",
    "data = create_synthetic_dataset(demo_data_config)\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(simple_config, \"simple_demo\")\n",
    "runner = PipelineRunner()\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Simple CV completed in {elapsed:.1f}s\")\n",
    "print(f\"📊 Generated {len(result._predictions)} prediction sets\")\n",
    "if result._predictions:\n",
    "    print(f\"🔑 Prediction keys: {result._predictions.list_keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ee7e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,622] A new study created in memory with name: no-name-bd9baffc-0e32-401a-bc8e-8f624b8dd87a\n",
      "[I 2025-09-26 15:06:53,628] Trial 0 finished with value: 4.32007458039583 and parameters: {'n_components': 3}. Best is trial 0 with value: 4.32007458039583.\n",
      "[I 2025-09-26 15:06:53,634] Trial 1 finished with value: 2.9699056444356553 and parameters: {'n_components': 5}. Best is trial 1 with value: 2.9699056444356553.\n",
      "[I 2025-09-26 15:06:53,640] Trial 2 finished with value: 3.51816225848337 and parameters: {'n_components': 4}. Best is trial 1 with value: 2.9699056444356553.\n",
      "[I 2025-09-26 15:06:53,647] Trial 3 finished with value: 2.5745211957465703 and parameters: {'n_components': 6}. Best is trial 3 with value: 2.5745211957465703.\n",
      "[I 2025-09-26 15:06:53,648] A new study created in memory with name: no-name-efc94447-b19c-4d32-9741-60e03c385621\n",
      "[I 2025-09-26 15:06:53,653] Trial 0 finished with value: 3.2403212969365516 and parameters: {'n_components': 5}. Best is trial 0 with value: 3.2403212969365516.\n",
      "[I 2025-09-26 15:06:53,658] Trial 1 finished with value: 7.078851719046117 and parameters: {'n_components': 1}. Best is trial 0 with value: 3.2403212969365516.\n",
      "[I 2025-09-26 15:06:53,664] Trial 2 finished with value: 2.755811263948262 and parameters: {'n_components': 8}. Best is trial 2 with value: 2.755811263948262.\n",
      "[I 2025-09-26 15:06:53,671] Trial 3 finished with value: 3.9161610667922298 and parameters: {'n_components': 3}. Best is trial 2 with value: 2.755811263948262.\n",
      "[I 2025-09-26 15:06:53,674] A new study created in memory with name: no-name-e0b5a728-7c1c-494c-8eec-77a16cd721b2\n",
      "[I 2025-09-26 15:06:53,679] Trial 0 finished with value: 6.191467358595095 and parameters: {'n_components': 2}. Best is trial 0 with value: 6.191467358595095.\n",
      "[I 2025-09-26 15:06:53,684] Trial 1 finished with value: 6.191467358595095 and parameters: {'n_components': 2}. Best is trial 0 with value: 6.191467358595095.\n",
      "[I 2025-09-26 15:06:53,689] Trial 2 finished with value: 5.207951959181389 and parameters: {'n_components': 4}. Best is trial 2 with value: 5.207951959181389.\n",
      "[I 2025-09-26 15:06:53,694] Trial 3 finished with value: 6.191467358595095 and parameters: {'n_components': 2}. Best is trial 2 with value: 5.207951959181389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚖️ 2. PER-FOLD CV - Optimize on each fold separately\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_per_fold_demo_4c61a9 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 3: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 3_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\3_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔍 Per-fold CV: Finetuning on each fold with per_fold_best strategy...\n",
      "🎛️ Finetuning fold 1/3...\n",
      "🔍 Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "🎛️ Finetuning fold 2/3...\n",
      "🔍 Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "🎛️ Finetuning fold 3/3...\n",
      "🔍 Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "✅ Per-fold CV completed successfully\n",
      "💾 Saved 4_finetuned_PLSRegression_9_per_fold_cv_fold1.pkl to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_finetuned_PLSRegression_9_per_fold_cv_fold1.pkl\n",
      "💾 Saved 4_predictions_finetuned_10_per_fold_cv_fold1.csv to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_predictions_finetuned_10_per_fold_cv_fold1.csv\n",
      "💾 Saved 4_finetuned_PLSRegression_11_per_fold_cv_fold2.pkl to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_finetuned_PLSRegression_11_per_fold_cv_fold2.pkl\n",
      "💾 Saved 4_predictions_finetuned_12_per_fold_cv_fold2.csv to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_predictions_finetuned_12_per_fold_cv_fold2.csv\n",
      "💾 Saved 4_finetuned_PLSRegression_13_per_fold_cv_fold3.pkl to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_finetuned_PLSRegression_13_per_fold_cv_fold3.pkl\n",
      "💾 Saved 4_predictions_finetuned_14_per_fold_cv_fold3.csv to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_predictions_finetuned_14_per_fold_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_per_fold_demo_4c61a9 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Per-fold CV completed in 0.1s\n",
      "📊 Generated 7 prediction sets\n",
      "🔑 Prediction keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_2']\n"
     ]
    }
   ],
   "source": [
    "# 2. PER-FOLD CV: Standard approach, good balance\n",
    "print(\"\\n⚖️ 2. PER-FOLD CV - Optimize on each fold separately\")\n",
    "\n",
    "per_fold_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),  # Create CV folds\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",  # 🎯 PER-FOLD MODE\n",
    "                \"param_strategy\": \"per_fold_best\",\n",
    "                \"n_trials\": 4,  # Fewer trials since it runs on each fold\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(per_fold_config, \"per_fold_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Per-fold CV completed in {elapsed:.1f}s\")\n",
    "print(f\"📊 Generated {len(result._predictions)} prediction sets\")\n",
    "if result._predictions:\n",
    "    print(f\"🔑 Prediction keys: {result._predictions.list_keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb28acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,732] A new study created in memory with name: no-name-47ba55bd-6a50-425a-a78b-906938284dba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 3. NESTED CV - Inner CV for optimization, outer CV for evaluation\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_nested_demo_d52524 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 5: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 5_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_nested_demo_d52524\\5_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 6: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔍 Nested CV: 3 outer folds with inner CV finetuning...\n",
      "📊 Parameter strategy: per_fold_best\n",
      "🏋️ Outer fold 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,743] Trial 0 finished with value: 6.590670929381243 and parameters: {'n_components': 4}. Best is trial 0 with value: 6.590670929381243.\n",
      "[I 2025-09-26 15:06:53,751] Trial 1 finished with value: 6.590670929381243 and parameters: {'n_components': 4}. Best is trial 0 with value: 6.590670929381243.\n",
      "[I 2025-09-26 15:06:53,761] Trial 2 finished with value: 6.378044723814769 and parameters: {'n_components': 6}. Best is trial 2 with value: 6.378044723814769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏋️ Outer fold 2/3..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,767] A new study created in memory with name: no-name-d880af6f-d287-4463-8533-a577757c6b59\n",
      "[I 2025-09-26 15:06:53,775] Trial 0 finished with value: 6.667593489768158 and parameters: {'n_components': 4}. Best is trial 0 with value: 6.667593489768158.\n",
      "[I 2025-09-26 15:06:53,785] Trial 1 finished with value: 6.667593489768158 and parameters: {'n_components': 4}. Best is trial 0 with value: 6.667593489768158.\n",
      "[I 2025-09-26 15:06:53,793] Trial 2 finished with value: 6.695758060721871 and parameters: {'n_components': 5}. Best is trial 0 with value: 6.667593489768158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏋️ Outer fold 3/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,799] A new study created in memory with name: no-name-29aa942b-778d-4942-a6d5-b17451162c8c\n",
      "[I 2025-09-26 15:06:53,809] Trial 0 finished with value: 8.76296574269475 and parameters: {'n_components': 3}. Best is trial 0 with value: 8.76296574269475.\n",
      "[I 2025-09-26 15:06:53,817] Trial 1 finished with value: 8.76296574269475 and parameters: {'n_components': 3}. Best is trial 0 with value: 8.76296574269475.\n",
      "[I 2025-09-26 15:06:53,827] Trial 2 finished with value: 8.55846215593177 and parameters: {'n_components': 6}. Best is trial 2 with value: 8.55846215593177.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Nested CV completed successfully\n",
      "💾 Saved 6_nested_cv_outer_fold1_PLSRegression_15.pkl to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_nested_cv_outer_fold1_PLSRegression_15.pkl\n",
      "💾 Saved 6_predictions_nested_cv_outer_fold1_16.csv to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_predictions_nested_cv_outer_fold1_16.csv\n",
      "💾 Saved 6_nested_cv_outer_fold2_PLSRegression_17.pkl to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_nested_cv_outer_fold2_PLSRegression_17.pkl\n",
      "💾 Saved 6_predictions_nested_cv_outer_fold2_18.csv to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_predictions_nested_cv_outer_fold2_18.csv\n",
      "💾 Saved 6_nested_cv_outer_fold3_PLSRegression_19.pkl to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_nested_cv_outer_fold3_PLSRegression_19.pkl\n",
      "💾 Saved 6_predictions_nested_cv_outer_fold3_20.csv to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_predictions_nested_cv_outer_fold3_20.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_nested_demo_d52524 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Nested CV completed in 0.1s\n",
      "📊 Generated 7 prediction sets\n",
      "🔑 Prediction keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_2']\n",
      "\n",
      "⏱️ CV Mode Comparison (approximate times):\n",
      "  Simple CV:    Fastest\n",
      "  Per-fold CV:  3x slower\n",
      "  Nested CV:    5-10x slower\n"
     ]
    }
   ],
   "source": [
    "# 3. NESTED CV: Most rigorous, highest computational cost\n",
    "print(\"\\n🔬 3. NESTED CV - Inner CV for optimization, outer CV for evaluation\")\n",
    "\n",
    "nested_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),  # Create CV folds\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"nested\",  # 🎯 NESTED MODE\n",
    "                \"inner_cv\": 2,  # Small for demo\n",
    "                \"param_strategy\": \"per_fold_best\",\n",
    "                \"n_trials\": 3,  # Very small for demo\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 6)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(nested_config, \"nested_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Nested CV completed in {elapsed:.1f}s\")\n",
    "print(f\"📊 Generated {len(result._predictions)} prediction sets\")\n",
    "if result._predictions:\n",
    "    print(f\"🔑 Prediction keys: {result._predictions.list_keys()}\")\n",
    "\n",
    "print(f\"\\n⏱️ CV Mode Comparison (approximate times):\")\n",
    "print(f\"  Simple CV:    Fastest\")\n",
    "print(f\"  Per-fold CV:  3x slower\")\n",
    "print(f\"  Nested CV:    5-10x slower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156262cf",
   "metadata": {},
   "source": [
    "## 2. Parameter Strategies\n",
    "\n",
    "Different strategies for aggregating parameters across cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b62c4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,870] A new study created in memory with name: no-name-5a72dbb9-3963-4172-9283-978c8b9d61d4\n",
      "[I 2025-09-26 15:06:53,876] Trial 0 finished with value: 3.1536673068704446 and parameters: {'n_components': 5}. Best is trial 0 with value: 3.1536673068704446.\n",
      "[I 2025-09-26 15:06:53,882] Trial 1 finished with value: 2.9214336046847986 and parameters: {'n_components': 6}. Best is trial 1 with value: 2.9214336046847986.\n",
      "[I 2025-09-26 15:06:53,887] Trial 2 finished with value: 3.3056925963368826 and parameters: {'n_components': 4}. Best is trial 1 with value: 2.9214336046847986.\n",
      "[I 2025-09-26 15:06:53,891] Trial 3 finished with value: 3.1536673068704446 and parameters: {'n_components': 5}. Best is trial 1 with value: 2.9214336046847986.\n",
      "[I 2025-09-26 15:06:53,893] A new study created in memory with name: no-name-744be270-befa-4e5e-9228-0a1e2eb09935\n",
      "[I 2025-09-26 15:06:53,899] Trial 0 finished with value: 3.8714537446639987 and parameters: {'n_components': 2}. Best is trial 0 with value: 3.8714537446639987.\n",
      "[I 2025-09-26 15:06:53,903] Trial 1 finished with value: 3.8714537446639987 and parameters: {'n_components': 2}. Best is trial 0 with value: 3.8714537446639987.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 1. PER_FOLD_BEST - Each fold uses its own optimized parameters\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_per_fold_best_demo_4c61a9 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 7: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 7_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\7_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 8: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔍 Per-fold CV: Finetuning on each fold with per_fold_best strategy...\n",
      "🎛️ Finetuning fold 1/3...\n",
      "🔍 Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "🎛️ Finetuning fold 2/3...\n",
      "🔍 Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,907] Trial 2 finished with value: 3.050189854233274 and parameters: {'n_components': 3}. Best is trial 2 with value: 3.050189854233274.\n",
      "[I 2025-09-26 15:06:53,913] Trial 3 finished with value: 0.9683112065412375 and parameters: {'n_components': 8}. Best is trial 3 with value: 0.9683112065412375.\n",
      "[I 2025-09-26 15:06:53,915] A new study created in memory with name: no-name-14090daf-bc03-4e32-bce1-ccae842f78f6\n",
      "[I 2025-09-26 15:06:53,921] Trial 0 finished with value: 1.7624151984669005 and parameters: {'n_components': 6}. Best is trial 0 with value: 1.7624151984669005.\n",
      "[I 2025-09-26 15:06:53,926] Trial 1 finished with value: 1.9075781663768288 and parameters: {'n_components': 5}. Best is trial 0 with value: 1.7624151984669005.\n",
      "[I 2025-09-26 15:06:53,930] Trial 2 finished with value: 1.7624151984669005 and parameters: {'n_components': 6}. Best is trial 0 with value: 1.7624151984669005.\n",
      "[I 2025-09-26 15:06:53,935] Trial 3 finished with value: 3.7553081951153033 and parameters: {'n_components': 2}. Best is trial 0 with value: 1.7624151984669005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎛️ Finetuning fold 3/3...\n",
      "🔍 Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "✅ Per-fold CV completed successfully\n",
      "💾 Saved 8_finetuned_PLSRegression_21_per_fold_cv_fold1.pkl to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_finetuned_PLSRegression_21_per_fold_cv_fold1.pkl\n",
      "💾 Saved 8_predictions_finetuned_22_per_fold_cv_fold1.csv to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_predictions_finetuned_22_per_fold_cv_fold1.csv\n",
      "💾 Saved 8_finetuned_PLSRegression_23_per_fold_cv_fold2.pkl to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_finetuned_PLSRegression_23_per_fold_cv_fold2.pkl\n",
      "💾 Saved 8_predictions_finetuned_24_per_fold_cv_fold2.csv to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_predictions_finetuned_24_per_fold_cv_fold2.csv\n",
      "💾 Saved 8_finetuned_PLSRegression_25_per_fold_cv_fold3.pkl to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_finetuned_PLSRegression_25_per_fold_cv_fold3.pkl\n",
      "💾 Saved 8_predictions_finetuned_26_per_fold_cv_fold3.csv to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_predictions_finetuned_26_per_fold_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_per_fold_best_demo_4c61a9 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Per-fold best completed in 0.1s\n",
      "📊 Generated 10 prediction sets\n"
     ]
    }
   ],
   "source": [
    "# Parameter Strategy 1: PER_FOLD_BEST (default)\n",
    "print(\"🎯 1. PER_FOLD_BEST - Each fold uses its own optimized parameters\")\n",
    "\n",
    "per_fold_best_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"per_fold_best\",  # 🎯 DEFAULT STRATEGY\n",
    "                \"n_trials\": 4,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(per_fold_best_config, \"per_fold_best_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Per-fold best completed in {elapsed:.1f}s\")\n",
    "print(f\"📊 Generated {len(result._predictions)} prediction sets\")\n",
    "\n",
    "# Get performance\n",
    "if result._predictions:\n",
    "    combined = result._predictions.combine_folds(\n",
    "        \"sample_data\", config.name, \"PLSRegression\", \"test_fold\"\n",
    "    )\n",
    "    if combined:\n",
    "        y_true = combined['y_true'].flatten()\n",
    "        y_pred = combined['y_pred'].flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        print(f\"🎯 Performance: RMSE={rmse:.3f}, R²={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0651a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,963] A new study created in memory with name: no-name-54213c7f-d0e3-4a4f-8f87-64cfbbb76ab2\n",
      "[I 2025-09-26 15:06:53,969] Trial 0 finished with value: 3.119835572618817 and parameters: {'n_components': 5}. Best is trial 0 with value: 3.119835572618817.\n",
      "[I 2025-09-26 15:06:53,974] Trial 1 finished with value: 2.4273903584050704 and parameters: {'n_components': 7}. Best is trial 1 with value: 2.4273903584050704.\n",
      "[I 2025-09-26 15:06:53,979] Trial 2 finished with value: 3.502549045081746 and parameters: {'n_components': 4}. Best is trial 1 with value: 2.4273903584050704.\n",
      "[I 2025-09-26 15:06:53,984] Trial 3 finished with value: 2.6440505475265668 and parameters: {'n_components': 6}. Best is trial 1 with value: 2.4273903584050704.\n",
      "[I 2025-09-26 15:06:53,986] A new study created in memory with name: no-name-6058c8d7-f695-469b-98d3-73b4dbffaa84\n",
      "[I 2025-09-26 15:06:53,991] Trial 0 finished with value: 2.6886753336663625 and parameters: {'n_components': 5}. Best is trial 0 with value: 2.6886753336663625.\n",
      "[I 2025-09-26 15:06:53,997] Trial 1 finished with value: 3.346063408408062 and parameters: {'n_components': 4}. Best is trial 0 with value: 2.6886753336663625.\n",
      "[I 2025-09-26 15:06:54,001] Trial 2 finished with value: 3.346063408408062 and parameters: {'n_components': 4}. Best is trial 0 with value: 2.6886753336663625.\n",
      "[I 2025-09-26 15:06:54,006] Trial 3 finished with value: 2.6886753336663625 and parameters: {'n_components': 5}. Best is trial 0 with value: 2.6886753336663625.\n",
      "[I 2025-09-26 15:06:54,009] A new study created in memory with name: no-name-0e89c2b1-a860-4924-a38f-feb3157c34e6\n",
      "[I 2025-09-26 15:06:54,014] Trial 0 finished with value: 3.3758056643189853 and parameters: {'n_components': 8}. Best is trial 0 with value: 3.3758056643189853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 2. GLOBAL_BEST - Single best parameter set for all folds\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_global_best_demo_c0374c on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 9: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 9_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\9_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 10: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔍 Per-fold CV: Finetuning on each fold with global_best strategy...\n",
      "🎛️ Finetuning fold 1/3...\n",
      "🔍 Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "🎛️ Finetuning fold 2/3...\n",
      "🔍 Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "🎛️ Finetuning fold 3/3...\n",
      "🔍 Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,020] Trial 1 finished with value: 3.3758056643189853 and parameters: {'n_components': 8}. Best is trial 0 with value: 3.3758056643189853.\n",
      "[I 2025-09-26 15:06:54,025] Trial 2 finished with value: 4.724794511830299 and parameters: {'n_components': 3}. Best is trial 0 with value: 3.3758056643189853.\n",
      "[I 2025-09-26 15:06:54,031] Trial 3 finished with value: 4.724794511830299 and parameters: {'n_components': 3}. Best is trial 0 with value: 3.3758056643189853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Global best parameters: {'n_components': 7}\n",
      "✅ Per-fold CV completed successfully\n",
      "💾 Saved 10_finetuned_PLSRegression_27_per_fold_cv_fold1.pkl to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_finetuned_PLSRegression_27_per_fold_cv_fold1.pkl\n",
      "💾 Saved 10_predictions_finetuned_28_per_fold_cv_fold1.csv to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_predictions_finetuned_28_per_fold_cv_fold1.csv\n",
      "💾 Saved 10_finetuned_PLSRegression_29_per_fold_cv_fold2.pkl to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_finetuned_PLSRegression_29_per_fold_cv_fold2.pkl\n",
      "💾 Saved 10_predictions_finetuned_30_per_fold_cv_fold2.csv to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_predictions_finetuned_30_per_fold_cv_fold2.csv\n",
      "💾 Saved 10_finetuned_PLSRegression_31_per_fold_cv_fold3.pkl to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_finetuned_PLSRegression_31_per_fold_cv_fold3.pkl\n",
      "💾 Saved 10_predictions_finetuned_32_per_fold_cv_fold3.csv to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_predictions_finetuned_32_per_fold_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_global_best_demo_c0374c completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Global best completed in 0.1s\n",
      "📊 Generated 13 prediction sets\n"
     ]
    }
   ],
   "source": [
    "# Parameter Strategy 2: GLOBAL_BEST\n",
    "print(\"\\n🏆 2. GLOBAL_BEST - Single best parameter set for all folds\")\n",
    "\n",
    "global_best_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_best\",  # 🎯 GLOBAL BEST STRATEGY\n",
    "                \"n_trials\": 4,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(global_best_config, \"global_best_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Global best completed in {elapsed:.1f}s\")\n",
    "print(f\"📊 Generated {len(result._predictions)} prediction sets\")\n",
    "\n",
    "if result._predictions:\n",
    "    combined = result._predictions.combine_folds(\n",
    "        \"sample_data\", config.name, \"PLSRegression\", \"test_fold\"\n",
    "    )\n",
    "    if combined:\n",
    "        y_true = combined['y_true'].flatten()\n",
    "        y_pred = combined['y_pred'].flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        print(f\"🎯 Performance: RMSE={rmse:.3f}, R²={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79f2733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,068] A new study created in memory with name: no-name-ea4b3d99-c209-4ee4-83e9-591d10e0ce1d\n",
      "[I 2025-09-26 15:06:54,082] Trial 0 finished with value: 10.513848496645641 and parameters: {'n_components': 4}. Best is trial 0 with value: 10.513848496645641.\n",
      "[I 2025-09-26 15:06:54,095] Trial 1 finished with value: 10.513848496645641 and parameters: {'n_components': 4}. Best is trial 0 with value: 10.513848496645641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌍 3. GLOBAL_AVERAGE - Optimize by averaging across ALL folds\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_global_average_demo_d7f2f7 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 11: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 11_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\11_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 12: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🌍 Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "🎯 Optimizing with 3 trials, evaluating each on all 3 folds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,119] Trial 2 finished with value: 11.2829692139246 and parameters: {'n_components': 1}. Best is trial 0 with value: 10.513848496645641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Global best parameters: {'n_components': 4}\n",
      "📊 Best average score: 10.5138\n",
      "🔄 Training 3 final models with global best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "✅ Global Average CV completed successfully\n",
      "💾 Saved 12_trained_PLSRegression_33_global_avg_cv_fold1.pkl to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_trained_PLSRegression_33_global_avg_cv_fold1.pkl\n",
      "💾 Saved 12_predictions_trained_34_global_avg_cv_fold1.csv to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_predictions_trained_34_global_avg_cv_fold1.csv\n",
      "💾 Saved 12_trained_PLSRegression_35_global_avg_cv_fold2.pkl to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_trained_PLSRegression_35_global_avg_cv_fold2.pkl\n",
      "💾 Saved 12_predictions_trained_36_global_avg_cv_fold2.csv to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_predictions_trained_36_global_avg_cv_fold2.csv\n",
      "💾 Saved 12_trained_PLSRegression_37_global_avg_cv_fold3.pkl to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_trained_PLSRegression_37_global_avg_cv_fold3.pkl\n",
      "💾 Saved 12_predictions_trained_38_global_avg_cv_fold3.csv to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_predictions_trained_38_global_avg_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_global_average_demo_d7f2f7 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Global average completed in 0.1s\n",
      "📊 Generated 16 prediction sets\n",
      "\n",
      "📊 Parameter Strategy Comparison:\n",
      "  per_fold_best:  Each fold optimized individually\n",
      "  global_best:    Best performing params used for all folds\n",
      "  global_average: Params optimized for average performance ⭐\n"
     ]
    }
   ],
   "source": [
    "# Parameter Strategy 3: GLOBAL_AVERAGE ⭐ NEW\n",
    "print(\"\\n🌍 3. GLOBAL_AVERAGE - Optimize by averaging across ALL folds\")\n",
    "\n",
    "global_average_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_average\",  # 🎯 NEW STRATEGY\n",
    "                \"n_trials\": 3,  # Fewer trials since more expensive per trial\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(global_average_config, \"global_average_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Global average completed in {elapsed:.1f}s\")\n",
    "print(f\"📊 Generated {len(result._predictions)} prediction sets\")\n",
    "\n",
    "if result._predictions:\n",
    "    combined = result._predictions.combine_folds(\n",
    "        \"sample_data\", config.name, \"PLSRegression\", \"test_fold\"\n",
    "    )\n",
    "    if combined:\n",
    "        y_true = combined['y_true'].flatten()\n",
    "        y_pred = combined['y_pred'].flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        print(f\"🎯 Performance: RMSE={rmse:.3f}, R²={r2:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 Parameter Strategy Comparison:\")\n",
    "print(f\"  per_fold_best:  Each fold optimized individually\")\n",
    "print(f\"  global_best:    Best performing params used for all folds\")\n",
    "print(f\"  global_average: Params optimized for average performance ⭐\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae7043",
   "metadata": {},
   "source": [
    "## 3. Full Training Option ⭐ NEW\n",
    "\n",
    "The `use_full_train_for_final` option lets you use CV for optimization but train the final model on all available training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e04c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,162] A new study created in memory with name: no-name-65d9b59b-4921-4f93-8c3d-c60b5ecb2bae\n",
      "[I 2025-09-26 15:06:54,177] Trial 0 finished with value: 11.53709932036127 and parameters: {'n_components': 4}. Best is trial 0 with value: 11.53709932036127.\n",
      "[I 2025-09-26 15:06:54,191] Trial 1 finished with value: 11.590515481026053 and parameters: {'n_components': 8}. Best is trial 0 with value: 11.53709932036127.\n",
      "[I 2025-09-26 15:06:54,204] Trial 2 finished with value: 11.543476125180026 and parameters: {'n_components': 3}. Best is trial 0 with value: 11.53709932036127.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 TRADITIONAL: Separate models per fold\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_traditional_demo_2f0f5c on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 13: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 13_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\13_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 14: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🌍 Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "🎯 Optimizing with 3 trials, evaluating each on all 3 folds...\n",
      "🏆 Global best parameters: {'n_components': 4}\n",
      "📊 Best average score: 11.5371\n",
      "🔄 Training 3 final models with global best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "✅ Global Average CV completed successfully\n",
      "💾 Saved 14_trained_PLSRegression_39_global_avg_cv_fold1.pkl to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_trained_PLSRegression_39_global_avg_cv_fold1.pkl\n",
      "💾 Saved 14_predictions_trained_40_global_avg_cv_fold1.csv to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_predictions_trained_40_global_avg_cv_fold1.csv\n",
      "💾 Saved 14_trained_PLSRegression_41_global_avg_cv_fold2.pkl to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_trained_PLSRegression_41_global_avg_cv_fold2.pkl\n",
      "💾 Saved 14_predictions_trained_42_global_avg_cv_fold2.csv to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_predictions_trained_42_global_avg_cv_fold2.csv\n",
      "💾 Saved 14_trained_PLSRegression_43_global_avg_cv_fold3.pkl to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_trained_PLSRegression_43_global_avg_cv_fold3.pkl\n",
      "💾 Saved 14_predictions_trained_44_global_avg_cv_fold3.csv to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_predictions_trained_44_global_avg_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_traditional_demo_2f0f5c completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Traditional approach completed in 0.1s\n",
      "📊 Generated 19 prediction sets\n",
      "🔑 Keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_2']\n"
     ]
    }
   ],
   "source": [
    "# Traditional approach: separate models per fold\n",
    "print(\"🔄 TRADITIONAL: Separate models per fold\")\n",
    "\n",
    "traditional_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_average\",\n",
    "                \"use_full_train_for_final\": False,  # 🎯 TRADITIONAL\n",
    "                \"n_trials\": 3,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(traditional_config, \"traditional_demo\")\n",
    "result_traditional, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Traditional approach completed in {elapsed:.1f}s\")\n",
    "print(f\"📊 Generated {len(result_traditional._predictions)} prediction sets\")\n",
    "print(f\"🔑 Keys: {result_traditional._predictions.list_keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5246a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,237] A new study created in memory with name: no-name-2b3dcbba-0aaf-4e7b-a996-223d833689b2\n",
      "[I 2025-09-26 15:06:54,253] Trial 0 finished with value: 9.578812769031337 and parameters: {'n_components': 6}. Best is trial 0 with value: 9.578812769031337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 FULL TRAINING: Single model on combined data ⭐\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_full_train_demo_c97b52 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 15: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 15_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_full_train_demo_c97b52\\15_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 16: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🌍 Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "🎯 Optimizing with 3 trials, evaluating each on all 3 folds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,266] Trial 1 finished with value: 9.792100848166182 and parameters: {'n_components': 3}. Best is trial 0 with value: 9.578812769031337.\n",
      "[I 2025-09-26 15:06:54,280] Trial 2 finished with value: 9.578812769031337 and parameters: {'n_components': 6}. Best is trial 0 with value: 9.578812769031337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Global best parameters: {'n_components': 6}\n",
      "📊 Best average score: 9.5788\n",
      "🎯 Training single model on full training data (global_avg)...\n",
      "📊 Combined training data: 126 samples\n",
      "📊 Combined test data: 42 samples\n",
      "✅ Applied optimized parameters: {'n_components': 6}\n",
      "🏋️ Training model with 126 samples...\n",
      "✅ Single model training on full data completed successfully\n",
      "💾 Saved 16_global_avg_model_PLSRegression_45.pkl to results\\synthetic_test_dataset\\config_full_train_demo_c97b52\\16_global_avg_model_PLSRegression_45.pkl\n",
      "💾 Saved 16_predictions_global_avg_model_46.csv to results\\synthetic_test_dataset\\config_full_train_demo_c97b52\\16_predictions_global_avg_model_46.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_full_train_demo_c97b52 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Full training approach completed in 0.1s\n",
      "📊 Generated 20 prediction sets\n",
      "🔑 Keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_full_train_demo_c97b52_PLSRegression_test_global_avg']\n",
      "\n",
      "📊 COMPARISON:\n",
      "  Traditional: 20 prediction sets (multiple models)\n",
      "  Full Train:  20 prediction sets (single model)\n",
      "\n",
      "💡 Full Training Benefits:\n",
      "  ✓ Uses all available training data\n",
      "  ✓ Single model for deployment\n",
      "  ✓ Often better performance\n",
      "  ✓ Simpler model management\n"
     ]
    }
   ],
   "source": [
    "# NEW Full Training approach: single model on full data\n",
    "print(\"\\n🎯 FULL TRAINING: Single model on combined data ⭐\")\n",
    "\n",
    "full_train_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_average\",\n",
    "                \"use_full_train_for_final\": True,  # 🎯 NEW OPTION\n",
    "                \"n_trials\": 3,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(full_train_config, \"full_train_demo\")\n",
    "result_full_train, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Full training approach completed in {elapsed:.1f}s\")\n",
    "print(f\"📊 Generated {len(result_full_train._predictions)} prediction sets\")\n",
    "print(f\"🔑 Keys: {result_full_train._predictions.list_keys()}\")\n",
    "\n",
    "# Compare approaches\n",
    "print(f\"\\n📊 COMPARISON:\")\n",
    "print(f\"  Traditional: {len(result_traditional._predictions)} prediction sets (multiple models)\")\n",
    "print(f\"  Full Train:  {len(result_full_train._predictions)} prediction sets (single model)\")\n",
    "print(f\"\\n💡 Full Training Benefits:\")\n",
    "print(f\"  ✓ Uses all available training data\")\n",
    "print(f\"  ✓ Single model for deployment\")\n",
    "print(f\"  ✓ Often better performance\")\n",
    "print(f\"  ✓ Simpler model management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82467f19",
   "metadata": {},
   "source": [
    "## 4. Different Model Types\n",
    "\n",
    "Test finetuning strategies with different model types and parameter spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aefff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,321] A new study created in memory with name: no-name-54b71f89-56b4-45b1-9fb2-4f5cc442086b\n",
      "[I 2025-09-26 15:06:54,327] Trial 0 finished with value: 0.06641292204265331 and parameters: {'n_components': 6}. Best is trial 0 with value: 0.06641292204265331.\n",
      "[I 2025-09-26 15:06:54,332] Trial 1 finished with value: 0.10276666343404751 and parameters: {'n_components': 5}. Best is trial 0 with value: 0.06641292204265331.\n",
      "[I 2025-09-26 15:06:54,337] Trial 2 finished with value: 0.4159393790482339 and parameters: {'n_components': 3}. Best is trial 0 with value: 0.06641292204265331.\n",
      "[I 2025-09-26 15:06:54,343] Trial 3 finished with value: 0.06641292204265331 and parameters: {'n_components': 6}. Best is trial 0 with value: 0.06641292204265331.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 1. PLS Regression - Continuous parameter optimization\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_pls_demo_febb66 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 17: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 17_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\17_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 18: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔍 Simple CV: Finetuning on full training data...\n",
      "🔍 Optimizing 1 parameters with random search (5 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,349] Trial 4 finished with value: 0.0409985299268884 and parameters: {'n_components': 8}. Best is trial 4 with value: 0.0409985299268884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Best parameters found: {'n_components': 8}\n",
      "🔄 Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "✅ Simple CV completed successfully\n",
      "💾 Saved 18_finetuned_PLSRegression_47.pkl to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_finetuned_PLSRegression_47.pkl\n",
      "💾 Saved 18_predictions_finetuned_48.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_predictions_finetuned_48.csv\n",
      "💾 Saved 18_trained_PLSRegression_49_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_trained_PLSRegression_49_simple_cv_fold1.pkl\n",
      "💾 Saved 18_predictions_trained_50_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_predictions_trained_50_simple_cv_fold1.csv\n",
      "💾 Saved 18_trained_PLSRegression_51_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_trained_PLSRegression_51_simple_cv_fold2.pkl\n",
      "💾 Saved 18_predictions_trained_52_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_predictions_trained_52_simple_cv_fold2.csv\n",
      "💾 Saved 18_trained_PLSRegression_53_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_trained_PLSRegression_53_simple_cv_fold3.pkl\n",
      "💾 Saved 18_predictions_trained_54_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_predictions_trained_54_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_pls_demo_febb66 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ PLS completed in 0.1s\n",
      "🎯 PLS Performance: RMSE=0.267, R²=0.995\n"
     ]
    }
   ],
   "source": [
    "# Model 1: PLS Regression (continuous parameter)\n",
    "print(\"🧮 1. PLS Regression - Continuous parameter optimization\")\n",
    "\n",
    "pls_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",  # Fast for demo\n",
    "                \"param_strategy\": \"global_average\",\n",
    "                \"n_trials\": 5,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 10)  # 🎯 Integer parameter\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(pls_config, \"pls_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ PLS completed in {elapsed:.1f}s\")\n",
    "if result._predictions:\n",
    "    keys = result._predictions.list_keys()\n",
    "    if keys:\n",
    "        key_parts = keys[0].split('_', 3)\n",
    "        if len(key_parts) >= 4:\n",
    "            pred_data = result._predictions.get_prediction_data(*key_parts)\n",
    "            if pred_data:\n",
    "                y_true = pred_data['y_true'].flatten()\n",
    "                y_pred = pred_data['y_pred'].flatten()\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                print(f\"🎯 PLS Performance: RMSE={rmse:.3f}, R²={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e73d790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,400] A new study created in memory with name: no-name-4a660835-4a59-4865-9879-2563a975a4a4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📐 2. Ridge Regression - Float parameter optimization\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_ridge_demo_ca3b40 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 19: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 19_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\19_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 20: (finetune) Ridge()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator Ridge\n",
      "🔍 Simple CV: Finetuning on full training data...\n",
      "🔍 Optimizing 1 parameters with random search (5 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,405] Trial 0 finished with value: 0.23077033956845602 and parameters: {'alpha': 7.7804537396434705}. Best is trial 0 with value: 0.23077033956845602.\n",
      "[I 2025-09-26 15:06:54,411] Trial 1 finished with value: 0.11347101877133052 and parameters: {'alpha': 3.984846289449217}. Best is trial 1 with value: 0.11347101877133052.\n",
      "[I 2025-09-26 15:06:54,415] Trial 2 finished with value: 0.11366061866283417 and parameters: {'alpha': 3.991897068025448}. Best is trial 1 with value: 0.11347101877133052.\n",
      "[I 2025-09-26 15:06:54,419] Trial 3 finished with value: 0.22531107564767203 and parameters: {'alpha': 7.619147142300146}. Best is trial 1 with value: 0.11347101877133052.\n",
      "[I 2025-09-26 15:06:54,423] Trial 4 finished with value: 0.2102480779091517 and parameters: {'alpha': 7.168890403267846}. Best is trial 1 with value: 0.11347101877133052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Best parameters found: {'alpha': 3.984846289449217}\n",
      "🔄 Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "✅ Simple CV completed successfully\n",
      "💾 Saved 20_finetuned_Ridge_55.pkl to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_finetuned_Ridge_55.pkl\n",
      "💾 Saved 20_predictions_finetuned_56.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_predictions_finetuned_56.csv\n",
      "💾 Saved 20_trained_Ridge_57_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_trained_Ridge_57_simple_cv_fold1.pkl\n",
      "💾 Saved 20_predictions_trained_58_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_predictions_trained_58_simple_cv_fold1.csv\n",
      "💾 Saved 20_trained_Ridge_59_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_trained_Ridge_59_simple_cv_fold2.pkl\n",
      "💾 Saved 20_predictions_trained_60_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_predictions_trained_60_simple_cv_fold2.csv\n",
      "💾 Saved 20_trained_Ridge_61_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_trained_Ridge_61_simple_cv_fold3.pkl\n",
      "💾 Saved 20_predictions_trained_62_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_predictions_trained_62_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_ridge_demo_ca3b40 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Ridge completed in 0.0s\n",
      "🎯 Ridge Performance: RMSE=0.267, R²=0.995\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Ridge Regression (float parameter)\n",
    "print(\"\\n📐 2. Ridge Regression - Float parameter optimization\")\n",
    "\n",
    "ridge_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": Ridge(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",\n",
    "                \"param_strategy\": \"global_average\",\n",
    "                \"n_trials\": 5,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"alpha\": (\"float\", 0.1, 10.0)  # 🎯 Float parameter\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(ridge_config, \"ridge_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Ridge completed in {elapsed:.1f}s\")\n",
    "if result._predictions:\n",
    "    keys = result._predictions.list_keys()\n",
    "    if keys:\n",
    "        key_parts = keys[0].split('_', 3)\n",
    "        if len(key_parts) >= 4:\n",
    "            pred_data = result._predictions.get_prediction_data(*key_parts)\n",
    "            if pred_data:\n",
    "                y_true = pred_data['y_true'].flatten()\n",
    "                y_pred = pred_data['y_pred'].flatten()\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                print(f\"🎯 Ridge Performance: RMSE={rmse:.3f}, R²={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a49f881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,459] A new study created in memory with name: no-name-726571ba-5209-43e1-886c-3956ce3d8069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌲 3. Random Forest - Mixed parameter types\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_rf_demo_707130 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 21: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 21_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\21_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 22: (finetune) RandomForestRegressor(random_state=42)\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator RandomForestRegressor\n",
      "🔍 Simple CV: Finetuning on full training data...\n",
      "🔍 Optimizing 2 parameters with grid search (4 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,554] Trial 0 finished with value: 2.900292467644007 and parameters: {'n_estimators': 30, 'max_depth': 3}. Best is trial 0 with value: 2.900292467644007.\n",
      "[I 2025-09-26 15:06:54,683] Trial 1 finished with value: 1.214873214161031 and parameters: {'n_estimators': 30, 'max_depth': 7}. Best is trial 1 with value: 1.214873214161031.\n",
      "[I 2025-09-26 15:06:54,732] Trial 2 finished with value: 1.4688841824561942 and parameters: {'n_estimators': 10, 'max_depth': 7}. Best is trial 1 with value: 1.214873214161031.\n",
      "[I 2025-09-26 15:06:54,773] Trial 3 finished with value: 3.169007985609278 and parameters: {'n_estimators': 10, 'max_depth': 3}. Best is trial 1 with value: 1.214873214161031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Best parameters found: {'n_estimators': 30, 'max_depth': 7}\n",
      "🔄 Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "✅ Simple CV completed successfully\n",
      "💾 Saved 22_finetuned_RandomForestRegressor_63.pkl to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_finetuned_RandomForestRegressor_63.pkl\n",
      "💾 Saved 22_predictions_finetuned_64.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_predictions_finetuned_64.csv\n",
      "💾 Saved 22_trained_RandomForestRegressor_65_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_trained_RandomForestRegressor_65_simple_cv_fold1.pkl\n",
      "💾 Saved 22_predictions_trained_66_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_predictions_trained_66_simple_cv_fold1.csv\n",
      "💾 Saved 22_trained_RandomForestRegressor_67_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_trained_RandomForestRegressor_67_simple_cv_fold2.pkl\n",
      "💾 Saved 22_predictions_trained_68_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_predictions_trained_68_simple_cv_fold2.csv\n",
      "💾 Saved 22_trained_RandomForestRegressor_69_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_trained_RandomForestRegressor_69_simple_cv_fold3.pkl\n",
      "💾 Saved 22_predictions_trained_70_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_predictions_trained_70_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_rf_demo_707130 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Random Forest completed in 0.6s\n",
      "🎯 RF Performance: RMSE=0.267, R²=0.995\n",
      "\n",
      "🎛️ Parameter Type Summary:\n",
      "  PLS:     ('int', min, max) - Integer range\n",
      "  Ridge:   ('float', min, max) - Float range\n",
      "  RF:      [val1, val2, val3] - Categorical list\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Random Forest (categorical and integer parameters)\n",
    "print(\"\\n🌲 3. Random Forest - Mixed parameter types\")\n",
    "\n",
    "rf_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": RandomForestRegressor(random_state=42),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",\n",
    "                \"param_strategy\": \"per_fold_best\",  # Faster for RF\n",
    "                \"n_trials\": 4,  # RF can be slow\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_estimators\": [10, 20, 30],  # 🎯 Categorical parameter\n",
    "                    \"max_depth\": [3, 5, 7]         # 🎯 Categorical parameter\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(rf_config, \"rf_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Random Forest completed in {elapsed:.1f}s\")\n",
    "if result._predictions:\n",
    "    keys = result._predictions.list_keys()\n",
    "    if keys:\n",
    "        key_parts = keys[0].split('_', 3)\n",
    "        if len(key_parts) >= 4:\n",
    "            pred_data = result._predictions.get_prediction_data(*key_parts)\n",
    "            if pred_data:\n",
    "                y_true = pred_data['y_true'].flatten()\n",
    "                y_pred = pred_data['y_pred'].flatten()\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                print(f\"🎯 RF Performance: RMSE={rmse:.3f}, R²={r2:.3f}\")\n",
    "\n",
    "print(f\"\\n🎛️ Parameter Type Summary:\")\n",
    "print(f\"  PLS:     ('int', min, max) - Integer range\")\n",
    "print(f\"  Ridge:   ('float', min, max) - Float range\")\n",
    "print(f\"  RF:      [val1, val2, val3] - Categorical list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31121745",
   "metadata": {},
   "source": [
    "## 5. Best Practice Combinations\n",
    "\n",
    "Recommended combinations for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b012969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:55,088] A new study created in memory with name: no-name-d32fd691-786c-4c7c-82dc-45250a413eb3\n",
      "[I 2025-09-26 15:06:55,095] Trial 0 finished with value: 0.14286875830932175 and parameters: {'n_components': 4}. Best is trial 0 with value: 0.14286875830932175.\n",
      "[I 2025-09-26 15:06:55,099] Trial 1 finished with value: 0.7513361955536707 and parameters: {'n_components': 2}. Best is trial 0 with value: 0.14286875830932175.\n",
      "[I 2025-09-26 15:06:55,110] Trial 2 finished with value: 0.14286875830932175 and parameters: {'n_components': 4}. Best is trial 0 with value: 0.14286875830932175.\n",
      "[I 2025-09-26 15:06:55,117] Trial 3 finished with value: 0.06591775050504516 and parameters: {'n_components': 6}. Best is trial 3 with value: 0.06591775050504516.\n",
      "[I 2025-09-26 15:06:55,125] Trial 4 finished with value: 0.05478362071166592 and parameters: {'n_components': 7}. Best is trial 4 with value: 0.05478362071166592.\n",
      "[I 2025-09-26 15:06:55,132] Trial 5 finished with value: 0.05478362071166592 and parameters: {'n_components': 7}. Best is trial 4 with value: 0.05478362071166592.\n",
      "[I 2025-09-26 15:06:55,138] Trial 6 finished with value: 0.33655481082615735 and parameters: {'n_components': 3}. Best is trial 4 with value: 0.05478362071166592.\n",
      "[I 2025-09-26 15:06:55,147] Trial 7 finished with value: 0.033882517664609445 and parameters: {'n_components': 10}. Best is trial 7 with value: 0.033882517664609445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 PROTOTYPING: Fast and simple\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_prototype_demo_608a92 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 23: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 23_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\23_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 24: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔍 Simple CV: Finetuning on full training data...\n",
      "🔍 Optimizing 1 parameters with random search (8 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n",
      "🏆 Best parameters found: {'n_components': 10}\n",
      "🔄 Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "✅ Simple CV completed successfully\n",
      "💾 Saved 24_finetuned_PLSRegression_71.pkl to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_finetuned_PLSRegression_71.pkl\n",
      "💾 Saved 24_predictions_finetuned_72.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_predictions_finetuned_72.csv\n",
      "💾 Saved 24_trained_PLSRegression_73_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_trained_PLSRegression_73_simple_cv_fold1.pkl\n",
      "💾 Saved 24_predictions_trained_74_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_predictions_trained_74_simple_cv_fold1.csv\n",
      "💾 Saved 24_trained_PLSRegression_75_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_trained_PLSRegression_75_simple_cv_fold2.pkl\n",
      "💾 Saved 24_predictions_trained_76_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_predictions_trained_76_simple_cv_fold2.csv\n",
      "💾 Saved 24_trained_PLSRegression_77_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_trained_PLSRegression_77_simple_cv_fold3.pkl\n",
      "💾 Saved 24_predictions_trained_78_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_predictions_trained_78_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_prototype_demo_608a92 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Prototyping completed in 0.1s\n",
      "💡 Use for: Quick experiments, initial model testing\n"
     ]
    }
   ],
   "source": [
    "# Use Case 1: Quick Prototyping\n",
    "print(\"🚀 PROTOTYPING: Fast and simple\")\n",
    "\n",
    "prototype_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",        # ⚡ Fastest CV mode\n",
    "                \"param_strategy\": \"per_fold_best\",  # 🎯 Standard strategy\n",
    "                \"n_trials\": 8,              # 📊 More trials since it's fast\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 10)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(prototype_config, \"prototype_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "prototype_time = time.time() - start\n",
    "\n",
    "print(f\"✅ Prototyping completed in {prototype_time:.1f}s\")\n",
    "print(\"💡 Use for: Quick experiments, initial model testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5235491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:55,183] A new study created in memory with name: no-name-1f9f64b2-d1c5-4049-95fc-86970aab3d7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:55,195] Trial 0 finished with value: 14.475699861645126 and parameters: {'n_components': 1}. Best is trial 0 with value: 14.475699861645126.\n",
      "[I 2025-09-26 15:06:55,211] Trial 1 finished with value: 14.389765533135874 and parameters: {'n_components': 8}. Best is trial 1 with value: 14.389765533135874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 PRODUCTION: Best generalization + Single model\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_production_demo_facf04 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 25: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 25_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_production_demo_facf04\\25_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 26: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🌍 Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "🎯 Optimizing with 6 trials, evaluating each on all 3 folds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:55,226] Trial 2 finished with value: 14.389765533135874 and parameters: {'n_components': 8}. Best is trial 1 with value: 14.389765533135874.\n",
      "[I 2025-09-26 15:06:55,237] Trial 3 finished with value: 14.475699861645126 and parameters: {'n_components': 1}. Best is trial 1 with value: 14.389765533135874.\n",
      "[I 2025-09-26 15:06:55,252] Trial 4 finished with value: 14.389158122016283 and parameters: {'n_components': 7}. Best is trial 4 with value: 14.389158122016283.\n",
      "[I 2025-09-26 15:06:55,264] Trial 5 finished with value: 14.189845278287764 and parameters: {'n_components': 2}. Best is trial 5 with value: 14.189845278287764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Global best parameters: {'n_components': 2}\n",
      "📊 Best average score: 14.1898\n",
      "🎯 Training single model on full training data (global_avg)...\n",
      "📊 Combined training data: 126 samples\n",
      "📊 Combined test data: 42 samples\n",
      "✅ Applied optimized parameters: {'n_components': 2}\n",
      "🏋️ Training model with 126 samples...\n",
      "✅ Single model training on full data completed successfully\n",
      "💾 Saved 26_global_avg_model_PLSRegression_79.pkl to results\\synthetic_test_dataset\\config_production_demo_facf04\\26_global_avg_model_PLSRegression_79.pkl\n",
      "💾 Saved 26_predictions_global_avg_model_80.csv to results\\synthetic_test_dataset\\config_production_demo_facf04\\26_predictions_global_avg_model_80.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_production_demo_facf04 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Production approach completed in 0.1s\n",
      "💡 Use for: Production deployment, single model needed\n",
      "📊 Models generated: 37 (should be 1 for deployment)\n"
     ]
    }
   ],
   "source": [
    "# Use Case 2: Production Deployment\n",
    "print(\"\\n🎯 PRODUCTION: Best generalization + Single model\")\n",
    "\n",
    "production_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",              # ⚖️ Good balance of rigor and speed\n",
    "                \"param_strategy\": \"global_average\", # 🌍 Most generalizable parameters\n",
    "                \"use_full_train_for_final\": True,  # 🎯 Single model for deployment\n",
    "                \"n_trials\": 6,                     # 📊 Moderate trials\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 12)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(production_config, \"production_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "production_time = time.time() - start\n",
    "\n",
    "print(f\"✅ Production approach completed in {production_time:.1f}s\")\n",
    "print(\"💡 Use for: Production deployment, single model needed\")\n",
    "print(f\"📊 Models generated: {len(result._predictions)} (should be 1 for deployment)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ee973ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 RESEARCH: Maximum rigor\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_research_demo_4d2c11 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 27: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 27_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\27_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 28: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔍 Nested CV: 3 outer folds with inner CV finetuning...\n",
      "📊 Parameter strategy: global_average\n",
      "🏋️ Outer fold 1/3...\n",
      "🏋️ Outer fold 2/3...\n",
      "🏋️ Outer fold 3/3...\n",
      "✅ Nested CV completed successfully\n",
      "💾 Saved 28_nested_cv_outer_fold1_PLSRegression_81.pkl to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_nested_cv_outer_fold1_PLSRegression_81.pkl\n",
      "💾 Saved 28_predictions_nested_cv_outer_fold1_82.csv to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_predictions_nested_cv_outer_fold1_82.csv\n",
      "💾 Saved 28_nested_cv_outer_fold2_PLSRegression_83.pkl to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_nested_cv_outer_fold2_PLSRegression_83.pkl\n",
      "💾 Saved 28_predictions_nested_cv_outer_fold2_84.csv to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_predictions_nested_cv_outer_fold2_84.csv\n",
      "💾 Saved 28_nested_cv_outer_fold3_PLSRegression_85.pkl to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_nested_cv_outer_fold3_PLSRegression_85.pkl\n",
      "💾 Saved 28_predictions_nested_cv_outer_fold3_86.csv to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_predictions_nested_cv_outer_fold3_86.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_research_demo_4d2c11 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "✅ Research approach completed in 0.1s\n",
      "💡 Use for: Academic publications, unbiased evaluation\n",
      "\n",
      "⏱️ Use Case Time Comparison:\n",
      "  Prototyping: 0.1s (fastest)\n",
      "  Production:  0.1s (balanced)\n",
      "  Research:    0.1s (most rigorous)\n"
     ]
    }
   ],
   "source": [
    "# Use Case 3: Research/Academic\n",
    "print(\"\\n🔬 RESEARCH: Maximum rigor\")\n",
    "\n",
    "research_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"nested\",                # 🎓 Most rigorous CV\n",
    "                \"inner_cv\": 2,                      # 🔄 Inner folds (small for demo)\n",
    "                \"param_strategy\": \"global_average\", # 🌍 Unbiased parameter selection\n",
    "                \"n_trials\": 4,                      # 📊 Fewer trials due to high cost\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(research_config, \"research_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "research_time = time.time() - start\n",
    "\n",
    "print(f\"✅ Research approach completed in {research_time:.1f}s\")\n",
    "print(\"💡 Use for: Academic publications, unbiased evaluation\")\n",
    "\n",
    "# Time comparison\n",
    "print(f\"\\n⏱️ Use Case Time Comparison:\")\n",
    "print(f\"  Prototyping: {prototype_time:.1f}s (fastest)\")\n",
    "print(f\"  Production:  {production_time:.1f}s (balanced)\")\n",
    "print(f\"  Research:    {research_time:.1f}s (most rigorous)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66dc04",
   "metadata": {},
   "source": [
    "## 6. Summary and Recommendations\n",
    "\n",
    "**Quick Reference Guide:**\n",
    "\n",
    "### CV Modes:\n",
    "- **`simple`**: Fast prototyping, limited rigor\n",
    "- **`per_fold`**: Standard choice, good balance ⭐\n",
    "- **`nested`**: Research/academic, maximum rigor\n",
    "\n",
    "### Parameter Strategies:\n",
    "- **`per_fold_best`**: Default, each fold optimized individually\n",
    "- **`global_best`**: Consistent parameters across folds\n",
    "- **`global_average`**: Most generalizable parameters ⭐\n",
    "\n",
    "### Full Training Option:\n",
    "- **`use_full_train_for_final: True`**: Single model, more training data ⭐\n",
    "- **`use_full_train_for_final: False`**: Multiple models, traditional approach\n",
    "\n",
    "### Recommended Combinations:\n",
    "1. **Prototyping**: `simple` + `per_fold_best`\n",
    "2. **Production**: `per_fold` + `global_average` + `use_full_train_for_final: True` ⭐\n",
    "3. **Research**: `nested` + `global_average`\n",
    "\n",
    "### Parameter Types:\n",
    "- **Integer**: `(\"int\", min_val, max_val)`\n",
    "- **Float**: `(\"float\", min_val, max_val)`\n",
    "- **Categorical**: `[option1, option2, option3]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbf5ab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 RECOMMENDED SETUP: Production-ready configuration\n",
      "Configuration: {'cv_mode': 'per_fold', 'param_strategy': 'global_average', 'use_full_train_for_final': True, 'n_trials': 10, 'verbose': 1, 'model_params': {'n_components': ('int', 1, 15)}, 'train_params': {'verbose': 0}}\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_recommended_demo_7b54c0 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 29: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved 29_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_recommended_demo_7b54c0\\29_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 30: (finetune) PLSRegression()\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🌍 Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "🎯 Optimizing with 10 trials, evaluating each on all 3 folds...\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "⚠️ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "🏆 Global best parameters: {'n_components': 14}\n",
      "📊 Best average score: 0.2513\n",
      "🎯 Training single model on full training data (global_avg)...\n",
      "📊 Combined training data: 126 samples\n",
      "📊 Combined test data: 42 samples\n",
      "✅ Applied optimized parameters: {'n_components': 14}\n",
      "🏋️ Training model with 126 samples...\n",
      "✅ Single model training on full data completed successfully\n",
      "💾 Saved 30_global_avg_model_PLSRegression_87.pkl to results\\synthetic_test_dataset\\config_recommended_demo_7b54c0\\30_global_avg_model_PLSRegression_87.pkl\n",
      "💾 Saved 30_predictions_global_avg_model_88.csv to results\\synthetic_test_dataset\\config_recommended_demo_7b54c0\\30_predictions_global_avg_model_88.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_recommended_demo_7b54c0 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "\n",
      "✅ Recommended setup completed in 0.1s\n",
      "📊 Generated 38 prediction sets\n",
      "🔑 Final prediction key: synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test\n",
      "\n",
      "🎯 Final Model Performance:\n",
      "  RMSE: 0.2670\n",
      "  R²:   0.9947\n",
      "  Test samples: 14\n",
      "\n",
      "🎉 Demo completed! You've seen all the finetuning strategies in action.\n",
      "💡 Try different combinations for your specific use case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n",
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n",
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n",
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n",
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n"
     ]
    }
   ],
   "source": [
    "# Final demonstration: The recommended production setup\n",
    "print(\"🏆 RECOMMENDED SETUP: Production-ready configuration\")\n",
    "\n",
    "recommended_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",               # ⚖️ Good balance\n",
    "                \"param_strategy\": \"global_average\",  # 🌍 Best generalization\n",
    "                \"use_full_train_for_final\": True,   # 🎯 Single deployment model\n",
    "                \"n_trials\": 10,                     # 📊 Thorough optimization\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 15)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Configuration:\", recommended_config[\"pipeline\"][1][\"finetune_params\"])\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(recommended_config, \"recommended_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"\\n✅ Recommended setup completed in {elapsed:.1f}s\")\n",
    "print(f\"📊 Generated {len(result._predictions)} prediction sets\")\n",
    "\n",
    "if result._predictions:\n",
    "    keys = result._predictions.list_keys()\n",
    "    print(f\"🔑 Final prediction key: {keys[0] if keys else 'None'}\")\n",
    "\n",
    "    if keys:\n",
    "        key_parts = keys[0].split('_', 3)\n",
    "        if len(key_parts) >= 4:\n",
    "            pred_data = result._predictions.get_prediction_data(*key_parts)\n",
    "            if pred_data:\n",
    "                y_true = pred_data['y_true'].flatten()\n",
    "                y_pred = pred_data['y_pred'].flatten()\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "                print(f\"\\n🎯 Final Model Performance:\")\n",
    "                print(f\"  RMSE: {rmse:.4f}\")\n",
    "                print(f\"  R²:   {r2:.4f}\")\n",
    "                print(f\"  Test samples: {len(y_true)}\")\n",
    "\n",
    "print(f\"\\n🎉 Demo completed! You've seen all the finetuning strategies in action.\")\n",
    "print(f\"💡 Try different combinations for your specific use case.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
