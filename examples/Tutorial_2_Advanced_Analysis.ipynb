{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e694de",
   "metadata": {},
   "source": [
    "# Tutorial 2: Advanced NIRS Analysis\n",
    "\n",
    "Welcome to the advanced NIRS4All tutorial! This guide covers sophisticated techniques for professional NIRS data analysis, including multi-source analysis, hyperparameter optimization, and advanced visualizations.\n",
    "\n",
    "## What You'll Master\n",
    "1. **Multi-Source Analysis** - Handle multiple datasets simultaneously\n",
    "2. **Hyperparameter Optimization** - Automated model tuning with Optuna\n",
    "3. **Configuration Generation** - Advanced pipeline customization\n",
    "4. **Advanced Visualizations** - Professional-grade charts and analysis\n",
    "5. **Neural Networks** - Deep learning for NIRS data\n",
    "6. **Everything Together** - Complex real-world workflows\n",
    "\n",
    "## Prerequisites\n",
    "- Completion of Tutorial 1 (Beginner's Guide)\n",
    "- Understanding of cross-validation and model evaluation\n",
    "- Basic knowledge of hyperparameter tuning concepts\n",
    "\n",
    "Let's dive into advanced NIRS analysis! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e2762",
   "metadata": {},
   "source": [
    "## Part 1: Multi-Source Data Analysis\n",
    "\n",
    "Multi-source analysis refers to datasets with multiple target variables (multi-target regression). This is different from multiple datasets - here we have one dataset but predict multiple properties simultaneously.\n",
    "\n",
    "### Step 1.1: Import Advanced Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086975da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced libraries imported successfully!\n",
      "üß† Neural network models available\n",
      "üî¨ Multiple spectral preprocessing techniques loaded\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Third-party imports\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import ShuffleSplit, RepeatedKFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# NIRS4All imports\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "from nirs4all.dataset.predictions import Predictions\n",
    "from nirs4all.dataset.prediction_analyzer import PredictionAnalyzer\n",
    "from nirs4all.operators.models.cirad_tf import nicon, customizable_nicon\n",
    "from nirs4all.operators.transformations import (\n",
    "    Gaussian, SavitzkyGolay, StandardNormalVariate, Haar,\n",
    "    MultiplicativeScatterCorrection, Detrend, FirstDerivative\n",
    ")\n",
    "from nirs4all.pipeline import PipelineConfigs, PipelineRunner\n",
    "\n",
    "# Enable visual feedback\n",
    "os.environ['DISABLE_EMOJIS'] = '0'\n",
    "\n",
    "print(\"‚úÖ Advanced libraries imported successfully!\")\n",
    "print(\"üß† Neural network models available\")\n",
    "print(\"üî¨ Multiple spectral preprocessing techniques loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e20a60",
   "metadata": {},
   "source": [
    "### Step 1.2: Configure Multi-Source Pipeline\n",
    "\n",
    "Let's build a sophisticated pipeline that works across multiple datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcaec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Multi-source pipeline configured with:\n",
      "   ‚Ä¢ 9 preprocessing strategies (including combinations)\n",
      "   ‚Ä¢ 5 different model types\n",
      "   ‚Ä¢ 5-fold cross-validation\n",
      "   ‚Ä¢ Neural network with custom training\n",
      "   ‚Ä¢ Total configurations: 45 = 45\n"
     ]
    }
   ],
   "source": [
    "# Advanced multi-source pipeline\n",
    "multi_source_pipeline = [\n",
    "    # Advanced scaling with custom range\n",
    "    MinMaxScaler(feature_range=(0.1, 0.8)),\n",
    "\n",
    "    # Comprehensive feature augmentation\n",
    "    {\"feature_augmentation\": [\n",
    "        MultiplicativeScatterCorrection(),\n",
    "        Gaussian(),\n",
    "        StandardNormalVariate(),\n",
    "        SavitzkyGolay(),\n",
    "        Haar(),\n",
    "        [MultiplicativeScatterCorrection(), Gaussian()],\n",
    "        [MultiplicativeScatterCorrection(), StandardNormalVariate()],\n",
    "        [StandardNormalVariate(), SavitzkyGolay()],\n",
    "        [Detrend(), FirstDerivative()],\n",
    "    ]},\n",
    "\n",
    "    # Robust cross-validation\n",
    "    ShuffleSplit(n_splits=5, test_size=0.2, random_state=42),\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "\n",
    "    # Diverse model ensemble\n",
    "    {\"model\": PLSRegression(15), \"name\": \"PLS-15\"},\n",
    "    {\"model\": PLSRegression(25), \"name\": \"PLS-25\"},\n",
    "    {\"model\": ElasticNet(alpha=0.1), \"name\": \"ElasticNet\"},\n",
    "    {\"model\": RandomForestRegressor(n_estimators=10, max_depth=5), \"name\": \"RandomForest\"},\n",
    "\n",
    "    # Neural network with custom training parameters\n",
    "    {\n",
    "        \"model\": nicon,\n",
    "        \"name\": \"DeepNIRS\",\n",
    "        \"train_params\": {\n",
    "            \"epochs\": 20,\n",
    "            \"patience\": 20,\n",
    "            \"batch_size\": 64,\n",
    "            \"verbose\": 0\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üîß Multi-source pipeline configured with:\")\n",
    "print(\"   ‚Ä¢ 9 preprocessing strategies (including combinations)\")\n",
    "print(\"   ‚Ä¢ 5 different model types\")\n",
    "print(\"   ‚Ä¢ 5-fold cross-validation\")\n",
    "print(\"   ‚Ä¢ Neural network with custom training\")\n",
    "print(f\"   ‚Ä¢ Total configurations: {5 * 9} = 45\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24e205",
   "metadata": {},
   "source": [
    "### Step 1.3: Run Multi-Source Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5512be00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Multiple train_x files found for sample_data/multi: 3 sources detected.\n",
      "üìä Multiple test_x files found for sample_data/multi: 3 sources detected.\n",
      "üèÉ‚Äç‚ôÇÔ∏è Running multi-source analysis (multi-target regression)...\n",
      "‚ö†Ô∏è  This may take several minutes due to neural network training\n",
      "========================================================================================================================\n",
      "\u001b[94müöÄ Starting Nirs4all run(s) with 1 pipeline on 1 dataset (1 total runs).\u001b[0m\n",
      "========================================================================================================================\n",
      "üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 1, 2151), processings=['raw'], min=-0.265, max=1.436, mean=0.466, var=0.149)\n",
      "- Source 1: (189, 1, 2151), processings=['raw'], min=-0.265, max=1.436, mean=0.466, var=0.149)\n",
      "- Source 2: (189, 1, 2151), processings=['raw'], min=-0.265, max=1.436, mean=0.466, var=0.149)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw']: 130 samples\n",
      "- \"test\", ['raw']: 59 samples\n",
      "\u001b[94müöÄ Starting pipeline Advanced_MultiSource_e90c40 on dataset multi\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.1, 0.8))}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1'], min=0.1, max=0.89, mean=0.661, var=0.016)\n",
      "- Source 1: (189, 1, 2151), processings=['raw_MinMaxScaler_2'], min=0.1, max=0.89, mean=0.661, var=0.016)\n",
      "- Source 2: (189, 1, 2151), processings=['raw_MinMaxScaler_3'], min=0.1, max=0.89, mean=0.661, var=0.016)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 2: {'feature_augmentation': [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}, {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}, {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}, {'class': 'nirs4all.operators.transformations.nirs.Haar', '_runtime_instance': Haar()}, [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}], [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}], [{'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}, {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}], [{'class': 'nirs4all.operators.transformations.signal.Detrend', '_runtime_instance': Detrend()}, {'class': 'nirs4all.operators.transformations.nirs.FirstDerivative', '_runtime_instance': FirstDerivative()}]]}\u001b[0m\n",
      "üîπ Executing controller FeatureAugmentationController without operator\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: {'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MultiplicativeScatterCorrection\n",
      "üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 1, 2151), processings=['raw'], min=-0.265, max=1.436, mean=0.466, var=0.149)\n",
      "- Source 1: (189, 1, 2151), processings=['raw'], min=-0.265, max=1.436, mean=0.466, var=0.149)\n",
      "- Source 2: (189, 1, 2151), processings=['raw'], min=-0.265, max=1.436, mean=0.466, var=0.149)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw']: 130 samples\n",
      "- \"test\", ['raw']: 59 samples\n",
      "\u001b[94müöÄ Starting pipeline Advanced_MultiSource_e90c40 on dataset multi\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.1, 0.8))}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1'], min=0.1, max=0.89, mean=0.661, var=0.016)\n",
      "- Source 1: (189, 1, 2151), processings=['raw_MinMaxScaler_2'], min=0.1, max=0.89, mean=0.661, var=0.016)\n",
      "- Source 2: (189, 1, 2151), processings=['raw_MinMaxScaler_3'], min=0.1, max=0.89, mean=0.661, var=0.016)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 2: {'feature_augmentation': [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}, {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}, {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}, {'class': 'nirs4all.operators.transformations.nirs.Haar', '_runtime_instance': Haar()}, [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}], [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}], [{'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}, {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}], [{'class': 'nirs4all.operators.transformations.signal.Detrend', '_runtime_instance': Detrend()}, {'class': 'nirs4all.operators.transformations.nirs.FirstDerivative', '_runtime_instance': FirstDerivative()}]]}\u001b[0m\n",
      "üîπ Executing controller FeatureAugmentationController without operator\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: {'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MultiplicativeScatterCorrection\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 2, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1'], min=-0.985, max=0.89, mean=0.334, var=0.121)\n",
      "- Source 1: (189, 2, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2'], min=-0.985, max=0.89, mean=0.334, var=0.121)\n",
      "- Source 2: (189, 2, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3'], min=-0.985, max=0.89, mean=0.334, var=0.121)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Gaussian\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 3, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4'], min=-0.985, max=0.89, mean=0.223, var=0.106)\n",
      "- Source 1: (189, 3, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5'], min=-0.985, max=0.89, mean=0.223, var=0.106)\n",
      "- Source 2: (189, 3, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6'], min=-0.985, max=0.89, mean=0.223, var=0.106)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.3: {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator StandardScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 4, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7'], min=-6.489, max=2.151, mean=0.183, var=0.282)\n",
      "- Source 1: (189, 4, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8'], min=-6.489, max=2.151, mean=0.183, var=0.282)\n",
      "- Source 2: (189, 4, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9'], min=-6.489, max=2.151, mean=0.183, var=0.282)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.4: {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 5, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10'], min=-6.489, max=2.151, mean=0.279, var=0.265)\n",
      "- Source 1: (189, 5, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11'], min=-6.489, max=2.151, mean=0.279, var=0.265)\n",
      "- Source 2: (189, 5, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12'], min=-6.489, max=2.151, mean=0.279, var=0.265)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.5: {'class': 'nirs4all.operators.transformations.nirs.Haar', '_runtime_instance': Haar()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Haar\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 2, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1'], min=-0.985, max=0.89, mean=0.334, var=0.121)\n",
      "- Source 1: (189, 2, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2'], min=-0.985, max=0.89, mean=0.334, var=0.121)\n",
      "- Source 2: (189, 2, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3'], min=-0.985, max=0.89, mean=0.334, var=0.121)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Gaussian\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 3, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4'], min=-0.985, max=0.89, mean=0.223, var=0.106)\n",
      "- Source 1: (189, 3, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5'], min=-0.985, max=0.89, mean=0.223, var=0.106)\n",
      "- Source 2: (189, 3, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6'], min=-0.985, max=0.89, mean=0.223, var=0.106)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.3: {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator StandardScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 4, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7'], min=-6.489, max=2.151, mean=0.183, var=0.282)\n",
      "- Source 1: (189, 4, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8'], min=-6.489, max=2.151, mean=0.183, var=0.282)\n",
      "- Source 2: (189, 4, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9'], min=-6.489, max=2.151, mean=0.183, var=0.282)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.4: {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 5, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10'], min=-6.489, max=2.151, mean=0.279, var=0.265)\n",
      "- Source 1: (189, 5, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11'], min=-6.489, max=2.151, mean=0.279, var=0.265)\n",
      "- Source 2: (189, 5, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12'], min=-6.489, max=2.151, mean=0.279, var=0.265)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.5: {'class': 'nirs4all.operators.transformations.nirs.Haar', '_runtime_instance': Haar()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Haar\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 6, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13'], min=-6.489, max=2.151, mean=0.232, var=0.232)\n",
      "- Source 1: (189, 6, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14'], min=-6.489, max=2.151, mean=0.232, var=0.232)\n",
      "- Source 2: (189, 6, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15'], min=-6.489, max=2.151, mean=0.232, var=0.232)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.6: [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}]\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.7: {'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MultiplicativeScatterCorrection\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 6, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13'], min=-6.489, max=2.151, mean=0.232, var=0.232)\n",
      "- Source 1: (189, 6, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14'], min=-6.489, max=2.151, mean=0.232, var=0.232)\n",
      "- Source 2: (189, 6, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15'], min=-6.489, max=2.151, mean=0.232, var=0.232)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.6: [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}]\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.7: {'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MultiplicativeScatterCorrection\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 7, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16'], min=-6.489, max=2.151, mean=0.2, var=0.207)\n",
      "- Source 1: (189, 7, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17'], min=-6.489, max=2.151, mean=0.2, var=0.207)\n",
      "- Source 2: (189, 7, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18'], min=-6.489, max=2.151, mean=0.2, var=0.207)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.8: {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Gaussian\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 7, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "- Source 1: (189, 7, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "- Source 2: (189, 7, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 7, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "- Source 1: (189, 7, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "- Source 2: (189, 7, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 7, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16'], min=-6.489, max=2.151, mean=0.2, var=0.207)\n",
      "- Source 1: (189, 7, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17'], min=-6.489, max=2.151, mean=0.2, var=0.207)\n",
      "- Source 2: (189, 7, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18'], min=-6.489, max=2.151, mean=0.2, var=0.207)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.8: {'class': 'nirs4all.operators.transformations.signal.Gaussian', '_runtime_instance': Gaussian()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Gaussian\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 7, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "- Source 1: (189, 7, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "- Source 2: (189, 7, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 7, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "- Source 1: (189, 7, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "- Source 2: (189, 7, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21'], min=-6.489, max=2.151, mean=0.199, var=0.205)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.0: [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}]\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: {'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MultiplicativeScatterCorrection\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.0: [{'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}, {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}]\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: {'class': 'nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', '_runtime_instance': MultiplicativeScatterCorrection()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MultiplicativeScatterCorrection\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 8, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22'], min=-6.489, max=2.151, mean=0.175, var=0.185)\n",
      "- Source 1: (189, 8, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23'], min=-6.489, max=2.151, mean=0.175, var=0.185)\n",
      "- Source 2: (189, 8, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24'], min=-6.489, max=2.151, mean=0.175, var=0.185)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator StandardScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 8, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "- Source 1: (189, 8, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "- Source 2: (189, 8, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 8, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "- Source 1: (189, 8, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "- Source 2: (189, 8, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 8, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22'], min=-6.489, max=2.151, mean=0.175, var=0.185)\n",
      "- Source 1: (189, 8, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23'], min=-6.489, max=2.151, mean=0.175, var=0.185)\n",
      "- Source 2: (189, 8, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24'], min=-6.489, max=2.151, mean=0.175, var=0.185)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator StandardScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 8, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "- Source 1: (189, 8, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "- Source 2: (189, 8, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 8, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "- Source 1: (189, 8, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "- Source 2: (189, 8, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27'], min=-6.489, max=2.151, mean=0.182, var=0.281)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.0: [{'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}, {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}]\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator StandardScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 9, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 1: (189, 9, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 2: (189, 9, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.0: [{'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}, {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}]\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: {'class': 'sklearn.preprocessing._data.StandardScaler', '_runtime_instance': StandardScaler()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator StandardScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 9, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 1: (189, 9, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 2: (189, 9, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 9, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 1: (189, 9, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 2: (189, 9, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 9, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 1: (189, 9, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 2: (189, 9, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.0: [{'class': 'nirs4all.operators.transformations.signal.Detrend', '_runtime_instance': Detrend()}, {'class': 'nirs4all.operators.transformations.nirs.FirstDerivative', '_runtime_instance': FirstDerivative()}]\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: {'class': 'nirs4all.operators.transformations.nirs.SavitzkyGolay', '_runtime_instance': SavitzkyGolay()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 9, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 1: (189, 9, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 2: (189, 9, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 9, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 1: (189, 9, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "- Source 2: (189, 9, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33'], min=-6.489, max=2.151, mean=0.169, var=0.339)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.0: [{'class': 'nirs4all.operators.transformations.signal.Detrend', '_runtime_instance': Detrend()}, {'class': 'nirs4all.operators.transformations.nirs.FirstDerivative', '_runtime_instance': FirstDerivative()}]\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: {'class': 'nirs4all.operators.transformations.signal.Detrend', '_runtime_instance': Detrend()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Detrend\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34'], min=-6.489, max=2.151, mean=0.152, var=0.309)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35'], min=-6.489, max=2.151, mean=0.152, var=0.309)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36'], min=-6.489, max=2.151, mean=0.152, var=0.309)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: {'class': 'nirs4all.operators.transformations.nirs.FirstDerivative', '_runtime_instance': FirstDerivative()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator FirstDerivative\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: {'class': 'nirs4all.operators.transformations.signal.Detrend', '_runtime_instance': Detrend()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Detrend\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34'], min=-6.489, max=2.151, mean=0.152, var=0.309)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35'], min=-6.489, max=2.151, mean=0.152, var=0.309)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36'], min=-6.489, max=2.151, mean=0.152, var=0.309)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: {'class': 'nirs4all.operators.transformations.nirs.FirstDerivative', '_runtime_instance': FirstDerivative()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator FirstDerivative\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 5, 'test_size': 0.2, 'random_state': 42}, '_runtime_instance': ShuffleSplit(n_splits=5, random_state=42, test_size=0.2, train_size=None)}\u001b[0m\n",
      "üîπ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 5, 'test_size': 0.2, 'random_state': 42}, '_runtime_instance': ShuffleSplit(n_splits=5, random_state=42, test_size=0.2, train_size=None)}\u001b[0m\n",
      "üîπ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\n",
      "Folds: [(104, 26), (104, 26), (104, 26), (104, 26), (104, 26)]\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}}\u001b[0m\n",
      "üîπ Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric', 'numeric_MinMaxScaler1'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "- numeric_MinMaxScaler1: min=-0.006, max=1.0, mean=0.228\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\n",
      "Folds: [(104, 26), (104, 26), (104, 26), (104, 26), (104, 26)]\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 15}, '_runtime_instance': PLSRegression(n_components=15)}, 'name': 'PLS-15'}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator PLSRegression\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\n",
      "Folds: [(104, 26), (104, 26), (104, 26), (104, 26), (104, 26)]\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}}\u001b[0m\n",
      "üîπ Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: multi (regression)\n",
      "Features (samples=189, sources=3):\n",
      "- Source 0: (189, 10, 2151), processings=['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 1: (189, 10, 2151), processings=['raw_MinMaxScaler_2', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17_Gaussian_20', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23_StandardScaler_26', 'raw_MinMaxScaler_2_StandardScaler_29_SavitzkyGolay_32', 'raw_MinMaxScaler_2_Detrend_35_FirstDerivative_38'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "- Source 2: (189, 10, 2151), processings=['raw_MinMaxScaler_3', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18_Gaussian_21', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24_StandardScaler_27', 'raw_MinMaxScaler_3_StandardScaler_30_SavitzkyGolay_33', 'raw_MinMaxScaler_3_Detrend_36_FirstDerivative_39'], min=-6.489, max=2.151, mean=0.152, var=0.308)\n",
      "Targets: (samples=189, targets=1, processings=['numeric', 'numeric_MinMaxScaler1'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "- numeric_MinMaxScaler1: min=-0.006, max=1.0, mean=0.228\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_1', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_2', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_3', 'raw_MinMaxScaler_1_Gaussian_4', 'raw_MinMaxScaler_2_Gaussian_5', 'raw_MinMaxScaler_3_Gaussian_6', 'raw_MinMaxScaler_1_StandardScaler_7', 'raw_MinMaxScaler_2_StandardScaler_8', 'raw_MinMaxScaler_3_StandardScaler_9', 'raw_MinMaxScaler_1_SavitzkyGolay_10', 'raw_MinMaxScaler_2_SavitzkyGolay_11', 'raw_MinMaxScaler_3_SavitzkyGolay_12', 'raw_MinMaxScaler_1_Haar_13', 'raw_MinMaxScaler_2_Haar_14', 'raw_MinMaxScaler_3_Haar_15', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_16_Gaussian_19', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_17', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_18', 'raw_MinMaxScaler_1_MultiplicativeScatterCorrection_22_StandardScaler_25', 'raw_MinMaxScaler_2_MultiplicativeScatterCorrection_23', 'raw_MinMaxScaler_3_MultiplicativeScatterCorrection_24', 'raw_MinMaxScaler_1_StandardScaler_28_SavitzkyGolay_31', 'raw_MinMaxScaler_2_StandardScaler_29', 'raw_MinMaxScaler_3_StandardScaler_30', 'raw_MinMaxScaler_1_Detrend_34_FirstDerivative_37', 'raw_MinMaxScaler_2_Detrend_35', 'raw_MinMaxScaler_3_Detrend_36']: 59 samples\n",
      "Folds: [(104, 26), (104, 26), (104, 26), (104, 26), (104, 26)]\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 15}, '_runtime_instance': PLSRegression(n_components=15)}, 'name': 'PLS-15'}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator PLSRegression\n",
      "üîç Model config: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 15}, '_runtime_instance': PLSRegression(n_components=15)}, 'name': 'PLS-15', 'model_instance': PLSRegression(n_components=15)}\n",
      "üîç Model config: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 15}, '_runtime_instance': PLSRegression(n_components=15)}, 'name': 'PLS-15', 'model_instance': PLSRegression(n_components=15)}\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 12.9148], [val: 14.1517], (fold: 0, id: 1) - [9wdd0i]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 14.2084], [val: 20.5814], (fold: 1, id: 2) - [h69285]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 12.1161], [val: 16.6279], (fold: 2, id: 3) - [uo5bh9]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 13.2750], [val: 14.7386], (fold: 3, id: 4) - [lqwwo5]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 14.0754], [val: 16.4778], (fold: 4, id: 5) - [e38l33]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 12.8672], [val: 7.0688], (avg, id: 6) - [j75rz0]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 12.8190], [val: 6.9137], (w_avg, id: 7) - [w5or5p]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 6: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 25}, '_runtime_instance': PLSRegression(n_components=25)}, 'name': 'PLS-25'}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator PLSRegression\n",
      "üîç Model config: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 25}, '_runtime_instance': PLSRegression(n_components=25)}, 'name': 'PLS-25', 'model_instance': PLSRegression(n_components=25)}\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 12.9148], [val: 14.1517], (fold: 0, id: 1) - [9wdd0i]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 14.2084], [val: 20.5814], (fold: 1, id: 2) - [h69285]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 12.1161], [val: 16.6279], (fold: 2, id: 3) - [uo5bh9]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 13.2750], [val: 14.7386], (fold: 3, id: 4) - [lqwwo5]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 14.0754], [val: 16.4778], (fold: 4, id: 5) - [e38l33]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 12.8672], [val: 7.0688], (avg, id: 6) - [j75rz0]\n",
      "‚úÖ PLS-15 rmse ‚Üì [test: 12.8190], [val: 6.9137], (w_avg, id: 7) - [w5or5p]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 6: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 25}, '_runtime_instance': PLSRegression(n_components=25)}, 'name': 'PLS-25'}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator PLSRegression\n",
      "üîç Model config: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 25}, '_runtime_instance': PLSRegression(n_components=25)}, 'name': 'PLS-25', 'model_instance': PLSRegression(n_components=25)}\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 12.9204], [val: 14.1800], (fold: 0, id: 1) - [zwbacq]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 14.1853], [val: 20.5728], (fold: 1, id: 2) - [3xp81u]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 12.1178], [val: 16.6372], (fold: 2, id: 3) - [p38m55]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 13.2819], [val: 14.7421], (fold: 3, id: 4) - [xl1b4v]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 14.0558], [val: 16.4749], (fold: 4, id: 5) - [zoh3oc]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 12.8599], [val: 7.0690], (avg, id: 6) - [ei1wha]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 12.8134], [val: 6.9154], (w_avg, id: 7) - [p9huhx]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 7: {'model': {'class': 'sklearn.linear_model._coordinate_descent.ElasticNet', 'params': {'alpha': 0.1}, '_runtime_instance': ElasticNet(alpha=0.1)}, 'name': 'ElasticNet'}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator ElasticNet\n",
      "üîç Model config: {'model': {'class': 'sklearn.linear_model._coordinate_descent.ElasticNet', 'params': {'alpha': 0.1}, '_runtime_instance': ElasticNet(alpha=0.1)}, 'name': 'ElasticNet', 'model_instance': ElasticNet(alpha=0.1)}\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 12.9204], [val: 14.1800], (fold: 0, id: 1) - [zwbacq]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 14.1853], [val: 20.5728], (fold: 1, id: 2) - [3xp81u]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 12.1178], [val: 16.6372], (fold: 2, id: 3) - [p38m55]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 13.2819], [val: 14.7421], (fold: 3, id: 4) - [xl1b4v]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 14.0558], [val: 16.4749], (fold: 4, id: 5) - [zoh3oc]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 12.8599], [val: 7.0690], (avg, id: 6) - [ei1wha]\n",
      "‚úÖ PLS-25 rmse ‚Üì [test: 12.8134], [val: 6.9154], (w_avg, id: 7) - [p9huhx]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 7: {'model': {'class': 'sklearn.linear_model._coordinate_descent.ElasticNet', 'params': {'alpha': 0.1}, '_runtime_instance': ElasticNet(alpha=0.1)}, 'name': 'ElasticNet'}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator ElasticNet\n",
      "üîç Model config: {'model': {'class': 'sklearn.linear_model._coordinate_descent.ElasticNet', 'params': {'alpha': 0.1}, '_runtime_instance': ElasticNet(alpha=0.1)}, 'name': 'ElasticNet', 'model_instance': ElasticNet(alpha=0.1)}\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8710], [val: 24.4047], (fold: 0, id: 1) - [i9o3ig]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8989], [val: 25.9066], (fold: 1, id: 2) - [guutua]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.9099], [val: 26.4456], (fold: 2, id: 3) - [em2a8q]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8442], [val: 21.1666], (fold: 3, id: 4) - [gpij7w]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8795], [val: 24.0245], (fold: 4, id: 5) - [4dwejw]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8788], [val: 24.4454], (avg, id: 6) - [eykg7h]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8770], [val: 24.4442], (w_avg, id: 7) - [6wsm8z]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 8: {'model': {'class': 'sklearn.ensemble._forest.RandomForestRegressor', 'params': {'n_estimators': 50, 'max_depth': 8}, '_runtime_instance': RandomForestRegressor(max_depth=8, n_estimators=50)}, 'name': 'RandomForest'}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator RandomForestRegressor\n",
      "üîç Model config: {'model': {'class': 'sklearn.ensemble._forest.RandomForestRegressor', 'params': {'n_estimators': 50, 'max_depth': 8}, '_runtime_instance': RandomForestRegressor(max_depth=8, n_estimators=50)}, 'name': 'RandomForest', 'model_instance': RandomForestRegressor(max_depth=8, n_estimators=50)}\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8710], [val: 24.4047], (fold: 0, id: 1) - [i9o3ig]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8989], [val: 25.9066], (fold: 1, id: 2) - [guutua]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.9099], [val: 26.4456], (fold: 2, id: 3) - [em2a8q]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8442], [val: 21.1666], (fold: 3, id: 4) - [gpij7w]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8795], [val: 24.0245], (fold: 4, id: 5) - [4dwejw]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8788], [val: 24.4454], (avg, id: 6) - [eykg7h]\n",
      "‚úÖ ElasticNet rmse ‚Üì [test: 19.8770], [val: 24.4442], (w_avg, id: 7) - [6wsm8z]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 8: {'model': {'class': 'sklearn.ensemble._forest.RandomForestRegressor', 'params': {'n_estimators': 50, 'max_depth': 8}, '_runtime_instance': RandomForestRegressor(max_depth=8, n_estimators=50)}, 'name': 'RandomForest'}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator RandomForestRegressor\n",
      "üîç Model config: {'model': {'class': 'sklearn.ensemble._forest.RandomForestRegressor', 'params': {'n_estimators': 50, 'max_depth': 8}, '_runtime_instance': RandomForestRegressor(max_depth=8, n_estimators=50)}, 'name': 'RandomForest', 'model_instance': RandomForestRegressor(max_depth=8, n_estimators=50)}\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è  This may take several minutes due to neural network training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m runner \u001b[38;5;241m=\u001b[39m PipelineRunner(save_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m multi_predictions, predictions_per_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Multi-source analysis completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä Total predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(multi_predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:119\u001b[0m, in \u001b[0;36mPipelineRunner.run\u001b[1;34m(self, pipeline_configs, dataset_configs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dataset)\n\u001b[0;32m    118\u001b[0m config_predictions \u001b[38;5;241m=\u001b[39m Predictions()\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Merge new predictions into stores\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_predictions\u001b[38;5;241m.\u001b[39mnum_predictions \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:273\u001b[0m, in \u001b[0;36mPipelineRunner._run_single\u001b[1;34m(self, steps, config_name, dataset, config_predictions)\u001b[0m\n\u001b[0;32m    270\u001b[0m context \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m: [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m*\u001b[39m dataset\u001b[38;5;241m.\u001b[39mfeatures_sources(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequential\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaver\u001b[38;5;241m.\u001b[39msave_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, PipelineConfigs\u001b[38;5;241m.\u001b[39mserializable_steps(steps))\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:310\u001b[0m, in \u001b[0;36mPipelineRunner.run_steps\u001b[1;34m(self, steps, dataset, context, execution, prediction_store, is_substep, mode)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(context, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;66;03m# print(\"üîÑ Running steps sequentially with shared context\")\u001b[39;00m\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m--> 310\u001b[0m         context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_substep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_substep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;66;03m# print(f\"üîπ Updated context after step: {context}\")\u001b[39;00m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubstep_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Reset sub-step number after sequential execution\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:403\u001b[0m, in \u001b[0;36mPipelineRunner.run_step\u001b[1;34m(self, step, dataset, context, prediction_store, is_substep, propagated_binaries)\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîç Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(b[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mb\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mloaded_binaries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m binaries for step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    402\u001b[0m         context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_controller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_binaries\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# self.history.complete_step(step_execution.step_id)\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# Fail step\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;66;03m# self.history.fail_step(step_execution.step_id, str(e))\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:495\u001b[0m, in \u001b[0;36mPipelineRunner._execute_controller\u001b[1;34m(self, controller, step, operator, dataset, context, prediction_store, source, loaded_binaries)\u001b[0m\n\u001b[0;32m    482\u001b[0m         context, binaries \u001b[38;5;241m=\u001b[39m controller\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    483\u001b[0m             step,\n\u001b[0;32m    484\u001b[0m             operator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m             prediction_store\n\u001b[0;32m    492\u001b[0m         )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;66;03m# Execute without spinner\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     context, binaries \u001b[38;5;241m=\u001b[39m \u001b[43mcontroller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_binaries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction_store\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# Always show final score for model controllers when verbose=0\u001b[39;00m\n\u001b[0;32m    508\u001b[0m is_model_controller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m controller_name\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_model.py:268\u001b[0m, in \u001b[0;36mSklearnModelController.execute\u001b[1;34m(self, step, operator, dataset, context, runner, source, mode, loaded_binaries, prediction_store)\u001b[0m\n\u001b[0;32m    265\u001b[0m context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_preferred_layout()\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# Call parent execute method\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_binaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_store\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py:165\u001b[0m, in \u001b[0;36mBaseModelController.execute\u001b[1;34m(self, step, operator, dataset, context, runner, source, mode, loaded_binaries, prediction_store)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müèãÔ∏è Starting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m     binaries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_unscaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_unscaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_binaries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloaded_binaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context, binaries\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py:249\u001b[0m, in \u001b[0;36mBaseModelController.train\u001b[1;34m(self, dataset, model_config, context, runner, prediction_store, X_train, y_train, X_test, y_test, y_train_unscaled, y_test_unscaled, folds, best_params, loaded_binaries, mode)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     best_params_fold \u001b[38;5;241m=\u001b[39m best_params\n\u001b[1;32m--> 249\u001b[0m model, model_id, score, model_name, prediction_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_fold_unscaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold_unscaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_unscaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest_params_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloaded_binaries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloaded_binaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m folds_models\u001b[38;5;241m.\u001b[39mappend((model_id, model, score))\n\u001b[0;32m    258\u001b[0m all_fold_predictions\u001b[38;5;241m.\u001b[39mappend(prediction_data)\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py:356\u001b[0m, in \u001b[0;36mBaseModelController.launch_training\u001b[1;34m(self, dataset, model_config, context, runner, prediction_store, X_train, y_train, X_val, y_val, X_test, y_train_unscaled, y_val_unscaled, y_test_unscaled, train_indices, val_indices, fold_idx, best_params, loaded_binaries, mode)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# if self.verbose > 0:\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# print(\"üöÄ Training model...\")\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# print(\"Dataset:\", dataset_name, \"Shape:\", X_train.shape)\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 356\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_model(model, X_train_prep, y_train_prep, X_val_prep, y_val_prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_params\u001b[39m\u001b[38;5;124m'\u001b[39m, {}))\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_model.py:126\u001b[0m, in \u001b[0;36mSklearnModelController._train_model\u001b[1;34m(self, model, X_train, y_train, X_val, y_val, train_params)\u001b[0m\n\u001b[0;32m    123\u001b[0m         trained_model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalid_params)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[43mtrained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure y is 1D for sklearn\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Always calculate and display final test scores, regardless of verbose level\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# But control the detail level based on verbose\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    475\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    478\u001b[0m ]\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\joblib\\parallel.py:1985\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1983\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1984\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\joblib\\parallel.py:1913\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1913\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    197\u001b[0m         X,\n\u001b[0;32m    198\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configure multi-source dataset (multiple targets)\n",
    "multi_source_data = 'sample_data/multi'  # Single dataset with multiple target variables\n",
    "multi_config = PipelineConfigs(multi_source_pipeline, \"Advanced_MultiSource\")\n",
    "dataset_config = DatasetConfigs(multi_source_data)\n",
    "\n",
    "print(f\"üèÉ‚Äç‚ôÇÔ∏è Running multi-source analysis (multi-target regression)...\")\n",
    "print(\"‚ö†Ô∏è  This may take several minutes due to neural network training\")\n",
    "\n",
    "runner = PipelineRunner(save_files=False, verbose=1)\n",
    "multi_predictions, predictions_per_dataset = runner.run(multi_config, dataset_config)\n",
    "\n",
    "print(f\"‚úÖ Multi-source analysis completed!\")\n",
    "print(f\"üìä Total predictions: {len(multi_predictions)}\")\n",
    "print(f\"üìÅ Multi-source results: {len(predictions_per_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee170af7",
   "metadata": {},
   "source": [
    "### Step 1.4: Analyze Multi-Source Results\n",
    "\n",
    "Let's examine how models perform across different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048bc1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Multi-Source Analysis Results:\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predictions_per_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Check if we have multi-target results\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpredictions_per_dataset\u001b[49m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m source_name, source_result \u001b[38;5;129;01min\u001b[39;00m predictions_per_dataset\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      8\u001b[0m         source_predictions \u001b[38;5;241m=\u001b[39m source_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_predictions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions_per_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Analyze multi-target results\n",
    "print(\"üìä Multi-Source Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if we have multi-target results\n",
    "if predictions_per_dataset:\n",
    "    for source_name, source_result in predictions_per_dataset.items():\n",
    "        source_predictions = source_result['run_predictions']\n",
    "        top_3 = source_predictions.top_k(3, 'rmse')\n",
    "\n",
    "        print(f\"\\nüéØ Multi-Source Data: {source_name}\")\n",
    "        print(f\"   Total predictions: {len(source_predictions)}\")\n",
    "        print(\"   Top 3 models for multi-target regression:\")\n",
    "\n",
    "        for idx, model in enumerate(top_3):\n",
    "            preprocessing = model['preprocessings'] if model['preprocessings'] else 'None'\n",
    "            print(f\"     {idx+1}. {model['model_name']} | RMSE: {model['rmse']:.4f} | R¬≤: {model['r2']:.4f}\")\n",
    "            print(f\"        Preprocessing: {preprocessing}\")\n",
    "            # Check if this model handles multiple targets\n",
    "            if hasattr(model.get('y_pred', []), 'shape') and len(model['y_pred'].shape) > 1:\n",
    "                print(f\"        Target dimensions: {model['y_pred'].shape}\")\n",
    "\n",
    "# Overall multi-target analysis\n",
    "print(\"\\nüèÜ Best Multi-Target Models:\")\n",
    "overall_top = multi_predictions.top_k(5, 'rmse')\n",
    "for idx, model in enumerate(overall_top):\n",
    "    print(f\"{idx+1}. {model['model_name']} | RMSE: {model['rmse']:.4f} | R¬≤: {model['r2']:.4f}\")\n",
    "    if 'dataset_name' in model:\n",
    "        print(f\"    Source: {model['dataset_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed5168",
   "metadata": {},
   "source": [
    "### Step 1.5: Multi-Source Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-source visualizations\n",
    "multi_analyzer = PredictionAnalyzer(multi_predictions)\n",
    "\n",
    "# 1. Performance across preprocessing methods\n",
    "print(\"üìä Creating visualization 1/3: Models vs Preprocessing\")\n",
    "fig1 = multi_analyzer.plot_variable_heatmap(\n",
    "    x_var=\"model_name\",\n",
    "    y_var=\"preprocessings\",\n",
    "    metric='rmse'\n",
    ")\n",
    "plt.title(\"Multi-Target Performance: Models vs Preprocessing\")\n",
    "\n",
    "# 2. Top models comparison\n",
    "print(\"üìä Creating visualization 2/3: Top Models Comparison\")\n",
    "fig2 = multi_analyzer.plot_top_k_comparison(k=8, metric='rmse')\n",
    "plt.title(\"Top 8 Multi-Target Models\")\n",
    "\n",
    "# 3. Performance distribution\n",
    "print(\"üìä Creating visualization 3/3: Performance Distribution\")\n",
    "fig3 = multi_analyzer.plot_variable_candlestick(\n",
    "    filters={\"partition\": \"test\"},\n",
    "    variable=\"model_name\"\n",
    ")\n",
    "plt.title(\"Multi-Target Model Performance Distribution\")\n",
    "\n",
    "plt.show()\n",
    "print(\"üé® Multi-source visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ec0bb",
   "metadata": {},
   "source": [
    "## Part 2: Hyperparameter Optimization with Optuna\n",
    "\n",
    "NIRS4All integrates with Optuna for sophisticated hyperparameter optimization. Let's optimize PLS and neural network models:\n",
    "\n",
    "### Step 2.1: Configure Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fa5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization pipeline\n",
    "optimization_pipeline = [\n",
    "    \"chart_2d\",\n",
    "    MinMaxScaler(),\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "\n",
    "    # Feature augmentation for optimization\n",
    "    {\"feature_augmentation\": {\n",
    "        \"_or_\": [\n",
    "            StandardNormalVariate(),\n",
    "            SavitzkyGolay(),\n",
    "            MultiplicativeScatterCorrection(),\n",
    "            Gaussian()\n",
    "        ],\n",
    "        \"size\": [1, 2],\n",
    "        \"count\": 4\n",
    "    }},\n",
    "\n",
    "    ShuffleSplit(n_splits=3, test_size=0.25),\n",
    "\n",
    "    # PLS with hyperparameter optimization\n",
    "    {\n",
    "        \"model\": PLSRegression(),\n",
    "        \"name\": \"OptimizedPLS\",\n",
    "        \"finetune_params\": {\n",
    "            \"n_trials\": 30,\n",
    "            \"verbose\": 2,\n",
    "            \"approach\": \"single\",\n",
    "            \"eval_mode\": \"best\",\n",
    "            \"sample\": \"tpe\",  # Tree-structured Parzen Estimator\n",
    "            \"model_params\": {\n",
    "                'n_components': ('int', 5, 30),\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Neural network with hyperparameter optimization\n",
    "    {\n",
    "        \"model\": customizable_nicon,\n",
    "        \"name\": \"OptimizedNeuralNet\",\n",
    "        \"finetune_params\": {\n",
    "            \"n_trials\": 20,\n",
    "            \"verbose\": 2,\n",
    "            \"sample\": \"hyperband\",\n",
    "            \"approach\": \"single\",\n",
    "            \"model_params\": {\n",
    "                \"filters_1\": [16, 32, 64, 128],\n",
    "                \"filters_2\": [16, 32, 64, 128],\n",
    "                \"filters_3\": [16, 32, 64, 128]\n",
    "            },\n",
    "            \"train_params\": {\n",
    "                \"epochs\": 20,\n",
    "                \"verbose\": 0\n",
    "            }\n",
    "        },\n",
    "        \"train_params\": {\n",
    "            \"epochs\": 100,\n",
    "            \"patience\": 15,\n",
    "            \"verbose\": 0\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Add baseline models for comparison\n",
    "for n_comp in [10, 15, 20]:\n",
    "    optimization_pipeline.append({\n",
    "        \"model\": PLSRegression(n_components=n_comp),\n",
    "        \"name\": f\"Baseline-PLS-{n_comp}\"\n",
    "    })\n",
    "\n",
    "print(\"üéØ Hyperparameter optimization pipeline configured:\")\n",
    "print(\"   ‚Ä¢ PLS optimization: 30 trials (n_components: 5-30)\")\n",
    "print(\"   ‚Ä¢ Neural net optimization: 20 trials (filter sizes)\")\n",
    "print(\"   ‚Ä¢ 3 baseline PLS models for comparison\")\n",
    "print(\"   ‚Ä¢ 4 preprocessing combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c169741",
   "metadata": {},
   "source": [
    "### Step 2.2: Run Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "opt_config = PipelineConfigs(optimization_pipeline, \"Advanced_Optimization\")\n",
    "dataset_config = DatasetConfigs('sample_data/regression')\n",
    "\n",
    "print(\"üéØ Starting hyperparameter optimization...\")\n",
    "print(\"‚ö†Ô∏è  This will take several minutes - Optuna is testing many configurations\")\n",
    "print(\"üìä Watch the verbose output to see optimization progress\")\n",
    "\n",
    "runner = PipelineRunner(save_files=True, verbose=1)  # Save optimized models\n",
    "opt_predictions, _ = runner.run(opt_config, dataset_config)\n",
    "\n",
    "print(f\"‚úÖ Hyperparameter optimization completed!\")\n",
    "print(f\"üîç Total configurations tested: {len(opt_predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf9dab",
   "metadata": {},
   "source": [
    "### Step 2.3: Analyze Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare optimized vs baseline models\n",
    "opt_top = opt_predictions.top_k(8, 'rmse')\n",
    "\n",
    "print(\"üèÜ Top Models After Optimization:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "optimized_models = []\n",
    "baseline_models = []\n",
    "\n",
    "for idx, model in enumerate(opt_top):\n",
    "    model_type = \"üéØ OPTIMIZED\" if \"Optimized\" in model['model_name'] else \"üìä Baseline\"\n",
    "    preprocessing = model['preprocessings'] if model['preprocessings'] else 'None'\n",
    "\n",
    "    print(f\"{idx+1}. {model_type} | {model['model_name']}\")\n",
    "    print(f\"    RMSE: {model['rmse']:.4f} | R¬≤: {model['r2']:.4f} | MAE: {model['mae']:.4f}\")\n",
    "    print(f\"    Preprocessing: {preprocessing}\")\n",
    "    print()\n",
    "\n",
    "    if \"Optimized\" in model['model_name']:\n",
    "        optimized_models.append(model)\n",
    "    else:\n",
    "        baseline_models.append(model)\n",
    "\n",
    "# Calculate improvement\n",
    "if optimized_models and baseline_models:\n",
    "    best_optimized = min(optimized_models, key=lambda x: x['rmse'])\n",
    "    best_baseline = min(baseline_models, key=lambda x: x['rmse'])\n",
    "\n",
    "    improvement = ((best_baseline['rmse'] - best_optimized['rmse']) / best_baseline['rmse']) * 100\n",
    "    print(f\"üìà Optimization Improvement: {improvement:.2f}% RMSE reduction\")\n",
    "    print(f\"   Best Optimized: {best_optimized['rmse']:.4f} RMSE\")\n",
    "    print(f\"   Best Baseline: {best_baseline['rmse']:.4f} RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50fa512",
   "metadata": {},
   "source": [
    "### Step 2.4: Optimization Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimization-focused visualizations\n",
    "opt_analyzer = PredictionAnalyzer(opt_predictions)\n",
    "\n",
    "# 1. Optimized vs Baseline comparison\n",
    "print(\"üìä Creating optimization visualizations...\")\n",
    "\n",
    "fig1 = opt_analyzer.plot_top_k_comparison(k=8, metric='rmse')\n",
    "plt.title(\"Hyperparameter Optimization Results\")\n",
    "\n",
    "# 2. Model performance heatmap\n",
    "fig2 = opt_analyzer.plot_variable_heatmap(\n",
    "    x_var=\"model_name\",\n",
    "    y_var=\"preprocessings\",\n",
    "    metric='rmse',\n",
    "    best_only=False\n",
    ")\n",
    "plt.title(\"Optimization: Models vs Preprocessing\")\n",
    "\n",
    "plt.show()\n",
    "print(\"üé® Optimization visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302769f",
   "metadata": {},
   "source": [
    "## Part 3: Custom Models and Transformers\n",
    "\n",
    "NIRS4All allows you to integrate custom models and transformers into your pipelines. Let's create custom components:\n",
    "\n",
    "### Step 3.1: Create a Custom Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class CustomSpectralNormalizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer that applies area normalization to spectral data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method='area'):\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # For transformers, fit usually just returns self\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.array(X)\n",
    "\n",
    "        if self.method == 'area':\n",
    "            # Normalize by area under the curve\n",
    "            areas = np.trapz(X, axis=1, dx=1.0)\n",
    "            # Avoid division by zero\n",
    "            areas = np.where(areas == 0, 1, areas)\n",
    "            X_normalized = X / areas[:, np.newaxis]\n",
    "\n",
    "        elif self.method == 'max':\n",
    "            # Normalize by maximum value\n",
    "            max_vals = np.max(X, axis=1)\n",
    "            max_vals = np.where(max_vals == 0, 1, max_vals)\n",
    "            X_normalized = X / max_vals[:, np.newaxis]\n",
    "\n",
    "        elif self.method == 'l2':\n",
    "            # L2 normalization\n",
    "            norms = np.linalg.norm(X, axis=1)\n",
    "            norms = np.where(norms == 0, 1, norms)\n",
    "            X_normalized = X / norms[:, np.newaxis]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown normalization method: {self.method}\")\n",
    "\n",
    "        return X_normalized\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        # Required for newer sklearn versions\n",
    "        if input_features is None:\n",
    "            return np.array([f\"feature_{i}\" for i in range(self.n_features_in_)])\n",
    "        return input_features\n",
    "\n",
    "print(\"‚úÖ Custom transformer created: CustomSpectralNormalizer\")\n",
    "print(\"   ‚Ä¢ Methods: 'area', 'max', 'l2'\")\n",
    "print(\"   ‚Ä¢ Follows sklearn TransformerMixin pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c15dc3",
   "metadata": {},
   "source": [
    "### Step 3.2: Create a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253eb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class CustomPCARegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Custom model that combines PCA dimensionality reduction with Ridge regression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components=10, ridge_alpha=1.0):\n",
    "        self.n_components = n_components\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Store the classes_ attribute for compatibility\n",
    "        if hasattr(y, 'shape') and len(y.shape) > 1 and y.shape[1] > 1:\n",
    "            self.n_outputs_ = y.shape[1]\n",
    "        else:\n",
    "            self.n_outputs_ = 1\n",
    "\n",
    "        # Initialize and fit PCA\n",
    "        self.pca_ = PCA(n_components=self.n_components)\n",
    "        X_pca = self.pca_.fit_transform(X)\n",
    "\n",
    "        # Initialize and fit Ridge regression\n",
    "        self.ridge_ = Ridge(alpha=self.ridge_alpha)\n",
    "        self.ridge_.fit(X_pca, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Transform with PCA then predict with Ridge\n",
    "        X_pca = self.pca_.transform(X)\n",
    "        return self.ridge_.predict(X_pca)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_components': self.n_components,\n",
    "            'ridge_alpha': self.ridge_alpha\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "\n",
    "print(\"‚úÖ Custom model created: CustomPCARegressor\")\n",
    "print(\"   ‚Ä¢ Combines PCA + Ridge regression\")\n",
    "print(\"   ‚Ä¢ Hyperparameters: n_components, ridge_alpha\")\n",
    "print(\"   ‚Ä¢ Follows sklearn RegressorMixin pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e6d008",
   "metadata": {},
   "source": [
    "### Step 3.3: Test Custom Components in Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with custom components\n",
    "custom_pipeline = [\n",
    "    MinMaxScaler(),\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "\n",
    "    # Use our custom transformer\n",
    "    CustomSpectralNormalizer(method='area'),\n",
    "\n",
    "    # Add some standard preprocessing for comparison\n",
    "    {\"feature_augmentation\": {\n",
    "        \"_or_\": [\n",
    "            StandardNormalVariate(),\n",
    "            SavitzkyGolay(),\n",
    "            CustomSpectralNormalizer(method='max'),  # Another custom transformer\n",
    "            CustomSpectralNormalizer(method='l2')\n",
    "        ],\n",
    "        \"size\": [1, 2],\n",
    "        \"count\": 3\n",
    "    }},\n",
    "\n",
    "    ShuffleSplit(n_splits=3, test_size=0.25),\n",
    "\n",
    "    # Standard models\n",
    "    {\"model\": PLSRegression(15), \"name\": \"StandardPLS\"},\n",
    "\n",
    "    # Our custom model\n",
    "    {\"model\": CustomPCARegressor(n_components=12, ridge_alpha=0.1), \"name\": \"CustomPCA-Ridge\"},\n",
    "    {\"model\": CustomPCARegressor(n_components=20, ridge_alpha=1.0), \"name\": \"CustomPCA-Ridge-L2\"},\n",
    "]\n",
    "\n",
    "print(\"üîß Custom pipeline configured with:\")\n",
    "print(\"   ‚Ä¢ Custom spectral normalization transformer\")\n",
    "print(\"   ‚Ä¢ Custom PCA+Ridge regression model\")\n",
    "print(\"   ‚Ä¢ Mixed with standard NIRS4All components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b8fcb4",
   "metadata": {},
   "source": [
    "### Step 3.4: Run Custom Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45117583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run custom pipeline\n",
    "custom_config = PipelineConfigs(custom_pipeline, \"Advanced_Custom\")\n",
    "dataset_config = DatasetConfigs('sample_data/regression')\n",
    "\n",
    "print(\"üèÉ‚Äç‚ôÇÔ∏è Running pipeline with custom components...\")\n",
    "runner = PipelineRunner(save_files=False, verbose=1)\n",
    "custom_predictions, _ = runner.run(custom_config, dataset_config)\n",
    "\n",
    "print(f\"‚úÖ Custom pipeline completed!\")\n",
    "print(f\"üìä Generated {len(custom_predictions)} predictions\")\n",
    "\n",
    "# Analyze custom results\n",
    "top_custom = custom_predictions.top_k(5, 'rmse')\n",
    "print(\"\\nüèÜ Top 5 Models (Including Custom):\")\n",
    "for idx, model in enumerate(top_custom):\n",
    "    model_type = \"üîß CUSTOM\" if \"Custom\" in model['model_name'] else \"üìä Standard\"\n",
    "    preprocessing = model['preprocessings'] if model['preprocessings'] else 'None'\n",
    "    print(f\"{idx+1}. {model_type} | {model['model_name']}\")\n",
    "    print(f\"    RMSE: {model['rmse']:.4f} | R¬≤: {model['r2']:.4f}\")\n",
    "    print(f\"    Preprocessing: {preprocessing}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46c3b7",
   "metadata": {},
   "source": [
    "### Step 3.5: Visualize Custom Component Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom component analysis\n",
    "custom_analyzer = PredictionAnalyzer(custom_predictions)\n",
    "\n",
    "# Compare custom vs standard models\n",
    "fig1 = custom_analyzer.plot_top_k_comparison(k=6, metric='rmse')\n",
    "plt.title(\"Custom vs Standard Models Performance\")\n",
    "\n",
    "# Show preprocessing effects including custom transformers\n",
    "fig2 = custom_analyzer.plot_variable_heatmap(\n",
    "    x_var=\"model_name\",\n",
    "    y_var=\"preprocessings\",\n",
    "    metric='rmse',\n",
    "    best_only=False\n",
    ")\n",
    "plt.title(\"Custom Components: Models vs Preprocessing\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"üé® Custom component visualizations completed!\")\n",
    "print(\"üí° Custom components successfully integrated into NIRS4All pipeline!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom component analysis\n",
    "custom_analyzer = PredictionAnalyzer(custom_predictions)\n",
    "\n",
    "# Compare custom vs standard models\n",
    "fig1 = custom_analyzer.plot_top_k_comparison(k=6, metric='rmse')\n",
    "plt.title(\"Custom vs Standard Models Performance\")\n",
    "\n",
    "# Show preprocessing effects including custom transformers\n",
    "fig2 = custom_analyzer.plot_variable_heatmap(\n",
    "    x_var=\"model_name\",\n",
    "    y_var=\"preprocessings\",\n",
    "    metric='rmse',\n",
    "    best_only=False\n",
    ")\n",
    "plt.title(\"Custom Components: Models vs Preprocessing\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"üé® Custom component visualizations completed!\")\n",
    "print(\"üí° Custom components successfully integrated into NIRS4All pipeline!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df6ba8",
   "metadata": {},
   "source": [
    "### Step 3.5: Visualize Custom Component Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c702ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run custom pipeline\n",
    "custom_config = PipelineConfigs(custom_pipeline, \"Advanced_Custom\")\n",
    "dataset_config = DatasetConfigs('sample_data/regression')\n",
    "\n",
    "print(\"üèÉ‚Äç‚ôÇÔ∏è Running pipeline with custom components...\")\n",
    "runner = PipelineRunner(save_files=False, verbose=1)\n",
    "custom_predictions, _ = runner.run(custom_config, dataset_config)\n",
    "\n",
    "print(f\"‚úÖ Custom pipeline completed!\")\n",
    "print(f\"üìä Generated {len(custom_predictions)} predictions\")\n",
    "\n",
    "# Analyze custom results\n",
    "top_custom = custom_predictions.top_k(5, 'rmse')\n",
    "print(\"\\nüèÜ Top 5 Models (Including Custom):\")\n",
    "for idx, model in enumerate(top_custom):\n",
    "    model_type = \"üîß CUSTOM\" if \"Custom\" in model['model_name'] else \"üìä Standard\"\n",
    "    preprocessing = model['preprocessings'] if model['preprocessings'] else 'None'\n",
    "    print(f\"{idx+1}. {model_type} | {model['model_name']}\")\n",
    "    print(f\"    RMSE: {model['rmse']:.4f} | R¬≤: {model['r2']:.4f}\")\n",
    "    print(f\"    Preprocessing: {preprocessing}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556f694",
   "metadata": {},
   "source": [
    "### Step 3.4: Run Custom Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baecfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with custom components\n",
    "custom_pipeline = [\n",
    "    MinMaxScaler(),\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "\n",
    "    # Use our custom transformer\n",
    "    CustomSpectralNormalizer(method='area'),\n",
    "\n",
    "    # Add some standard preprocessing for comparison\n",
    "    {\"feature_augmentation\": {\n",
    "        \"_or_\": [\n",
    "            StandardNormalVariate(),\n",
    "            SavitzkyGolay(),\n",
    "            CustomSpectralNormalizer(method='max'),  # Another custom transformer\n",
    "            CustomSpectralNormalizer(method='l2')\n",
    "        ],\n",
    "        \"size\": [1, 2],\n",
    "        \"count\": 3\n",
    "    }},\n",
    "\n",
    "    ShuffleSplit(n_splits=3, test_size=0.25),\n",
    "\n",
    "    # Standard models\n",
    "    {\"model\": PLSRegression(15), \"name\": \"StandardPLS\"},\n",
    "\n",
    "    # Our custom model\n",
    "    {\"model\": CustomPCARegressor(n_components=12, ridge_alpha=0.1), \"name\": \"CustomPCA-Ridge\"},\n",
    "    {\"model\": CustomPCARegressor(n_components=20, ridge_alpha=1.0), \"name\": \"CustomPCA-Ridge-L2\"},\n",
    "]\n",
    "\n",
    "print(\"üîß Custom pipeline configured with:\")\n",
    "print(\"   ‚Ä¢ Custom spectral normalization transformer\")\n",
    "print(\"   ‚Ä¢ Custom PCA+Ridge regression model\")\n",
    "print(\"   ‚Ä¢ Mixed with standard NIRS4All components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da191c",
   "metadata": {},
   "source": [
    "### Step 3.3: Test Custom Components in Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class CustomPCARegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Custom model that combines PCA dimensionality reduction with Ridge regression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components=10, ridge_alpha=1.0):\n",
    "        self.n_components = n_components\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Store the classes_ attribute for compatibility\n",
    "        if hasattr(y, 'shape') and len(y.shape) > 1 and y.shape[1] > 1:\n",
    "            self.n_outputs_ = y.shape[1]\n",
    "        else:\n",
    "            self.n_outputs_ = 1\n",
    "\n",
    "        # Initialize and fit PCA\n",
    "        self.pca_ = PCA(n_components=self.n_components)\n",
    "        X_pca = self.pca_.fit_transform(X)\n",
    "\n",
    "        # Initialize and fit Ridge regression\n",
    "        self.ridge_ = Ridge(alpha=self.ridge_alpha)\n",
    "        self.ridge_.fit(X_pca, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Transform with PCA then predict with Ridge\n",
    "        X_pca = self.pca_.transform(X)\n",
    "        return self.ridge_.predict(X_pca)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_components': self.n_components,\n",
    "            'ridge_alpha': self.ridge_alpha\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "\n",
    "print(\"‚úÖ Custom model created: CustomPCARegressor\")\n",
    "print(\"   ‚Ä¢ Combines PCA + Ridge regression\")\n",
    "print(\"   ‚Ä¢ Hyperparameters: n_components, ridge_alpha\")\n",
    "print(\"   ‚Ä¢ Follows sklearn RegressorMixin pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac338d6",
   "metadata": {},
   "source": [
    "### Step 3.2: Create a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class CustomSpectralNormalizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer that applies area normalization to spectral data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method='area'):\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # For transformers, fit usually just returns self\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.array(X)\n",
    "\n",
    "        if self.method == 'area':\n",
    "            # Normalize by area under the curve\n",
    "            areas = np.trapz(X, axis=1, dx=1.0)\n",
    "            # Avoid division by zero\n",
    "            areas = np.where(areas == 0, 1, areas)\n",
    "            X_normalized = X / areas[:, np.newaxis]\n",
    "\n",
    "        elif self.method == 'max':\n",
    "            # Normalize by maximum value\n",
    "            max_vals = np.max(X, axis=1)\n",
    "            max_vals = np.where(max_vals == 0, 1, max_vals)\n",
    "            X_normalized = X / max_vals[:, np.newaxis]\n",
    "\n",
    "        elif self.method == 'l2':\n",
    "            # L2 normalization\n",
    "            norms = np.linalg.norm(X, axis=1)\n",
    "            norms = np.where(norms == 0, 1, norms)\n",
    "            X_normalized = X / norms[:, np.newaxis]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown normalization method: {self.method}\")\n",
    "\n",
    "        return X_normalized\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        # Required for newer sklearn versions\n",
    "        if input_features is None:\n",
    "            return np.array([f\"feature_{i}\" for i in range(self.n_features_in_)])\n",
    "        return input_features\n",
    "\n",
    "print(\"‚úÖ Custom transformer created: CustomSpectralNormalizer\")\n",
    "print(\"   ‚Ä¢ Methods: 'area', 'max', 'l2'\")\n",
    "print(\"   ‚Ä¢ Follows sklearn TransformerMixin pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7486a73",
   "metadata": {},
   "source": [
    "## Part 3: Custom Models and Transformers\n",
    "\n",
    "NIRS4All allows you to integrate custom models and transformers into your pipelines. Let's create custom components:\n",
    "\n",
    "### Step 3.1: Create a Custom Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9464b",
   "metadata": {},
   "source": [
    "## Part 4: Advanced Configuration Generation\n",
    "\n",
    "Let's explore advanced pipeline configuration techniques for complex workflows:\n",
    "\n",
    "### Step 4.1: Dynamic Pipeline Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced configuration generation function\n",
    "def create_advanced_pipeline(complexity_level=\"medium\", include_neural_nets=True, custom_preprocessing=None):\n",
    "    \"\"\"\n",
    "    Generate dynamic pipelines based on complexity requirements\n",
    "\n",
    "    Args:\n",
    "        complexity_level: 'simple', 'medium', 'complex'\n",
    "        include_neural_nets: Whether to include deep learning models\n",
    "        custom_preprocessing: List of custom preprocessing techniques\n",
    "    \"\"\"\n",
    "\n",
    "    # Base pipeline\n",
    "    pipeline = []\n",
    "\n",
    "    # Visualization based on complexity\n",
    "    if complexity_level in ['medium', 'complex']:\n",
    "        pipeline.append(\"chart_2d\")\n",
    "\n",
    "    # Scaling\n",
    "    if complexity_level == 'simple':\n",
    "        pipeline.append(MinMaxScaler())\n",
    "    else:\n",
    "        pipeline.append(MinMaxScaler(feature_range=(0.1, 0.9)))\n",
    "\n",
    "    # Target processing\n",
    "    pipeline.append({\"y_processing\": MinMaxScaler()})\n",
    "\n",
    "    # Preprocessing based on complexity\n",
    "    if custom_preprocessing:\n",
    "        preprocessing_options = custom_preprocessing\n",
    "    elif complexity_level == 'simple':\n",
    "        preprocessing_options = [StandardNormalVariate(), SavitzkyGolay()]\n",
    "    elif complexity_level == 'medium':\n",
    "        preprocessing_options = [\n",
    "            StandardNormalVariate(), SavitzkyGolay(),\n",
    "            MultiplicativeScatterCorrection(), Gaussian()\n",
    "        ]\n",
    "    else:  # complex\n",
    "        preprocessing_options = [\n",
    "            StandardNormalVariate(), SavitzkyGolay(),\n",
    "            MultiplicativeScatterCorrection(), Gaussian(),\n",
    "            Detrend(), FirstDerivative(), Haar()\n",
    "        ]\n",
    "\n",
    "    # Feature augmentation configuration\n",
    "    if complexity_level == 'simple':\n",
    "        augmentation_config = {\"_or_\": preprocessing_options, \"size\": [1], \"count\": 2}\n",
    "    elif complexity_level == 'medium':\n",
    "        augmentation_config = {\"_or_\": preprocessing_options, \"size\": [1, 2], \"count\": 4}\n",
    "    else:  # complex\n",
    "        augmentation_config = {\"_or_\": preprocessing_options, \"size\": [1, (1, 2), (2, 3)], \"count\": 6}\n",
    "\n",
    "    pipeline.append({\"feature_augmentation\": augmentation_config})\n",
    "\n",
    "    # Cross-validation\n",
    "    if complexity_level == 'simple':\n",
    "        pipeline.append(ShuffleSplit(n_splits=3, test_size=0.25))\n",
    "    elif complexity_level == 'medium':\n",
    "        pipeline.append(ShuffleSplit(n_splits=5, test_size=0.2))\n",
    "    else:  # complex\n",
    "        pipeline.append(RepeatedKFold(n_splits=5, n_repeats=2, random_state=42))\n",
    "\n",
    "    # Models based on complexity\n",
    "    if complexity_level == 'simple':\n",
    "        models = [\n",
    "            {\"model\": PLSRegression(10), \"name\": \"PLS-10\"},\n",
    "            {\"model\": PLSRegression(15), \"name\": \"PLS-15\"}\n",
    "        ]\n",
    "    elif complexity_level == 'medium':\n",
    "        models = [\n",
    "            {\"model\": PLSRegression(10), \"name\": \"PLS-10\"},\n",
    "            {\"model\": PLSRegression(20), \"name\": \"PLS-20\"},\n",
    "            {\"model\": ElasticNet(), \"name\": \"ElasticNet\"},\n",
    "            {\"model\": RandomForestRegressor(n_estimators=50), \"name\": \"RandomForest\"}\n",
    "        ]\n",
    "    else:  # complex\n",
    "        models = [\n",
    "            {\"model\": PLSRegression(15), \"name\": \"PLS-15\"},\n",
    "            {\"model\": PLSRegression(25), \"name\": \"PLS-25\"},\n",
    "            {\"model\": ElasticNet(alpha=0.1), \"name\": \"ElasticNet\"},\n",
    "            {\"model\": RandomForestRegressor(n_estimators=100), \"name\": \"RandomForest\"},\n",
    "            {\"model\": GradientBoostingRegressor(n_estimators=50), \"name\": \"GradientBoosting\"},\n",
    "            {\"model\": SVR(kernel='rbf'), \"name\": \"SVR\"}\n",
    "        ]\n",
    "\n",
    "    # Add neural networks if requested\n",
    "    if include_neural_nets and complexity_level in ['medium', 'complex']:\n",
    "        if complexity_level == 'medium':\n",
    "            models.append({\n",
    "                \"model\": nicon,\n",
    "                \"name\": \"SimpleNeuralNet\",\n",
    "                \"train_params\": {\"epochs\": 50, \"verbose\": 0}\n",
    "            })\n",
    "        else:  # complex\n",
    "            models.append({\n",
    "                \"model\": nicon,\n",
    "                \"name\": \"DeepNeuralNet\",\n",
    "                \"train_params\": {\"epochs\": 150, \"patience\": 20, \"verbose\": 0}\n",
    "            })\n",
    "\n",
    "    pipeline.extend(models)\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "# Generate different complexity pipelines\n",
    "simple_config = create_advanced_pipeline(\"simple\", include_neural_nets=False)\n",
    "medium_config = create_advanced_pipeline(\"medium\", include_neural_nets=True)\n",
    "complex_config = create_advanced_pipeline(\"complex\", include_neural_nets=True)\n",
    "\n",
    "print(\"üîß Dynamic pipeline generation completed:\")\n",
    "print(f\"   ‚Ä¢ Simple pipeline: {len([x for x in simple_config if 'model' in str(x)])} models\")\n",
    "print(f\"   ‚Ä¢ Medium pipeline: {len([x for x in medium_config if 'model' in str(x)])} models\")\n",
    "print(f\"   ‚Ä¢ Complex pipeline: {len([x for x in complex_config if 'model' in str(x)])} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b908d",
   "metadata": {},
   "source": [
    "### Step 3.2: Run Dynamic Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d567e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the medium complexity configuration\n",
    "print(\"üèÉ‚Äç‚ôÇÔ∏è Testing medium complexity configuration...\")\n",
    "\n",
    "dynamic_config = PipelineConfigs(medium_config, \"Advanced_Dynamic\")\n",
    "dataset_config = DatasetConfigs('sample_data/regression')\n",
    "\n",
    "runner = PipelineRunner(save_files=False, verbose=1)\n",
    "dynamic_predictions, _ = runner.run(dynamic_config, dataset_config)\n",
    "\n",
    "print(f\"‚úÖ Dynamic configuration completed!\")\n",
    "print(f\"üìä Generated {len(dynamic_predictions)} predictions\")\n",
    "\n",
    "# Quick analysis\n",
    "top_dynamic = dynamic_predictions.top_k(5, 'rmse')\n",
    "print(\"\\nüèÜ Top 5 Models from Dynamic Configuration:\")\n",
    "for idx, model in enumerate(top_dynamic):\n",
    "    print(f\"{idx+1}. {model['model_name']} | RMSE: {model['rmse']:.4f} | R¬≤: {model['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680f8ce",
   "metadata": {},
   "source": [
    "### Step 4.2: Run Dynamic Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_analysis(predictions, title=\"Advanced NIRS Analysis\"):\n",
    "    \"\"\"\n",
    "    Create a comprehensive analysis dashboard\n",
    "    \"\"\"\n",
    "    analyzer = PredictionAnalyzer(predictions)\n",
    "\n",
    "    # Create a large figure with multiple subplots\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1. Top models comparison (top left)\n",
    "    plt.subplot(2, 3, 1)\n",
    "    analyzer.plot_top_k_comparison(k=6, metric='rmse')\n",
    "    plt.title(\"Top 6 Models: RMSE\")\n",
    "\n",
    "    # 2. Model vs preprocessing heatmap (top center)\n",
    "    plt.subplot(2, 3, 2)\n",
    "    analyzer.plot_variable_heatmap(\n",
    "        x_var=\"model_name\",\n",
    "        y_var=\"preprocessings\",\n",
    "        metric='rmse',\n",
    "        best_only=True\n",
    "    )\n",
    "    plt.title(\"Best Models: Preprocessing Heatmap\")\n",
    "\n",
    "    # 3. Performance distribution (top right)\n",
    "    plt.subplot(2, 3, 3)\n",
    "    analyzer.plot_variable_candlestick(\n",
    "        filters={\"partition\": \"test\"},\n",
    "        variable=\"model_name\"\n",
    "    )\n",
    "    plt.title(\"Performance Distribution\")\n",
    "\n",
    "    # 4. R¬≤ comparison (bottom left)\n",
    "    plt.subplot(2, 3, 4)\n",
    "    analyzer.plot_top_k_comparison(k=6, metric='r2')\n",
    "    plt.title(\"Top 6 Models: R¬≤\")\n",
    "\n",
    "    # 5. Full preprocessing heatmap (bottom center)\n",
    "    plt.subplot(2, 3, 5)\n",
    "    analyzer.plot_variable_heatmap(\n",
    "        x_var=\"model_name\",\n",
    "        y_var=\"preprocessings\",\n",
    "        metric='rmse',\n",
    "        best_only=False,\n",
    "        display_n=False\n",
    "    )\n",
    "    plt.title(\"All Results: Preprocessing Heatmap\")\n",
    "\n",
    "    # 6. Model performance summary (bottom right)\n",
    "    plt.subplot(2, 3, 6)\n",
    "\n",
    "    # Get performance statistics\n",
    "    top_models = predictions.top_k(10, 'rmse')\n",
    "    model_names = [model['model_name'] for model in top_models]\n",
    "    rmse_values = [model['rmse'] for model in top_models]\n",
    "    r2_values = [model['r2'] for model in top_models]\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.scatter(rmse_values, r2_values, s=100, alpha=0.7, c=range(len(rmse_values)), cmap='viridis')\n",
    "    plt.xlabel('RMSE')\n",
    "    plt.ylabel('R¬≤')\n",
    "    plt.title('RMSE vs R¬≤ (Top 10 Models)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add annotations for top 3\n",
    "    for i in range(min(3, len(top_models))):\n",
    "        plt.annotate(f'{i+1}', (rmse_values[i], r2_values[i]),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "print(\"üìä Advanced visualization functions defined\")\n",
    "print(\"üé® Ready to create comprehensive analysis dashboards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36713b93",
   "metadata": {},
   "source": [
    "### Step 5.2: Generate Advanced Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd13899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive analysis for our best dataset\n",
    "print(\"üé® Creating comprehensive analysis dashboard...\")\n",
    "\n",
    "# Use the multi-source predictions for rich visualizations\n",
    "comprehensive_fig = create_comprehensive_analysis(\n",
    "    multi_predictions,\n",
    "    \"NIRS4All Advanced Analysis Dashboard\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Comprehensive dashboard created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d36d4d",
   "metadata": {},
   "source": [
    "## Part 5: Advanced Visualization Techniques\n",
    "\n",
    "Let's create professional-grade visualizations for comprehensive analysis:\n",
    "\n",
    "### Step 5.1: Custom Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43150ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_performance_report(predictions, report_name=\"Advanced Analysis Report\"):\n",
    "    \"\"\"\n",
    "    Generate a detailed performance report\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìã {report_name}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Overall statistics\n",
    "    print(f\"Total predictions: {len(predictions)}\")\n",
    "\n",
    "    # Get all metrics\n",
    "    all_predictions = list(predictions)\n",
    "    rmse_values = [p['rmse'] for p in all_predictions]\n",
    "    r2_values = [p['r2'] for p in all_predictions]\n",
    "    mae_values = [p['mae'] for p in all_predictions]\n",
    "\n",
    "    print(f\"\\nüìä Performance Statistics:\")\n",
    "    print(f\"   RMSE - Mean: {np.mean(rmse_values):.4f}, Std: {np.std(rmse_values):.4f}, Min: {np.min(rmse_values):.4f}\")\n",
    "    print(f\"   R¬≤   - Mean: {np.mean(r2_values):.4f}, Std: {np.std(r2_values):.4f}, Max: {np.max(r2_values):.4f}\")\n",
    "    print(f\"   MAE  - Mean: {np.mean(mae_values):.4f}, Std: {np.std(mae_values):.4f}, Min: {np.min(mae_values):.4f}\")\n",
    "\n",
    "    # Model type analysis\n",
    "    model_types = {}\n",
    "    for pred in all_predictions:\n",
    "        model_name = pred['model_name']\n",
    "        model_type = model_name.split('-')[0] if '-' in model_name else model_name\n",
    "        if model_type not in model_types:\n",
    "            model_types[model_type] = []\n",
    "        model_types[model_type].append(pred['rmse'])\n",
    "\n",
    "    print(f\"\\nüî¨ Model Type Performance (Average RMSE):\")\n",
    "    for model_type, rmse_list in sorted(model_types.items(), key=lambda x: np.mean(x[1])):\n",
    "        avg_rmse = np.mean(rmse_list)\n",
    "        count = len(rmse_list)\n",
    "        print(f\"   {model_type:15s}: {avg_rmse:.4f} (n={count})\")\n",
    "\n",
    "    # Top performers\n",
    "    top_5 = predictions.top_k(5, 'rmse')\n",
    "    print(f\"\\nüèÜ Top 5 Performers:\")\n",
    "    for idx, model in enumerate(top_5):\n",
    "        preprocessing = model['preprocessings'] if model['preprocessings'] else 'None'\n",
    "        print(f\"   {idx+1}. {model['model_name']} | RMSE: {model['rmse']:.4f} | R¬≤: {model['r2']:.4f}\")\n",
    "        print(f\"      Preprocessing: {preprocessing}\")\n",
    "        if 'dataset_name' in model:\n",
    "            print(f\"      Dataset: {model['dataset_name']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Generate reports for different analyses\n",
    "generate_performance_report(multi_predictions, \"Multi-Source Analysis Report\")\n",
    "generate_performance_report(opt_predictions, \"Hyperparameter Optimization Report\")\n",
    "generate_performance_report(dynamic_predictions, \"Dynamic Configuration Report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d94898",
   "metadata": {},
   "source": [
    "## Part 5: Putting It All Together - Complete Workflow\n",
    "\n",
    "Let's create a comprehensive workflow that combines all advanced techniques:\n",
    "\n",
    "### Step 5.1: Ultimate NIRS Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultimate comprehensive pipeline\n",
    "ultimate_pipeline = [\n",
    "    # Comprehensive visualization\n",
    "    \"chart_2d\",\n",
    "\n",
    "    # Advanced scaling\n",
    "    MinMaxScaler(feature_range=(0.05, 0.95)),\n",
    "\n",
    "    # Ultimate feature augmentation\n",
    "    {\"feature_augmentation\": {\n",
    "        \"_or_\": [\n",
    "            StandardNormalVariate(),\n",
    "            SavitzkyGolay(),\n",
    "            MultiplicativeScatterCorrection(),\n",
    "            Gaussian(),\n",
    "            Detrend(),\n",
    "            FirstDerivative(),\n",
    "            [StandardNormalVariate(), SavitzkyGolay()],\n",
    "            [MultiplicativeScatterCorrection(), Gaussian()],\n",
    "            [Detrend(), FirstDerivative()],\n",
    "            [StandardNormalVariate(), MultiplicativeScatterCorrection(), SavitzkyGolay()]\n",
    "        ],\n",
    "        \"size\": [1, 2, 3],\n",
    "        \"count\": 8\n",
    "    }},\n",
    "\n",
    "    # Robust cross-validation\n",
    "    RepeatedKFold(n_splits=5, n_repeats=2, random_state=42),\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "\n",
    "    # Optimized PLS models\n",
    "    {\n",
    "        \"model\": PLSRegression(),\n",
    "        \"name\": \"UltimatePLS\",\n",
    "        \"finetune_params\": {\n",
    "            \"n_trials\": 25,\n",
    "            \"verbose\": 1,\n",
    "            \"approach\": \"single\",\n",
    "            \"sample\": \"tpe\",\n",
    "            \"model_params\": {\n",
    "                'n_components': ('int', 5, 35),\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Diverse model ensemble\n",
    "    {\"model\": ElasticNet(alpha=0.01), \"name\": \"TunedElasticNet\"},\n",
    "    {\"model\": RandomForestRegressor(n_estimators=200, max_depth=15), \"name\": \"TunedRandomForest\"},\n",
    "    {\"model\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1), \"name\": \"TunedGradientBoosting\"},\n",
    "\n",
    "    # Advanced neural network\n",
    "    {\n",
    "        \"model\": nicon,\n",
    "        \"name\": \"UltimateDeepNIRS\",\n",
    "        \"train_params\": {\n",
    "            \"epochs\": 200,\n",
    "            \"patience\": 25,\n",
    "            \"batch_size\": 32,\n",
    "            \"verbose\": 0\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üöÄ Ultimate NIRS pipeline configured:\")\n",
    "print(\"   ‚Ä¢ 10 preprocessing strategies (including 3-step combinations)\")\n",
    "print(\"   ‚Ä¢ Hyperparameter-optimized PLS (25 trials)\")\n",
    "print(\"   ‚Ä¢ 4 additional tuned models\")\n",
    "print(\"   ‚Ä¢ Advanced neural network with extended training\")\n",
    "print(\"   ‚Ä¢ Repeated 5-fold cross-validation\")\n",
    "print(f\"   ‚Ä¢ Estimated total configurations: {5 * 8} = 40+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe38019",
   "metadata": {},
   "source": [
    "### Step 5.3: Performance Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c99b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ultimate analysis\n",
    "ultimate_config = PipelineConfigs(ultimate_pipeline, \"Ultimate_NIRS_Analysis\")\n",
    "\n",
    "# Use the best available dataset\n",
    "ultimate_datasets = ['sample_data/regression', 'sample_data/regression_2']\n",
    "ultimate_dataset_config = DatasetConfigs(ultimate_datasets)\n",
    "\n",
    "print(\"üöÄ Starting ultimate NIRS analysis...\")\n",
    "print(\"‚ö†Ô∏è  This is the most comprehensive analysis - expect 10-15 minutes\")\n",
    "print(\"üìä Processing multiple datasets with advanced optimization\")\n",
    "\n",
    "# Run with full capabilities\n",
    "ultimate_runner = PipelineRunner(save_files=True, verbose=1)\n",
    "ultimate_predictions, ultimate_per_dataset = ultimate_runner.run(ultimate_config, ultimate_dataset_config)\n",
    "\n",
    "print(f\"üéâ Ultimate analysis completed!\")\n",
    "print(f\"üìä Total predictions: {len(ultimate_predictions)}\")\n",
    "print(f\"üóÇÔ∏è  Datasets processed: {len(ultimate_per_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad04fe52",
   "metadata": {},
   "source": [
    "### Step 5.3: Ultimate Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ac318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive ultimate analysis\n",
    "print(\"üîç Analyzing ultimate results...\")\n",
    "\n",
    "# Generate comprehensive report\n",
    "generate_performance_report(ultimate_predictions, \"üöÄ ULTIMATE NIRS ANALYSIS REPORT üöÄ\")\n",
    "\n",
    "# Create ultimate dashboard\n",
    "print(\"\\nüé® Creating ultimate analysis dashboard...\")\n",
    "ultimate_fig = create_comprehensive_analysis(\n",
    "    ultimate_predictions,\n",
    "    \"üöÄ Ultimate NIRS4All Analysis Dashboard üöÄ\"\n",
    ")\n",
    "\n",
    "# Save the best model for future use\n",
    "ultimate_best = ultimate_predictions.top_k(1, 'rmse')[0]\n",
    "ultimate_model_id = ultimate_best['id']\n",
    "\n",
    "print(f\"\\nüíæ Best model saved with ID: {ultimate_model_id}\")\n",
    "print(f\"üèÜ Ultimate champion: {ultimate_best['model_name']}\")\n",
    "print(f\"üìà Performance: RMSE={ultimate_best['rmse']:.4f}, R¬≤={ultimate_best['r2']:.4f}\")\n",
    "print(f\"üî¨ Preprocessing: {ultimate_best['preprocessings'] if ultimate_best['preprocessings'] else 'None'}\")\n",
    "print(f\"üìÅ Dataset: {ultimate_best.get('dataset_name', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8b7041",
   "metadata": {},
   "source": [
    "## Part 6: Putting It All Together - Complete Workflow\n",
    "\n",
    "Let's create a comprehensive workflow that combines all advanced techniques:\n",
    "\n",
    "### Step 6.1: Ultimate NIRS Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee48c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the ultimate model on new data\n",
    "print(\"üß™ Testing ultimate model on independent dataset...\")\n",
    "\n",
    "# Use a different dataset for final validation\n",
    "test_dataset = DatasetConfigs('sample_data/regression_3')\n",
    "\n",
    "# Make predictions with the ultimate model\n",
    "final_predictor = PipelineRunner(save_files=False, verbose=1)\n",
    "final_predictions, _ = final_predictor.predict(ultimate_model_id, test_dataset, verbose=1)\n",
    "\n",
    "print(f\"‚úÖ Final testing completed!\")\n",
    "print(f\"üìä Generated {len(final_predictions)} final predictions\")\n",
    "print(f\"üìà Prediction range: {final_predictions.min():.3f} to {final_predictions.max():.3f}\")\n",
    "print(f\"üìä Mean prediction: {final_predictions.mean():.3f} ¬± {final_predictions.std():.3f}\")\n",
    "\n",
    "# Final visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Prediction distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(final_predictions.flatten(), bins=25, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "plt.title(\"Final Prediction Distribution\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.boxplot(final_predictions.flatten())\n",
    "plt.title(\"Final Prediction Statistics\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Time series style plot\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(final_predictions.flatten(), 'o-', alpha=0.7, markersize=4)\n",
    "plt.title(\"Final Predictions Sequence\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üé® Final visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e3445",
   "metadata": {},
   "source": [
    "## Summary and Conclusion\n",
    "\n",
    "üéâ **Congratulations!** You've mastered advanced NIRS analysis with NIRS4All!\n",
    "\n",
    "### What You've Accomplished:\n",
    "1. ‚úÖ **Multi-Source Analysis** - Handled multiple datasets simultaneously with sophisticated preprocessing\n",
    "2. ‚úÖ **Hyperparameter Optimization** - Used Optuna for automated model tuning\n",
    "3. ‚úÖ **Dynamic Configuration** - Created flexible, complexity-based pipeline generation\n",
    "4. ‚úÖ **Advanced Visualizations** - Built comprehensive analysis dashboards\n",
    "5. ‚úÖ **Neural Networks** - Integrated deep learning models with custom training\n",
    "6. ‚úÖ **Complete Workflow** - Executed end-to-end professional NIRS analysis\n",
    "\n",
    "### Advanced Techniques Mastered:\n",
    "- **Complex Feature Augmentation**: Multi-step preprocessing combinations\n",
    "- **Ensemble Methods**: Multiple model types working together\n",
    "- **Robust Validation**: Repeated k-fold cross-validation\n",
    "- **Model Persistence**: Save/load optimized models\n",
    "- **Performance Analysis**: Comprehensive statistical reporting\n",
    "- **Professional Visualization**: Multi-panel analysis dashboards\n",
    "\n",
    "### Key Performance Insights:\n",
    "- üî¨ **Preprocessing Impact**: Spectral preprocessing can significantly improve model performance\n",
    "- üéØ **Optimization Benefits**: Hyperparameter tuning provides measurable improvements\n",
    "- üß† **Neural Networks**: Deep learning excels with sufficient data and proper training\n",
    "- üìä **Multi-Source Robustness**: Cross-dataset validation ensures model generalizability\n",
    "- üîÑ **Pipeline Flexibility**: Dynamic configuration enables rapid experimentation\n",
    "\n",
    "### Production-Ready Workflow:\n",
    "You now have the skills to:\n",
    "- üöÄ Build production-grade NIRS analysis pipelines\n",
    "- üìà Optimize models for specific applications\n",
    "- üîç Validate models across multiple datasets\n",
    "- üìä Create professional analysis reports\n",
    "- üíæ Deploy saved models for real-time prediction\n",
    "\n",
    "### Next Steps for Your Projects:\n",
    "1. üéØ **Domain Adaptation**: Customize preprocessing for your specific spectral data\n",
    "2. üî¨ **Experiment Design**: Use cross-validation strategies appropriate for your study\n",
    "3. üìä **Metric Selection**: Choose evaluation metrics that align with your application goals\n",
    "4. ü§ñ **Model Selection**: Balance complexity with interpretability based on your needs\n",
    "5. üìà **Continuous Improvement**: Regularly retrain models as new data becomes available\n",
    "\n",
    "### Advanced Tips:\n",
    "- üí° **Start Complex, Simplify**: Begin with comprehensive analysis, then streamline\n",
    "- üîÑ **Iterate Rapidly**: Use dynamic configurations for quick experimentation\n",
    "- üìä **Visualize Everything**: Rich visualizations reveal insights numbers can't\n",
    "- üíæ **Save Everything**: Model persistence enables reproducible research\n",
    "- üî¨ **Validate Thoroughly**: Multi-dataset testing ensures real-world performance\n",
    "\n",
    "You're now ready to tackle any NIRS analysis challenge! üöÄüî¨üìä"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
