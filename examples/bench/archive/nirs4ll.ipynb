{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd318ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from nirs4all.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG, Gaussian as GS\n",
    "from nirs4all.transformations import Rotate_Translate as RT\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"data\": {\n",
    "        \"action\": \"classification\",\n",
    "        \"dataset\": \"data/sample_data.csv\"\n",
    "    },\n",
    "\n",
    "    \"pipeline\": [\n",
    "        MinMaxScaler(),\n",
    "        { \"feature_augmentation\": [ None, SG, [SNV, GS] ] },\n",
    "        { \"sample_augmentation\": [ RT, RT(p_range=3) ] },\n",
    "\n",
    "        ShuffleSplit(), # First one is target:test by default\n",
    "\n",
    "        { \"cluster\": KMeans(n_clusters=5, random_state=42) },\n",
    "\n",
    "        {\n",
    "            \"class\": \"sklearn.model_selection.RepeatedStratifiedKFold\",\n",
    "            \"params\": { \"n_splits\": 5, \"n_repeats\": 2, \"random_state\": 42 }\n",
    "        },\n",
    "\n",
    "        \"uncluster\",\n",
    "\n",
    "        \"PlotData\",\n",
    "        \"PlotClusters\",\n",
    "        \"PlotResults\",\n",
    "\n",
    "        {\n",
    "            \"branch\": [\n",
    "                {\n",
    "                    \"model\": RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10),\n",
    "                    \"y_pipeline\": \"StandardScaler\",\n",
    "                },\n",
    "                {\n",
    "                    \"model\": SVC(kernel='linear', C=1.0, random_state=42),\n",
    "                    \"y_pipeline\": [MinMaxScaler(), RobustScaler()],\n",
    "                    \"finetune_params\": {\n",
    "                        \"C\": [0.1, 1.0, 10.0]\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"stack\": {\n",
    "                        \"model\": RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10),\n",
    "                        \"y_pipeline\": StandardScaler(),\n",
    "                        \"base_learners\": [\n",
    "                            {\n",
    "                                \"model\": GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=5),\n",
    "                                \"y_pipeline\": MinMaxScaler(),\n",
    "                            },\n",
    "                            {\n",
    "                                \"model\": DecisionTreeClassifier(random_state=42, max_depth=5),\n",
    "                                \"y_pipeline\": MinMaxScaler(),\n",
    "                                \"finetune_params\": {\n",
    "                                    \"max_depth\": [3, 5, 7]\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "\n",
    "        \"PlotModelPerformance\",\n",
    "        \"PlotFeatureImportance\",\n",
    "        \"PlotConfusionMatrix\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "presets = {\n",
    "    'StandardScaler': {'class': \"sklearn.preprocessing.StandardScaler\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[0.96557783 0.04731449 0.01774207 ... 0.55277315 0.22486138 0.54856955]\n",
      "Running pipeline\n",
      "Transforming source 0 with shape (2000, 2500)\n",
      "Transforming source 1 with shape (2000, 500)\n",
      "Pipeline finished.\n",
      "[0.96557783 0.04731449 0.01774207 ... 0.55277315 0.22486138 0.54856955]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spectradataset import SpectraDataset\n",
    "import polars as pl\n",
    "from pipeline import PipelineRunner\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "features = [np.random.rand(1000, 2500), np.random.rand(1000, 500)]\n",
    "targets = np.random.rand(1000, 2)\n",
    "metadata = pd.DataFrame({\n",
    "    'sample_id': np.arange(1000),\n",
    "    'condition': np.random.choice(['A', 'B'], size=1000),\n",
    "    'age': np.random.randint(20, 60, size=1000)\n",
    "})\n",
    "\n",
    "dataset = SpectraDataset()\n",
    "# print(dataset.indices)\n",
    "dataset.add_spectra(\n",
    "    sources=features,\n",
    "    targets=targets,\n",
    "    metadata=metadata,\n",
    ")\n",
    "# print(dataset.indices)\n",
    "\n",
    "dataset.add_spectra(\n",
    "    sources=features,\n",
    "    targets=targets,\n",
    "    metadata=metadata,\n",
    "    # sample=[i for i in range(1000)],\n",
    "    spectra_type=\"raman\"\n",
    ")\n",
    "# print(dataset.indices)\n",
    "# print(dataset.features)\n",
    "\n",
    "\n",
    "# x = dataset.x({\n",
    "#     \"sample\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "#     # \"spectra_type\": \"raman\",\n",
    "#     },\n",
    "#     source_merge=True,\n",
    "# )\n",
    "\n",
    "\n",
    "pipeline = [\n",
    "    MinMaxScaler(feature_range=(0, 2), copy=False),\n",
    "]\n",
    "runner = PipelineRunner()\n",
    "print(dataset.x()[0])\n",
    "runner.run_pipeline(pipeline, data=dataset)\n",
    "print(dataset.x()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f99841",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import builder, data_loader, runner\n",
    "\n",
    "\n",
    "spectra_set = data_loader.load_data(config[\"data\"])\n",
    "print(spectra_set.X().shape, spectra_set.y().shape)\n",
    "print(spectra_set.features)\n",
    "\n",
    "pipeline_builder = builder.PipelineBuilder(presets)\n",
    "pipeline = pipeline_builder.build_pipeline(config[\"pipeline\"])\n",
    "print(json.dumps(pipeline, indent=4, default=str))\n",
    "\n",
    "pipeline_runner = runner.PipelineRunner()\n",
    "pipeline_runner.run_pipeline(pipeline, spectra_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330573b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline results:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m     \u001b[43mexample_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m, in \u001b[0;36mexample_usage\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m dataset\u001b[38;5;241m.\u001b[39madd_data(X_test, y_test, partition\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Define pipeline\u001b[39;00m\n\u001b[0;32m     31\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 32\u001b[0m     \u001b[43mTransformOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStandardScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     33\u001b[0m     ClusterOperation(KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m     34\u001b[0m     ModelOperation(RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m     35\u001b[0m ]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Run pipeline\u001b[39;00m\n\u001b[0;32m     38\u001b[0m runner \u001b[38;5;241m=\u001b[39m PipelineRunner()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from new4all import SpectraDataset, TransformOperation, ClusterOperation, ModelOperation, PipelineRunner\n",
    "\n",
    "def example_usage():\n",
    "    \"\"\"Example of how to use the improved pipeline.\"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = SpectraDataset()\n",
    "\n",
    "    # Add some dummy data\n",
    "    X_train = np.random.randn(100, 1000)  # 100 samples, 1000 features\n",
    "    y_train = np.random.randint(0, 3, 100)  # 3 classes\n",
    "    X_train = X_train.astype(np.float64)\n",
    "    y_train = y_train.astype(np.float64)\n",
    "\n",
    "    X_test = np.random.randn(30, 1000)\n",
    "    y_test = np.random.randint(0, 3, 30)\n",
    "    X_test = X_test.astype(np.float64)\n",
    "    y_test = y_test.astype(np.float64)\n",
    "\n",
    "    dataset.add_data(X_train, y_train, partition=\"train\")\n",
    "    dataset.add_data(X_test, y_test, partition=\"test\")\n",
    "\n",
    "    # Define pipeline\n",
    "    pipeline = [\n",
    "        TransformOperation(StandardScaler()),\n",
    "        ClusterOperation(KMeans(n_clusters=3)),\n",
    "        ModelOperation(RandomForestClassifier(n_estimators=100))\n",
    "    ]\n",
    "\n",
    "    # Run pipeline\n",
    "    runner = PipelineRunner()\n",
    "    results = runner.run(pipeline, dataset)\n",
    "\n",
    "    print(\"Pipeline results:\", results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
