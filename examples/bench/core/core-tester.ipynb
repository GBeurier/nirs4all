{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd62d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from nirs4all.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG, Gaussian as GS\n",
    "from nirs4all.transformations import Rotate_Translate as RT\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "import json\n",
    "from sample import config as python_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d701b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'dataset': {'type': 'classification', 'folder': './sample_data'}, 'pipeline': ['PlotModelPerformance', MinMaxScaler(), 'PlotModelPerformance', {'feature_augmentation': [None, <class 'nirs4all.transformations._nirs.SavitzkyGolay'>, [<class 'sklearn.preprocessing._data.StandardScaler'>, <class 'nirs4all.transformations._standard.Gaussian'>]]}, 'PlotModelPerformance', {'sample_augmentation': [<class 'nirs4all.transformations._random_augmentation.Rotate_Translate'>, Rotate_Translate(p_range=3)]}, 'PlotModelPerformance', ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), 'PlotModelPerformance', {'cluster': KMeans(n_clusters=5, random_state=42)}, 'PlotModelPerformance', RepeatedStratifiedKFold(n_repeats=2, n_splits=5, random_state=42), 'PlotModelPerformance', 'uncluster', 'PlotData', {'dispatch': [[MinMaxScaler(), {'feature_augmentation': [None, <class 'nirs4all.transformations._nirs.SavitzkyGolay'>, [<class 'sklearn.preprocessing._data.StandardScaler'>, <class 'nirs4all.transformations._standard.Gaussian'>]]}, {'model': RandomForestClassifier(max_depth=10, random_state=42), 'y_pipeline': <class 'sklearn.preprocessing._data.StandardScaler'>}, 'PlotModelPerformance'], {'model': <function decon at 0x000001B7E476ADD0>, 'y_pipeline': StandardScaler()}, {'model': SVC(kernel='linear', random_state=42), 'y_pipeline': [<class 'sklearn.preprocessing._data.MinMaxScaler'>, RobustScaler()], 'finetune_params': {'C': [0.1, 1.0, 10.0]}}, {'stack': {'model': RandomForestClassifier(max_depth=10, random_state=42), 'y_pipeline': StandardScaler(), 'base_learners': [{'model': GradientBoostingClassifier(max_depth=5, random_state=42), 'y_pipeline': MinMaxScaler()}, {'model': DecisionTreeClassifier(max_depth=5, random_state=42), 'y_pipeline': MinMaxScaler(), 'finetune_params': {'max_depth': [3, 5, 7]}}]}}]}, 'PlotModelPerformance', 'PlotFeatureImportance', 'PlotConfusionMatrix']}\n",
      "Loading data from folder structure...\n",
      "{'dataset': {'action': 'classification', 'folder': './sample_data'}, 'pipeline': [{'class': 'sklearn.preprocessing.MinMaxScaler'}, {'feature_augmentation': [None, {'class': 'nirs4all.transformations.SavitzkyGolay'}, [{'class': 'nirs4all.transformations.StandardNormalVariate'}, {'class': 'nirs4all.transformations.Gaussian'}]]}, {'sample_augmentation': [{'class': 'nirs4all.transformations.Rotate_Translate'}, {'class': 'nirs4all.transformations.Rotate_Translate', 'params': {'p_range': 3}}]}, {'class': 'sklearn.model_selection.ShuffleSplit'}, {'cluster': {'class': 'sklearn.cluster.KMeans', 'params': {'n_clusters': 5, 'random_state': 42}}}, {'class': 'sklearn.model_selection.RepeatedStratifiedKFold', 'params': {'n_splits': 5, 'n_repeats': 2, 'random_state': 42}}, 'uncluster', {'class': 'PlotData'}, {'class': 'PlotClusters'}, {'class': 'PlotResults'}, {'dispatch': [[{'class': 'sklearn.preprocessing.MinMaxScaler'}, {'feature_augmentation': [None, {'class': 'nirs4all.transformations.SavitzkyGolay'}, [{'class': 'nirs4all.transformations.StandardNormalVariate'}, {'class': 'nirs4all.transformations.Gaussian'}]]}, {'model': {'class': 'sklearn.ensemble.RandomForestClassifier', 'params': {'random_state': 42, 'max_depth': 10}}, 'y_pipeline': {'class': 'sklearn.preprocessing.StandardScaler'}}], {'model': 'nirs4all.presets.ref_models.decon', 'y_pipeline': {'class': 'sklearn.preprocessing.StandardScaler'}}, {'model': {'class': 'sklearn.svm.SVC', 'params': {'kernel': 'linear', 'C': 1.0, 'random_state': 42}}, 'y_pipeline': [{'class': 'sklearn.preprocessing.MinMaxScaler'}, {'class': 'sklearn.preprocessing.RobustScaler'}], 'finetune_params': {'C': [0.1, 1.0, 10.0]}}, {'stack': {'model': {'class': 'sklearn.ensemble.RandomForestClassifier', 'params': {'random_state': 42, 'max_depth': 10}}, 'y_pipeline': {'class': 'sklearn.preprocessing.StandardScaler'}, 'base_learners': [{'model': {'class': 'sklearn.ensemble.GradientBoostingClassifier', 'params': {'random_state': 42, 'n_estimators': 100, 'max_depth': 5}}, 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler'}}, {'model': {'class': 'sklearn.tree.DecisionTreeClassifier', 'params': {'random_state': 42, 'max_depth': 5}}, 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler'}, 'finetune_params': {'max_depth': [3, 5, 7]}}]}}]}, {'class': 'PlotModelPerformance'}, {'class': 'PlotFeatureImportance'}, {'class': 'PlotConfusionMatrix'}]}\n",
      "Loading data from folder structure...\n",
      "{'dataset': {'action': 'classification', 'folder': './sample_data'}, 'pipeline': [{'class': 'sklearn.preprocessing.MinMaxScaler'}, {'feature_augmentation': [None, {'class': 'nirs4all.transformations.SavitzkyGolay'}, [{'class': 'nirs4all.transformations.StandardNormalVariate'}, {'class': 'nirs4all.transformations.Gaussian'}]]}, {'sample_augmentation': [{'class': 'nirs4all.transformations.Rotate_Translate'}, {'class': 'nirs4all.transformations.Rotate_Translate', 'params': {'p_range': 3}}]}, {'class': 'sklearn.model_selection.ShuffleSplit'}, {'cluster': {'class': 'sklearn.cluster.KMeans', 'params': {'n_clusters': 5, 'random_state': 42}}}, {'class': 'sklearn.model_selection.RepeatedStratifiedKFold', 'params': {'n_splits': 5, 'n_repeats': 2, 'random_state': 42}}, 'uncluster', {'class': 'PlotData'}, {'class': 'PlotClusters'}, {'class': 'PlotResults'}, {'dispatch': [{'model': {'class': 'sklearn.ensemble.RandomForestClassifier', 'params': {'random_state': 42, 'max_depth': 10}}, 'y_pipeline': {'class': 'sklearn.preprocessing.StandardScaler'}}, {'model': {'class': 'nirs4all.presets.ref_models.decon'}, 'y_pipeline': {'class': 'sklearn.preprocessing.StandardScaler'}}, {'model': {'class': 'sklearn.svm.SVC', 'params': {'kernel': 'linear', 'C': 1.0, 'random_state': 42}}, 'y_pipeline': [{'class': 'sklearn.preprocessing.MinMaxScaler'}, {'class': 'sklearn.preprocessing.RobustScaler'}], 'finetune_params': {'C': [0.1, 1.0, 10.0]}}, {'stack': {'model': {'class': 'sklearn.ensemble.RandomForestClassifier', 'params': {'random_state': 42, 'max_depth': 10}}, 'y_pipeline': {'class': 'sklearn.preprocessing.StandardScaler'}, 'base_learners': [{'model': {'class': 'sklearn.ensemble.GradientBoostingClassifier', 'params': {'random_state': 42, 'n_estimators': 100, 'max_depth': 5}}, 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler'}}, {'model': {'class': 'sklearn.tree.DecisionTreeClassifier', 'params': {'random_state': 42, 'max_depth': 5}}, 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler'}, 'finetune_params': {'max_depth': [3, 5, 7]}}]}}]}, {'class': 'PlotModelPerformance'}, {'class': 'PlotFeatureImportance'}, {'class': 'PlotConfusionMatrix'}]}\n",
      "Loading data from folder structure...\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "Python Dataset:\n",
      " 130x2151 Mean: 0.46, Std: 0.37 for regression \n",
      "Samples: 130, Rows: 130, Features: 1\n",
      "Partitions: ['train']\n",
      "  train: 130 samples\n",
      "Groups: [0]\n",
      "Branches: [0]\n",
      "Processing: ['raw']\n",
      "Targets: {'task_type': 'regression', 'n_classes': 10, 'is_binary': False, 'classes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'n_samples': 130, 'regression_transformers': [], 'classification_transformers': []}\n",
      "Results: {'n_predictions': 0, 'models': [], 'partitions': [], 'folds': []}\n",
      "\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "JSON Dataset:\n",
      " 130x2151 Mean: 0.46, Std: 0.37 for regression \n",
      "Samples: 130, Rows: 130, Features: 1\n",
      "Partitions: ['train']\n",
      "  train: 130 samples\n",
      "Groups: [0]\n",
      "Branches: [0]\n",
      "Processing: ['raw']\n",
      "Targets: {'task_type': 'regression', 'n_classes': 10, 'is_binary': False, 'classes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'n_samples': 130, 'regression_transformers': [], 'classification_transformers': []}\n",
      "Results: {'n_predictions': 0, 'models': [], 'partitions': [], 'folds': []}\n",
      "\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "YAML Dataset:\n",
      " 130x2151 Mean: 0.46, Std: 0.37 for regression \n",
      "Samples: 130, Rows: 130, Features: 1\n",
      "Partitions: ['train']\n",
      "  train: 130 samples\n",
      "Groups: [0]\n",
      "Branches: [0]\n",
      "Processing: ['raw']\n",
      "Targets: {'task_type': 'regression', 'n_classes': 10, 'is_binary': False, 'classes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'n_samples': 130, 'regression_transformers': [], 'classification_transformers': []}\n",
      "Results: {'n_predictions': 0, 'models': [], 'partitions': [], 'folds': []}\n",
      "\n",
      "🚀 Starting Pipeline Runner\n",
      "📋 Step 1: 'PlotModelPerformance'\n",
      "❌ Step 1 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 2: MinMaxScaler object\n",
      "❌ Step 2 failed: name 'TransformationOperation' is not defined\n",
      "📋 Step 3: 'PlotModelPerformance'\n",
      "❌ Step 3 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 4: 'feature_augmentation' control\n",
      "  🔄 Feature augmentation with 3 augmenters\n",
      "❌ Step 4 failed: No module named 'DatasetView'\n",
      "📋 Step 5: 'PlotModelPerformance'\n",
      "❌ Step 5 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 6: 'sample_augmentation' control\n",
      "  🔄 Sample augmentation with 2 augmenters\n",
      "    📌 Augmenter 1/2\n",
      "❌ Step 6 failed: name 'TransformationOperation' is not defined\n",
      "📋 Step 7: 'PlotModelPerformance'\n",
      "❌ Step 7 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 8: ShuffleSplit object\n",
      "  🔧 Executing: Generic(ShuffleSplit)\n",
      "❌ Step 8 failed: Don't know how to execute <class 'sklearn.model_selection._split.ShuffleSplit'>\n",
      "📋 Step 9: 'PlotModelPerformance'\n",
      "❌ Step 9 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 10: 'cluster' control\n",
      "❌ Step 10 failed: name 'TransformationOperation' is not defined\n",
      "📋 Step 11: 'PlotModelPerformance'\n",
      "❌ Step 11 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 12: RepeatedStratifiedKFold object\n",
      "Type mismatch: <class 'int'> != <class 'NoneType'>\n",
      "  🔧 Executing: Generic(RepeatedStratifiedKFold)\n",
      "❌ Step 12 failed: Don't know how to execute <class 'sklearn.model_selection._split.RepeatedStratifiedKFold'>\n",
      "📋 Step 13: 'PlotModelPerformance'\n",
      "❌ Step 13 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 14: 'uncluster'\n",
      "  🔓 Uncluster operation\n",
      "✅ Step 14 completed\n",
      "📋 Step 15: 'PlotData'\n",
      "❌ Step 15 failed: Unknown preset: PlotData\n",
      "📋 Step 16: 'dispatch' control\n",
      "  🌿 Dispatch with 4 branches\n",
      "      📋 Step 17: sub-pipeline (4 steps)\n",
      "        📋 Sub-pipeline with 4 steps\n",
      "          📋 Step 18: MinMaxScaler object\n",
      "          ❌ Step 18 failed: name 'TransformationOperation' is not defined\n",
      "          📋 Step 19: 'feature_augmentation' control\n",
      "            🔄 Feature augmentation with 3 augmenters\n",
      "      📋 Step 20: complex dict with ['model', 'y_pipeline']\n",
      "        🤖 Model operation\n",
      "          ❌ Step 20 failed: No module named 'DatasetView'\n",
      "          📋 Step 21: complex dict with ['model', 'y_pipeline']\n",
      "            🤖 Model operation\n",
      "          ❌ Step 21 failed: name 'ModelOperation' is not defined\n",
      "          📋 Step 22: 'PlotModelPerformance'\n",
      "          ❌ Step 22 failed: Unknown preset: PlotModelPerformance\n",
      "      ✅ Step 22 completed\n",
      "      📋 Step 23: complex dict with ['model', 'y_pipeline', 'finetune_params']\n",
      "        🤖 Model operation\n",
      "      ❌ Step 23 failed: name 'ModelOperation' is not defined\n",
      "      ❌ Step 23 failed: name 'ModelOperation' is not defined\n",
      "    ✅ Branch 1 completed\n",
      "    ✅ Branch 2 completed\n",
      "    ✅ Branch 3 completed\n",
      "      📋 Step 24: 'stack' control\n",
      "      ❌ Step 24 failed: name 'StackOperation' is not defined\n",
      "    ✅ Branch 4 completed\n",
      "✅ Step 24 completed\n",
      "📋 Step 25: 'PlotModelPerformance'\n",
      "❌ Step 25 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 26: 'PlotFeatureImportance'\n",
      "❌ Step 26 failed: Unknown preset: PlotFeatureImportance\n",
      "📋 Step 27: 'PlotConfusionMatrix'\n",
      "❌ Step 27 failed: Unknown preset: PlotConfusionMatrix\n",
      "🚀 Starting Pipeline Runner\n",
      "  ⚠️ Warning: Previous run detected, resetting step count\n",
      "📋 Step 1: 'class' control\n",
      "❌ Step 1 failed: name 'TransformationOperation' is not defined\n",
      "📋 Step 2: 'feature_augmentation' control\n",
      "  🔄 Feature augmentation with 3 augmenters\n",
      "❌ Step 2 failed: No module named 'DatasetView'\n",
      "📋 Step 3: 'sample_augmentation' control\n",
      "  🔄 Sample augmentation with 2 augmenters\n",
      "    📌 Augmenter 1/2\n",
      "❌ Step 3 failed: name 'TransformationOperation' is not defined\n",
      "📋 Step 4: 'class' control\n",
      "  🔧 Executing: Generic(ShuffleSplit)\n",
      "❌ Step 4 failed: Don't know how to execute <class 'sklearn.model_selection._split.ShuffleSplit'>\n",
      "📋 Step 5: 'cluster' control\n",
      "❌ Step 5 failed: name 'TransformationOperation' is not defined\n",
      "📋 Step 6: complex dict with ['class', 'params']\n",
      "  🔧 Executing: Generic(RepeatedStratifiedKFold)\n",
      "❌ Step 6 failed: Don't know how to execute <class 'sklearn.model_selection._split.RepeatedStratifiedKFold'>\n",
      "📋 Step 7: 'uncluster'\n",
      "  🔓 Uncluster operation\n",
      "✅ Step 7 completed\n",
      "📋 Step 8: 'class' control\n",
      "❌ Step 8 failed: Unknown preset: PlotData\n",
      "📋 Step 9: 'class' control\n",
      "❌ Step 9 failed: Unknown preset: PlotClusters\n",
      "📋 Step 10: 'class' control\n",
      "❌ Step 10 failed: Unknown preset: PlotResults\n",
      "📋 Step 11: 'dispatch' control\n",
      "  🌿 Dispatch with 4 branches\n",
      "      📋 Step 12: sub-pipeline (3 steps)\n",
      "        📋 Sub-pipeline with 3 steps\n",
      "          📋 Step 13: 'class' control\n",
      "          ❌ Step 13 failed: name 'TransformationOperation' is not defined\n",
      "          📋 Step 14: 'feature_augmentation' control\n",
      "            🔄 Feature augmentation with 3 augmenters\n",
      "      📋 Step 15: complex dict with ['model', 'y_pipeline']\n",
      "        🤖 Model operation\n",
      "      ❌ Step 15 failed: Unknown preset: nirs4all.presets.ref_models.decon\n",
      "      📋 Step 16: complex dict with ['model', 'y_pipeline', 'finetune_params']\n",
      "        🤖 Model operation\n",
      "          ❌ Step 16 failed: No module named 'DatasetView'\n",
      "          📋 Step 17: complex dict with ['model', 'y_pipeline']\n",
      "            🤖 Model operation\n",
      "      📋 Step 18: 'stack' control\n",
      "      ❌ Step 18 failed: name 'StackOperation' is not defined\n",
      "      ❌ Step 18 failed: name 'ModelOperation' is not defined\n",
      "          ❌ Step 18 failed: name 'ModelOperation' is not defined\n",
      "      ✅ Step 18 completed\n",
      "    ✅ Branch 1 completed\n",
      "    ✅ Branch 2 completed\n",
      "    ✅ Branch 3 completed\n",
      "    ✅ Branch 4 completed\n",
      "✅ Step 18 completed\n",
      "📋 Step 19: 'class' control\n",
      "❌ Step 19 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 20: 'class' control\n",
      "❌ Step 20 failed: Unknown preset: PlotFeatureImportance\n",
      "📋 Step 21: 'class' control\n",
      "❌ Step 21 failed: Unknown preset: PlotConfusionMatrix\n",
      "🚀 Starting Pipeline Runner\n",
      "  ⚠️ Warning: Previous run detected, resetting step count\n",
      "📋 Step 1: 'class' control\n",
      "❌ Step 1 failed: name 'TransformationOperation' is not defined\n",
      "📋 Step 2: 'feature_augmentation' control\n",
      "  🔄 Feature augmentation with 3 augmenters\n",
      "❌ Step 2 failed: No module named 'DatasetView'\n",
      "📋 Step 3: 'sample_augmentation' control\n",
      "  🔄 Sample augmentation with 2 augmenters\n",
      "    📌 Augmenter 1/2\n",
      "❌ Step 3 failed: name 'TransformationOperation' is not defined\n",
      "📋 Step 4: 'class' control\n",
      "  🔧 Executing: Generic(ShuffleSplit)\n",
      "❌ Step 4 failed: Don't know how to execute <class 'sklearn.model_selection._split.ShuffleSplit'>\n",
      "📋 Step 5: 'cluster' control\n",
      "❌ Step 5 failed: name 'TransformationOperation' is not defined\n",
      "📋 Step 6: complex dict with ['class', 'params']\n",
      "  🔧 Executing: Generic(RepeatedStratifiedKFold)\n",
      "❌ Step 6 failed: Don't know how to execute <class 'sklearn.model_selection._split.RepeatedStratifiedKFold'>\n",
      "📋 Step 7: 'uncluster'\n",
      "  🔓 Uncluster operation\n",
      "✅ Step 7 completed\n",
      "📋 Step 8: 'class' control\n",
      "❌ Step 8 failed: Unknown preset: PlotData\n",
      "📋 Step 9: 'class' control\n",
      "❌ Step 9 failed: Unknown preset: PlotClusters\n",
      "📋 Step 10: 'class' control\n",
      "❌ Step 10 failed: Unknown preset: PlotResults\n",
      "📋 Step 11: 'dispatch' control\n",
      "  🌿 Dispatch with 4 branches\n",
      "      📋 Step 12: complex dict with ['model', 'y_pipeline']\n",
      "        🤖 Model operation\n",
      "      ❌ Step 12 failed: name 'ModelOperation' is not defined\n",
      "      📋 Step 13: complex dict with ['model', 'y_pipeline']\n",
      "        🤖 Model operation\n",
      "      ❌ Step 13 failed: decon() missing 1 required positional argument: 'input_shape'\n",
      "      📋 Step 14: complex dict with ['model', 'y_pipeline', 'finetune_params']\n",
      "        🤖 Model operation\n",
      "      ❌ Step 14 failed: name 'ModelOperation' is not defined\n",
      "    ✅ Branch 1 completed\n",
      "    ✅ Branch 2 completed\n",
      "    ✅ Branch 3 completed\n",
      "      📋 Step 15: 'stack' control\n",
      "      ❌ Step 15 failed: name 'StackOperation' is not defined\n",
      "    ✅ Branch 4 completed\n",
      "✅ Step 15 completed\n",
      "📋 Step 16: 'class' control\n",
      "❌ Step 16 failed: Unknown preset: PlotModelPerformance\n",
      "📋 Step 17: 'class' control\n",
      "❌ Step 17 failed: Unknown preset: PlotFeatureImportance\n",
      "📋 Step 18: 'class' control\n",
      "❌ Step 18 failed: Unknown preset: PlotConfusionMatrix\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from SpectraDataset import SpectraDataset\n",
    "from PipelineRunner import PipelineRunner\n",
    "\n",
    "\n",
    "# Load dataset (using current SpectraDataset API)\n",
    "dataset_py = SpectraDataset.from_config(python_config)\n",
    "dataset_json = SpectraDataset.from_config(\"sample.json\")\n",
    "dataset_yaml = SpectraDataset.from_config(\"sample.yaml\")\n",
    "\n",
    "print(\"\\n\", \"=\"*200, \"\\nPython Dataset:\\n\", dataset_py)\n",
    "print(\"\\n\", \"=\"*200, \"\\nJSON Dataset:\\n\", dataset_json)\n",
    "print(\"\\n\", \"=\"*200, \"\\nYAML Dataset:\\n\", dataset_yaml)\n",
    "\n",
    "# Execute with different config types\n",
    "\n",
    "runner = PipelineRunner(max_workers=4, continue_on_error=True)\n",
    "history_py = runner.run(python_config, dataset_py)\n",
    "history_json = runner.run(\"sample.json\", dataset_json)\n",
    "history_yaml = runner.run(\"sample.yaml\", dataset_yaml)\n",
    "\n",
    "# # Get execution summary\n",
    "# summary = runner.get_execution_summary()\n",
    "# print(f\"Executed {summary['total_steps']} steps\")\n",
    "# print(f\"Success rate: {summary['successful_steps']}/{summary['total_steps']}\")\n",
    "\n",
    "# # Access predictions\n",
    "# predictions = summary['predictions']\n",
    "# for model_name, preds in predictions.items():\n",
    "#     print(f\"Model {model_name}: {preds.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c416674",
   "metadata": {},
   "source": [
    "### Preparation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c81a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Data loader functions ready to use!\n",
      "# For single dataset:\n",
      "Loading single XY dataset...\n",
      "Loaded single dataset: X shape (130, 2148), Y shape (130, 3)\n",
      "\n",
      "# For multiple datasets:\n",
      "Loading multiple datasets...\n",
      "Loaded train: X(130, 2151), Y(130, 1)\n",
      "Loaded test: X(59, 2151), Y(59, 1)\n",
      "Loaded train: X shape (130, 2151), Y shape (130, 1)\n",
      "Loaded test: X shape (59, 2151), Y shape (59, 1)\n",
      "\n",
      "# For folder data:\n",
      "Loading data from folder structure...\n",
      "Loaded folder data: X shape (130, 2151), Y shape (130, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Example 1: Single dataset configuration\n",
    "single_config = {\n",
    "    \"dataset\": {\n",
    "        \"X\": \"./sample_data/Xcal.csv\",\n",
    "        \"Y\": {\"from\": 0, \"to\": 3},\n",
    "        \"params\": {\n",
    "            \"delimiter\": \";\",\n",
    "            \"decimal\": \".\",\n",
    "            \"na_policy\": \"auto\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Example 2: Multiple datasets configuration\n",
    "multi_config = {\n",
    "    \"dataset\": {\n",
    "        \"train\": {\n",
    "            \"X\": \"./sample_data/Xcal.csv\",\n",
    "            \"Y\": \"./sample_data/Ycal.csv\",\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"X\": \"./sample_data/Xval.csv\",\n",
    "            \"Y\": \"./sample_data/Yval.csv\",\n",
    "        },\n",
    "        # \"valid\": {\n",
    "        #     \"X\": \"/path/to/valid_features.csv\",\n",
    "        #     \"Y\": [0, 1, 2]\n",
    "        # }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Example 3: Folder configuration\n",
    "folder_config = {\n",
    "    \"dataset\": \"./sample_data/\"\n",
    "}\n",
    "\n",
    "from spectra.CsvLoader import load_data_from_config\n",
    "\n",
    "try:\n",
    "    print(\"Data loader functions ready to use!\")\n",
    "\n",
    "    print(\"# For single dataset:\")\n",
    "    X, Y = load_data_from_config(single_config)\n",
    "    print(f\"Loaded single dataset: X shape {X.shape}, Y shape {Y.shape}\")\n",
    "\n",
    "    print(\"\\n# For multiple datasets:\")\n",
    "    datasets = load_data_from_config(multi_config)\n",
    "    for name, (X_data, Y_data) in datasets.items():\n",
    "        print(f\"Loaded {name}: X shape {X_data.shape}, Y shape {Y_data.shape}\")\n",
    "\n",
    "    print(\"\\n# For folder data:\")\n",
    "    X, Y = load_data_from_config(folder_config)\n",
    "    print(f\"Loaded folder data: X shape {X.shape}, Y shape {Y.shape}\")\n",
    "\n",
    "    print(type(Y[0]))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Example failed (expected with dummy paths): {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
