{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd62d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from nirs4all.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG, Gaussian as GS\n",
    "from nirs4all.transformations import Rotate_Translate as RT\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "import json\n",
    "\n",
    "json_string_config = \"\"\"{\n",
    "  \"experiment\": {\n",
    "    \"action\": \"classification\",\n",
    "    \"dataset\": \"data/sample_data.csv\"\n",
    "  },\n",
    "  \"pipeline\": [\n",
    "    {\n",
    "      \"class\": \"sklearn.preprocessing.MinMaxScaler\"\n",
    "    },\n",
    "    {\n",
    "      \"feature_augmentation\": [\n",
    "        null,\n",
    "        { \"class\": \"nirs4all.transformations.SavitzkyGolay\" },\n",
    "        [\n",
    "          { \"class\": \"nirs4all.transformations.StandardNormalVariate\" },\n",
    "          { \"class\": \"nirs4all.transformations.Gaussian\" }\n",
    "        ]\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"sample_augmentation\": [\n",
    "        { \"class\": \"nirs4all.transformations.Rotate_Translate\" },\n",
    "        {\n",
    "          \"class\": \"nirs4all.transformations.Rotate_Translate\",\n",
    "          \"params\": { \"p_range\": 3 }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    { \"class\": \"sklearn.model_selection.ShuffleSplit\" },\n",
    "    {\n",
    "      \"cluster\": {\n",
    "        \"class\": \"sklearn.cluster.KMeans\",\n",
    "        \"params\": { \"n_clusters\": 5, \"random_state\": 42 }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"class\": \"sklearn.model_selection.RepeatedStratifiedKFold\",\n",
    "      \"params\": { \"n_splits\": 5, \"n_repeats\": 2, \"random_state\": 42 }\n",
    "    },\n",
    "    \"uncluster\",\n",
    "    { \"class\": \"PlotData\" },\n",
    "    { \"class\": \"PlotClusters\" },\n",
    "    { \"class\": \"PlotResults\" },\n",
    "    {\n",
    "      \"dispatch\": [\n",
    "        {\n",
    "          \"model\": {\n",
    "            \"class\": \"sklearn.ensemble.RandomForestClassifier\",\n",
    "            \"params\": { \"random_state\": 42, \"n_estimators\": 100, \"max_depth\": 10 }\n",
    "          },\n",
    "          \"y_pipeline\": { \"class\": \"sklearn.preprocessing.StandardScaler\" }\n",
    "        },\n",
    "        {\n",
    "          \"model\": \"nirs4all.presets.ref_models.decon\",\n",
    "          \"y_pipeline\": { \"class\": \"sklearn.preprocessing.StandardScaler\" }\n",
    "        },\n",
    "        {\n",
    "          \"model\": {\n",
    "            \"class\": \"sklearn.svm.SVC\",\n",
    "            \"params\": { \"kernel\": \"linear\", \"C\": 1.0, \"random_state\": 42 }\n",
    "          },\n",
    "          \"y_pipeline\": [\n",
    "            { \"class\": \"sklearn.preprocessing.MinMaxScaler\" },\n",
    "            { \"class\": \"sklearn.preprocessing.RobustScaler\" }\n",
    "          ],\n",
    "          \"finetune_params\": { \"C\": [0.1, 1.0, 10.0] }\n",
    "        },\n",
    "        {\n",
    "          \"stack\": {\n",
    "            \"model\": {\n",
    "              \"class\": \"sklearn.ensemble.RandomForestClassifier\",\n",
    "              \"params\": { \"random_state\": 42, \"n_estimators\": 100, \"max_depth\": 10 }\n",
    "            },\n",
    "            \"y_pipeline\": { \"class\": \"sklearn.preprocessing.StandardScaler\" },\n",
    "            \"base_learners\": [\n",
    "              {\n",
    "                \"model\": {\n",
    "                  \"class\": \"sklearn.ensemble.GradientBoostingClassifier\",\n",
    "                  \"params\": { \"random_state\": 42, \"n_estimators\": 100, \"max_depth\": 5 }\n",
    "                },\n",
    "                \"y_pipeline\": { \"class\": \"sklearn.preprocessing.MinMaxScaler\" }\n",
    "              },\n",
    "              {\n",
    "                \"model\": {\n",
    "                  \"class\": \"sklearn.tree.DecisionTreeClassifier\",\n",
    "                  \"params\": { \"random_state\": 42, \"max_depth\": 5 }\n",
    "                },\n",
    "                \"y_pipeline\": { \"class\": \"sklearn.preprocessing.MinMaxScaler\" },\n",
    "                \"finetune_params\": { \"max_depth\": [3, 5, 7] }\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    { \"class\": \"PlotModelPerformance\" },\n",
    "    { \"class\": \"PlotFeatureImportance\" },\n",
    "    { \"class\": \"PlotConfusionMatrix\" }\n",
    "  ]\n",
    "}\"\"\"\n",
    "\n",
    "json_config = json.loads(json_string_config)\n",
    "\n",
    "py_config = {\n",
    "    \"experiment\": {\n",
    "        \"action\": \"classification\",\n",
    "        \"dataset\": \"Mock_data_with_2_sources\" ## let suppose 2 sources (time 1 and time 2, for 10k samples with respectively 1000 and 2000 features)\n",
    "    },\n",
    "\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "            \"merge\": \"sources\", # merge the 2 sources into a single dataset\n",
    "        },\n",
    "        MinMaxScaler(),\n",
    "        { \"sample_augmentation\": [ RT, RT(p_range=3) ] }, # From the partition train, create 2 new versions of the sample (create new samples ids with new processing)\n",
    "        { \"feature_augmentation\": [ None, SG, [SNV, GS] ] },  # From the partition train, create 3 new versions of the sample (keep sample id, new processing) [] is a sub pipeline\n",
    "\n",
    "        ShuffleSplit(), # Because we have no test partition for now, the target of the split is to create test partition. Thus split the dataset into train and test partitions.\n",
    "\n",
    "        { \"cluster\": KMeans(n_clusters=5, random_state=42) }, # launch cluster and change group value in indices with the cluster id. From now, the operation are done considering the centroids and applied identically to all the samples of the cluster (ie: scaling with fit on centroids and apply to all samples of the cluster, or split train/test on centroids and apply to all samples of the cluster).\n",
    "\n",
    "        RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42), # populate folds with validation indices and train indices using groups as stratifying variable.\n",
    "\n",
    "        \"uncluster\", # stop using centroids and use all the original samples. If the centroids are construct (sample = None), they are discarded or hidden\n",
    "\n",
    "        \"PlotData\", # mockup for now, just print the dataset information\n",
    "        \"PlotClusters\", # mockup for now, just print the clusters information\n",
    "        \"PlotResults\", # mockup for now, just print the results information\n",
    "\n",
    "        {\n",
    "            \"dispatch\": [ # create as many branches in the pipeline as there are objects in the list. Data from train partition are copied to each branch. Can be used also to split the pipeline per source of data.\n",
    "                {\n",
    "                    \"y_pipeline\": StandardScaler(), # preprocess target data\n",
    "                    \"model\": RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10), # train model and predict on test\n",
    "                },\n",
    "                {\n",
    "                    \"y_pipeline\": [MinMaxScaler(), RobustScaler()] , # preprocess target data with 2 different scalers successively\n",
    "                    \"model\": SVC(kernel='linear', C=1.0, random_state=42), # train model and predict on test\n",
    "                    \"finetune_params\": { # As there are finetune parameters, optuna is used to optimize the model.\n",
    "                        \"C\": [0.1, 1.0, 10.0]\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"stack\": { # create a stack of models, each model is trained on the same data and the predictions are used as features for the next model.\n",
    "                        \"y_pipeline\": StandardScaler(),\n",
    "                        \"model\": RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10),\n",
    "                        \"base_learners\": [\n",
    "                            {\n",
    "                                \"y_pipeline\": MinMaxScaler(),\n",
    "                                \"model\": GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=5),\n",
    "                            },\n",
    "                            {\n",
    "                                \"y_pipeline\": MinMaxScaler(),\n",
    "                                \"model\": DecisionTreeClassifier(random_state=42, max_depth=5),\n",
    "                                \"finetune_params\": {\n",
    "                                    \"max_depth\": [3, 5, 7]\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "\n",
    "        \"PlotModelPerformance\", # a type of graph\n",
    "        \"PlotFeatureImportance\", # a type of graph\n",
    "        \"PlotConfusionMatrix\" # a type of graph\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d701b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'classification', 'dataset': 'data/sample_data.csv'}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SpectraLoader' from 'spectra.SpectraLoader' (d:\\Workspace\\ML\\NIRS\\nirs4all\\examples\\bench\\core\\spectra\\SpectraLoader.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(json_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspectra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSpectraLoader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpectraLoader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspectra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSpectraDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpectraDataset\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SpectraLoader' from 'spectra.SpectraLoader' (d:\\Workspace\\ML\\NIRS\\nirs4all\\examples\\bench\\core\\spectra\\SpectraLoader.py)"
     ]
    }
   ],
   "source": [
    "from spectra.SpectraLoader import SpectraLoader\n",
    "from pipeline.PipelineBuilder import PipelineBuilder\n",
    "from pipeline.PipelineConfig import PipelineConfig\n",
    "\n",
    "config1 = PipelineConfig.from_json(json_config)\n",
    "config2 = PipelineConfig.from_dict(py_config)\n",
    "\n",
    "config1.export(\"config1.yaml\")\n",
    "config2.export(\"config2.yaml\")\n",
    "\n",
    "dataset1 = SpectraLoader.load(config1.experiment)\n",
    "dataset2 = SpectraLoader.load(config2.experiment)\n",
    "\n",
    "pipeline = PipelineBuilder.build(config1)\n",
    "report = pipeline.run(dataset1)\n",
    "results = dataset1.get_results()\n",
    "print(\"Pipeline executed successfully on dataset 1.\")\n",
    "pipeline.export(\"pipeline_test.nirs\")\n",
    "\n",
    "pipeline = PipelineBuilder.build(\"pipeline_test.nirs\")\n",
    "report = pipeline.predict(dataset2)\n",
    "results = dataset2.get_results()\n",
    "print(\"Pipeline executed successfully on new dataset 2.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
