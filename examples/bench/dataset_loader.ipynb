{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7c38901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'type': 'classification', 'folder': './sample_data'}\n",
      ">> Browsing ./sample_data\n",
      "No train_group file found for ./sample_data.\n",
      "No test_group file found for ./sample_data.\n",
      "Dataset key: train_x\n",
      "Dataset value shape: (130, 2151)\n",
      "\n",
      "Dataset key: train_y\n",
      "Dataset value shape: (130, 1)\n",
      "\n",
      "Dataset key: test_x\n",
      "Dataset value shape: (59, 2151)\n",
      "\n",
      "Dataset key: test_y\n",
      "Dataset value shape: (59, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nirs4all.dataset.loader import get_dataset\n",
    "\n",
    "from sample import config as python_config\n",
    "\n",
    "print(python_config[\"dataset\"])\n",
    "\n",
    "dataset = get_dataset(python_config[\"dataset\"], True)\n",
    "for key in dataset.keys():\n",
    "    print(f\"Dataset key: {key}\")\n",
    "    if hasattr(dataset[key], \"shape\"):\n",
    "        print(f\"Dataset value shape: {dataset[key].shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a062ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌─────┬────────┬────────┬───────────┬───────┬────────┬────────────┐\n",
      "│ row ┆ sample ┆ origin ┆ partition ┆ group ┆ branch ┆ processing │\n",
      "│ --- ┆ ---    ┆ ---    ┆ ---       ┆ ---   ┆ ---    ┆ ---        │\n",
      "│ i32 ┆ i32    ┆ i32    ┆ cat       ┆ i8    ┆ i8     ┆ cat        │\n",
      "╞═════╪════════╪════════╪═══════════╪═══════╪════════╪════════════╡\n",
      "│ 0   ┆ 0      ┆ 0      ┆ test      ┆ 0     ┆ 0      ┆ raw        │\n",
      "│ 1   ┆ 1      ┆ 1      ┆ test      ┆ 0     ┆ 0      ┆ raw        │\n",
      "│ 2   ┆ 2      ┆ 2      ┆ test      ┆ 0     ┆ 0      ┆ raw        │\n",
      "│ 3   ┆ 3      ┆ 3      ┆ test      ┆ 0     ┆ 0      ┆ raw        │\n",
      "│ 4   ┆ 4      ┆ 4      ┆ test      ┆ 0     ┆ 0      ┆ raw        │\n",
      "└─────┴────────┴────────┴───────────┴───────┴────────┴────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Workspace\\ML\\nirs4all\\nirs4all\\dataset\\indexer.py:184: CategoricalRemappingWarning: Local categoricals have different encodings, expensive re-encoding is done to perform this merge operation. Consider using a StringCache or an Enum type if the categories are known in advance\n",
      "  self.df = self.df.with_columns(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nirs4all.dataset.features import Features\n",
    "\n",
    "f = Features()\n",
    "\n",
    "# First batch: 3 samples, 2 sources\n",
    "a1 = np.random.randn(3, 4).astype(np.float32)\n",
    "a2 = np.random.randn(3, 8).astype(np.float32)\n",
    "f.add_features({\"partition\": \"train\"}, [a1, a2])\n",
    "\n",
    "# Second batch: 2 new samples\n",
    "b1 = np.random.randn(2, 4).astype(np.float32)\n",
    "b2 = np.random.randn(2, 8).astype(np.float32)\n",
    "f.add_features({\"partition\": \"test\"}, [b1, b2])\n",
    "\n",
    "print(f.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
