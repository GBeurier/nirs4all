{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c38901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'type': 'classification', 'folder': './sample_data'}\n",
      ">> Browsing ./sample_data\n",
      "No train_group file found for ./sample_data.\n",
      "No test_group file found for ./sample_data.\n",
      "Dataset key: train_x\n",
      "Dataset value shape: (130, 2151)\n",
      "\n",
      "Dataset key: train_y\n",
      "Dataset value shape: (130, 1)\n",
      "\n",
      "Dataset key: test_x\n",
      "Dataset value shape: (59, 2151)\n",
      "\n",
      "Dataset key: test_y\n",
      "Dataset value shape: (59, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nirs4all.dataset.loader import get_dataset\n",
    "from sample import config as python_config\n",
    "\n",
    "print(python_config[\"dataset\"])\n",
    "\n",
    "dataset = get_dataset(python_config[\"dataset\"], disjoint=True)\n",
    "for key in dataset.keys():\n",
    "    print(f\"Dataset key: {key}\")\n",
    "    if hasattr(dataset[key], \"shape\"):\n",
    "        print(f\"Dataset value shape: {dataset[key].shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a062ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ShapeError",
     "evalue": "unable to append to a DataFrame of width 7 with a DataFrame of width 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mShapeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m b1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     13\u001b[0m b2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m8\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpartition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(f\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\dataset\\features.py:88\u001b[0m, in \u001b[0;36mFeatures.add_features\u001b[1;34m(self, filter_dict, x_list)\u001b[0m\n\u001b[0;32m     85\u001b[0m         src\u001b[38;5;241m.\u001b[39madd_samples(new_arr)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# 2) ajout des lignes dans l’index (avec overrides éventuels)\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m#  Synchronisation de la copie locale de l’index\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer\u001b[38;5;241m.\u001b[39mdf\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\dataset\\indexer.py:76\u001b[0m, in \u001b[0;36mSampleIndexManager.add_rows\u001b[1;34m(self, n_rows, overrides)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m         cols[col] \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mSeries([val] \u001b[38;5;241m*\u001b[39m n_rows)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\dataset\\indexer.py:195\u001b[0m, in \u001b[0;36mSampleIndexManager.add_samples\u001b[1;34m(self, new_df)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_df: pl\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    Ajoute de nouveaux samples au DataFrame.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m        new_df: DataFrame contenant les nouveaux samples\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvertical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_sorted()\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\polars\\functions\\eager.py:229\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(items, how, rechunk, parallel)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first, pl\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 229\u001b[0m         out \u001b[38;5;241m=\u001b[39m wrap_df(\u001b[43mplr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43melems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical_relaxed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    231\u001b[0m         out \u001b[38;5;241m=\u001b[39m wrap_ldf(\n\u001b[0;32m    232\u001b[0m             plr\u001b[38;5;241m.\u001b[39mconcat_lf(\n\u001b[0;32m    233\u001b[0m                 [df\u001b[38;5;241m.\u001b[39mlazy() \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m elems],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m             )\n\u001b[0;32m    238\u001b[0m         )\u001b[38;5;241m.\u001b[39mcollect(no_optimization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mShapeError\u001b[0m: unable to append to a DataFrame of width 7 with a DataFrame of width 5"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nirs4all.dataset.features import Features\n",
    "\n",
    "f = Features()\n",
    "\n",
    "# First batch: 3 samples, 2 sources\n",
    "a1 = np.random.randn(3, 4).astype(np.float32)\n",
    "a2 = np.random.randn(3, 8).astype(np.float32)\n",
    "f.add_features({\"partition\": \"train\"}, [a1, a2])\n",
    "\n",
    "# Second batch: 2 new samples\n",
    "b1 = np.random.randn(2, 4).astype(np.float32)\n",
    "b2 = np.random.randn(2, 8).astype(np.float32)\n",
    "f.add_features({\"partition\": \"test\"}, [b1, b2])\n",
    "\n",
    "print(f.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
