{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d701b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      ">> Browsing ./sample_data\n",
      "No train_group file found for ./sample_data.\n",
      "No test_group file found for ./sample_data.\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "Python Dataset:\n",
      " FeatureBlock with 1 sources and 189 samples\n",
      "Source 0: FeatureSource(shape=(189, 1, 2151), dtype=float32, processing_ids=['raw'], mean=0.46620577573776245, variance=0.1492786705493927)\n",
      "Unique augmentations: [None]\n",
      "Index:\n",
      "shape: (189, 8)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ row â”† sample â”† origin â”† partition â”† group â”† branch â”† processing â”† augmentation â”‚\n",
      "â”‚ --- â”† ---    â”† ---    â”† ---       â”† ---   â”† ---    â”† ---        â”† ---          â”‚\n",
      "â”‚ i32 â”† i32    â”† i32    â”† cat       â”† i8    â”† i8     â”† cat        â”† cat          â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† 0      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 1   â”† 1      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 2   â”† 2      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 3   â”† 3      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 4   â”† 4      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ â€¦   â”† â€¦      â”† â€¦      â”† â€¦         â”† â€¦     â”† â€¦      â”† â€¦          â”† â€¦            â”‚\n",
      "â”‚ 184 â”† 184    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 185 â”† 185    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 186 â”† 186    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 187 â”† 187    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 188 â”† 188    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "Target: 248 samples\n",
      "  numeric: (59, 1)\n",
      "  raw: (59, 1)\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "Running Python Config:\n",
      "\n",
      "ğŸš€ Starting Pipeline Runner\n",
      "ğŸ”„ Running 6 steps in sequential mode\n",
      "ğŸ”„ Running steps sequentially with shared context\n",
      "ğŸ”¹ 0: Step spectra_charts\n",
      "ğŸ”¹ Current context: {'branch': 0, 'processing': 'raw', 'y': 'numeric'}\n",
      "ğŸ”¹ Step config: spectra_charts\n",
      "ğŸ“‹ Workflow operation: spectra_charts\n",
      "ğŸ”„ Selected controller: <nirs4all.controllers.chart.op_spectra_charts.SpectraChartController object at 0x000002006AC7F010>\n",
      "ğŸ”„ Executing controller SpectraChartController for step: spectra_charts, operator: None, source: -1, context: {'branch': 0, 'processing': 'raw', 'y': 'numeric', 'step_id': 1}\n",
      "ğŸ”„ Running single operator None for step: spectra_charts, source: 0\n",
      "Executing spectra charts for step: spectra_charts, keyword: , source: 0\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset state after step 1:\n",
      "FeatureBlock with 1 sources and 189 samples\n",
      "Source 0: FeatureSource(shape=(189, 1, 2151), dtype=float32, processing_ids=['raw'], mean=0.46620577573776245, variance=0.1492786705493927)\n",
      "Unique augmentations: [None]\n",
      "Index:\n",
      "shape: (189, 8)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ row â”† sample â”† origin â”† partition â”† group â”† branch â”† processing â”† augmentation â”‚\n",
      "â”‚ --- â”† ---    â”† ---    â”† ---       â”† ---   â”† ---    â”† ---        â”† ---          â”‚\n",
      "â”‚ i32 â”† i32    â”† i32    â”† cat       â”† i8    â”† i8     â”† cat        â”† cat          â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† 0      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 1   â”† 1      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 2   â”† 2      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 3   â”† 3      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 4   â”† 4      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ â€¦   â”† â€¦      â”† â€¦      â”† â€¦         â”† â€¦     â”† â€¦      â”† â€¦          â”† â€¦            â”‚\n",
      "â”‚ 184 â”† 184    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 185 â”† 185    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 186 â”† 186    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 187 â”† 187    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â”‚ 188 â”† 188    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”† null         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "Target: 248 samples\n",
      "  numeric: (59, 1)\n",
      "  raw: (59, 1)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "âŒ Pipeline failed: Pipeline step failed: index 59 is out of bounds for axis 0 with size 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: CategoricalRemappingWarning: Local categoricals have different encodings, expensive re-encoding is done to perform this merge operation. Consider using a StringCache or an Enum type if the categories are known in advance\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Workspace\\ML\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 142, in _run_step\n",
      "    return self._execute_controller(controller, step, operator, dataset, context)\n",
      "  File \"C:\\Workspace\\ML\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 199, in _execute_controller\n",
      "    return controller.execute(step, operator, dataset, context, self, source)\n",
      "  File \"C:\\Workspace\\ML\\nirs4all\\nirs4all\\controllers\\chart\\op_spectra_charts.py\", line 39, in execute\n",
      "    y = dataset.y(local_context)\n",
      "  File \"C:\\Workspace\\ML\\nirs4all\\nirs4all\\dataset\\dataset.py\", line 73, in y\n",
      "    return self.targets.y(filter_dict)\n",
      "  File \"C:\\Workspace\\ML\\nirs4all\\nirs4all\\dataset\\targets.py\", line 193, in y\n",
      "    return y_data[filtered_indices]\n",
      "IndexError: index 59 is out of bounds for axis 0 with size 59\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Pipeline step failed: index 59 is out of bounds for axis 0 with size 59",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Workspace\\ML\\nirs4all\\nirs4all\\pipeline\\runner.py:142\u001b[0m, in \u001b[0;36mPipelineRunner._run_step\u001b[1;34m(self, step, dataset, context)\u001b[0m\n\u001b[0;32m    141\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_controller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# self.history.complete_step(step_execution.step_id)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Workspace\\ML\\nirs4all\\nirs4all\\pipeline\\runner.py:199\u001b[0m, in \u001b[0;36mPipelineRunner._execute_controller\u001b[1;34m(self, controller, step, operator, dataset, context, source)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ Running single operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, source: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontroller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workspace\\ML\\nirs4all\\nirs4all\\controllers\\chart\\op_spectra_charts.py:39\u001b[0m, in \u001b[0;36mSpectraChartController.execute\u001b[1;34m(self, step, operator, dataset, context, runner, source)\u001b[0m\n\u001b[0;32m     38\u001b[0m spectra_data \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mx(local_context, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;124m\"\u001b[39m, source\u001b[38;5;241m=\u001b[39msource)\n\u001b[1;32m---> 39\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>\u001b[39m\u001b[38;5;124m\"\u001b[39m, spectra_data\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mC:\\Workspace\\ML\\nirs4all\\nirs4all\\dataset\\dataset.py:73\u001b[0m, in \u001b[0;36mSpectroDataset.y\u001b[1;34m(self, filter_dict, encoding)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21my\u001b[39m(\u001b[38;5;28mself\u001b[39m, filter_dict: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}, encoding: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workspace\\ML\\nirs4all\\nirs4all\\dataset\\targets.py:193\u001b[0m, in \u001b[0;36mTargets.y\u001b[1;34m(self, filter_dict)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m# Convert to row indices for this processing\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# sample_indices = self._samples_to_rows(filtered_indices, processing)\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43my_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfiltered_indices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_data\n",
      "\u001b[1;31mIndexError\u001b[0m: index 59 is out of bounds for axis 0 with size 59",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# json_config = PipelineConfig(\"sample.json\")\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# yaml_config = PipelineConfig(\"sample.yaml\")\u001b[39;00m\n\u001b[0;32m     20\u001b[0m runner \u001b[38;5;241m=\u001b[39m PipelineRunner(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, continue_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 22\u001b[0m res_dataset, history, pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpy_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_py\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workspace\\ML\\nirs4all\\nirs4all\\pipeline\\runner.py:49\u001b[0m, in \u001b[0;36mPipelineRunner.run\u001b[1;34m(self, config, dataset)\u001b[0m\n\u001b[0;32m     46\u001b[0m context \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbranch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequential\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# self.history.complete_execution()\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Pipeline completed successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Workspace\\ML\\nirs4all\\nirs4all\\pipeline\\runner.py:75\u001b[0m, in \u001b[0;36mPipelineRunner.run_steps\u001b[1;34m(self, steps, dataset, context, execution)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ Running steps sequentially with shared context\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m---> 75\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”¹ Updated context after step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\n",
      "File \u001b[1;32mC:\\Workspace\\ML\\nirs4all\\nirs4all\\pipeline\\runner.py:155\u001b[0m, in \u001b[0;36mPipelineRunner._run_step\u001b[1;34m(self, step, dataset, context)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš ï¸ Step failed but continuing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline step failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Pipeline step failed: index 59 is out of bounds for axis 0 with size 59"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "from nirs4all.pipeline.config import PipelineConfig\n",
    "from nirs4all.dataset import SpectroDataset\n",
    "from sample import config as python_config\n",
    "from nirs4all.dataset.loader import get_dataset\n",
    "from nirs4all.controllers.registry import reset_registry\n",
    "from nirs4all.controllers import *\n",
    "\n",
    "dataset_py = get_dataset(python_config[\"dataset\"])\n",
    "print(\"\\n\", \"=\"*200, \"\\nPython Dataset:\\n\", dataset_py)\n",
    "\n",
    "print(\"\\n\", \"=\"*200, \"\\nRunning Python Config:\\n\")\n",
    "py_config = PipelineConfig(python_config)\n",
    "# json_config = PipelineConfig(\"sample.json\")\n",
    "# yaml_config = PipelineConfig(\"sample.yaml\")\n",
    "\n",
    "runner = PipelineRunner(max_workers=4, continue_on_error=False)\n",
    "\n",
    "res_dataset, history, pipeline = runner.run(py_config, dataset_py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b9d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 3] TEST: [1 2 4]\n",
      "TRAIN: [1 2 4] TEST: [0 3]\n",
      "<generator object _BaseKFold.split at 0x000002006DE75070>\n",
      "TRAIN: [0 3] TEST: [1 2 4]\n",
      "TRAIN: [1 2 4] TEST: [0 3]\n"
     ]
    }
   ],
   "source": [
    "# import kfold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# random data for kfold\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [1, 2, 3, 4, 5]\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "t = kf.split(X)\n",
    "print(t)\n",
    "l = list(t)\n",
    "for train_index, test_index in l:\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
