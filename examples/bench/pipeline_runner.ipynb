{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d701b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      ">> Browsing ./sample_data\n",
      "No train_group file found for ./sample_data.\n",
      "No test_group file found for ./sample_data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: CategoricalRemappingWarning: Local categoricals have different encodings, expensive re-encoding is done to perform this merge operation. Consider using a StringCache or an Enum type if the categories are known in advance\n",
      "sys:1: CategoricalRemappingWarning: Local categoricals have different encodings, expensive re-encoding is done to perform this merge operation. Consider using a StringCache or an Enum type if the categories are known in advance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "Python Dataset:\n",
      " FeatureBlock with 1 sources and 189 samples\n",
      "Source 0: FeatureSource(shape=(189, 1, 2151), dtype=float32, processing_ids=['raw'], mean=0.46620577573776245, variance=0.1492786705493927)\n",
      "Index:\n",
      "shape: (189, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ row â”† sample â”† origin â”† partition â”† group â”† branch â”† processing â”‚\n",
      "â”‚ --- â”† ---    â”† ---    â”† ---       â”† ---   â”† ---    â”† ---        â”‚\n",
      "â”‚ i32 â”† i32    â”† i32    â”† cat       â”† i8    â”† i8     â”† cat        â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† 0      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”‚\n",
      "â”‚ 1   â”† 1      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”‚\n",
      "â”‚ 2   â”† 2      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”‚\n",
      "â”‚ 3   â”† 3      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”‚\n",
      "â”‚ 4   â”† 4      â”† null   â”† train     â”† 0     â”† 0      â”† raw        â”‚\n",
      "â”‚ â€¦   â”† â€¦      â”† â€¦      â”† â€¦         â”† â€¦     â”† â€¦      â”† â€¦          â”‚\n",
      "â”‚ 184 â”† 184    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”‚\n",
      "â”‚ 185 â”† 185    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”‚\n",
      "â”‚ 186 â”† 186    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”‚\n",
      "â”‚ 187 â”† 187    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”‚\n",
      "â”‚ 188 â”† 188    â”† null   â”† test      â”† 0     â”† 0      â”† raw        â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "Running Python Config:\n",
      "\n",
      "ğŸš€ Starting Pipeline Runner\n",
      "ğŸ”„ Running 2 steps in sequential mode\n",
      "ğŸ”„ Running steps sequentially with shared context\n",
      "ğŸ”¹ 0: Step Dict with 3 keys\n",
      "ğŸ”¹ Current context: {'branch': 0, 'processing': 'raw'}\n",
      "ğŸ”¹ Step config: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.2, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.2, 0.8))}\n",
      "ğŸ“¦ Deserializing dict operation: class\n",
      "ğŸ”„ Executing controller TransformerMixinController for step: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.2, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.2, 0.8))}, operator: MinMaxScaler(feature_range=(0.2, 0.8)), source: -1, context: {'branch': 0, 'processing': 'raw', 'step_id': 1}\n",
      "ğŸ”„ Running single operator MinMaxScaler(feature_range=(0.2, 0.8)) for step: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.2, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.2, 0.8))}, source: 0\n",
      "Executing transformer operation\n",
      "ğŸ”„ Fitting operator MinMaxScaler_1 with data shape: (130, 2151)\n",
      "ğŸ”„ Transforming data with operator MinMaxScaler_1 with data shape: (189, 2151)\n",
      "âœ… Transformation complete, transformed data shape: (189, 2151)\n",
      "âœ… Successfully applied MinMaxScaler_1 transformation\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset state after step 1:\n",
      "FeatureBlock with 1 sources and 189 samples\n",
      "Source 0: FeatureSource(shape=(189, 1, 2151), dtype=float32, processing_ids=['raw_MinMaxScaler_1'], mean=0.6808587312698364, variance=0.011851510033011436)\n",
      "Index:\n",
      "shape: (189, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ row â”† sample â”† origin â”† partition â”† group â”† branch â”† processing         â”‚\n",
      "â”‚ --- â”† ---    â”† ---    â”† ---       â”† ---   â”† ---    â”† ---                â”‚\n",
      "â”‚ i32 â”† i32    â”† i32    â”† cat       â”† i8    â”† i8     â”† cat                â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† 0      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 1   â”† 1      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 2   â”† 2      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 3   â”† 3      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 4   â”† 4      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ â€¦   â”† â€¦      â”† â€¦      â”† â€¦         â”† â€¦     â”† â€¦      â”† â€¦                  â”‚\n",
      "â”‚ 184 â”† 184    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 185 â”† 185    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 186 â”† 186    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 187 â”† 187    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 188 â”† 188    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ”¹ Updated context after step: {'branch': 0, 'processing': 'raw_MinMaxScaler_1', 'step_id': 1}\n",
      "ğŸ”¹ 1: Step sample_augmentation\n",
      "ğŸ”¹ Current context: {'branch': 0, 'processing': 'raw_MinMaxScaler_1', 'step_id': 1}\n",
      "ğŸ”¹ Step config: {'sample_augmentation': ['nirs4all.operators.augmentation.random.Rotate_Translate', {'class': 'nirs4all.operators.augmentation.random.Rotate_Translate', 'params': {'p_range': 3}, '_runtime_instance': Rotate_Translate(p_range=3)}]}\n",
      "ğŸ“‹ Workflow operation: sample_augmentation\n",
      "ğŸ”„ Executing controller SampleAugmentationController for step: {'sample_augmentation': ['nirs4all.operators.augmentation.random.Rotate_Translate', {'class': 'nirs4all.operators.augmentation.random.Rotate_Translate', 'params': {'p_range': 3}, '_runtime_instance': Rotate_Translate(p_range=3)}]}, operator: None, source: -1, context: {'branch': 0, 'processing': 'raw_MinMaxScaler_1', 'step_id': 2}\n",
      "ğŸ”„ Running single operator None for step: {'sample_augmentation': ['nirs4all.operators.augmentation.random.Rotate_Translate', {'class': 'nirs4all.operators.augmentation.random.Rotate_Translate', 'params': {'p_range': 3}, '_runtime_instance': Rotate_Translate(p_range=3)}]}, source: 0\n",
      "Executing sample augmentation for step: {'sample_augmentation': ['nirs4all.operators.augmentation.random.Rotate_Translate', {'class': 'nirs4all.operators.augmentation.random.Rotate_Translate', 'params': {'p_range': 3}, '_runtime_instance': Rotate_Translate(p_range=3)}]}, keyword: , source: 0\n",
      "shape: (189, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ row â”† sample â”† origin â”† partition â”† group â”† branch â”† processing         â”‚\n",
      "â”‚ --- â”† ---    â”† ---    â”† ---       â”† ---   â”† ---    â”† ---                â”‚\n",
      "â”‚ i32 â”† i32    â”† i32    â”† cat       â”† i8    â”† i8     â”† cat                â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† 0      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 1   â”† 1      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 2   â”† 2      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 3   â”† 3      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 4   â”† 4      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ â€¦   â”† â€¦      â”† â€¦      â”† â€¦         â”† â€¦     â”† â€¦      â”† â€¦                  â”‚\n",
      "â”‚ 184 â”† 184    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 185 â”† 185    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 186 â”† 186    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 187 â”† 187    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 188 â”† 188    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "[189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377]\n",
      "shape: (189, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ row â”† sample â”† origin â”† partition â”† group â”† branch â”† processing         â”‚\n",
      "â”‚ --- â”† ---    â”† ---    â”† ---       â”† ---   â”† ---    â”† ---                â”‚\n",
      "â”‚ i32 â”† i32    â”† i32    â”† cat       â”† i8    â”† i8     â”† cat                â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† 0      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 1   â”† 1      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 2   â”† 2      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 3   â”† 3      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 4   â”† 4      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ â€¦   â”† â€¦      â”† â€¦      â”† â€¦         â”† â€¦     â”† â€¦      â”† â€¦                  â”‚\n",
      "â”‚ 184 â”† 184    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 185 â”† 185    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 186 â”† 186    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 187 â”† 187    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 188 â”† 188    â”† null   â”† test      â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "[378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566]\n",
      "ğŸ”„ Running 2 steps in sequential mode\n",
      "ğŸ”„ Running steps sequentially with separate contexts\n",
      "ğŸ”¹ 2: Step nirs4all.operators.augmentation.random.Rotate_Translate\n",
      "ğŸ”¹ Current context: {'branch': 0, 'processing': 'raw_MinMaxScaler_1', 'step_id': 2, 'sample': [189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377]}\n",
      "ğŸ”¹ Step config: nirs4all.operators.augmentation.random.Rotate_Translate\n",
      "ğŸ“¦ Deserializing str operation: nirs4all.operators.augmentation.random.Rotate_Translate\n",
      "ğŸ”„ Executing controller TransformerMixinController for step: nirs4all.operators.augmentation.random.Rotate_Translate, operator: Rotate_Translate(), source: -1, context: {'branch': 0, 'processing': 'raw_MinMaxScaler_1', 'step_id': 3, 'sample': [189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377]}\n",
      "ğŸ”„ Running single operator Rotate_Translate() for step: nirs4all.operators.augmentation.random.Rotate_Translate, source: 0\n",
      "Executing transformer operation\n",
      "ğŸ”„ Fitting operator Rotate_Translate_3 with data shape: (189, 2151)\n",
      "ğŸ”„ Transforming data with operator Rotate_Translate_3 with data shape: (189, 2151)\n",
      "âœ… Transformation complete, transformed data shape: (189, 2151)\n",
      "âœ… Successfully applied Rotate_Translate_3 transformation\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset state after step 3:\n",
      "FeatureBlock with 1 sources and 567 samples\n",
      "Source 0: FeatureSource(shape=(567, 1, 2151), dtype=float32, processing_ids=['raw_MinMaxScaler_1_Rotate_Translate_3'], mean=0.6830330491065979, variance=0.011796859093010426)\n",
      "Index:\n",
      "shape: (567, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ row â”† sample â”† origin â”† partition â”† group â”† branch â”† processing         â”‚\n",
      "â”‚ --- â”† ---    â”† ---    â”† ---       â”† ---   â”† ---    â”† ---                â”‚\n",
      "â”‚ i32 â”† i32    â”† i32    â”† cat       â”† i8    â”† i8     â”† cat                â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† 0      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 1   â”† 1      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 2   â”† 2      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 3   â”† 3      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 4   â”† 4      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ â€¦   â”† â€¦      â”† â€¦      â”† â€¦         â”† â€¦     â”† â€¦      â”† â€¦                  â”‚\n",
      "â”‚ 562 â”† 562    â”† 184    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 563 â”† 563    â”† 185    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 564 â”† 564    â”† 186    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 565 â”† 565    â”† 187    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 566 â”† 566    â”† 188    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ”¹ 3: Step Dict with 3 keys\n",
      "ğŸ”¹ Current context: {'branch': 0, 'processing': 'raw_MinMaxScaler_1', 'step_id': 2, 'sample': [378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566]}\n",
      "ğŸ”¹ Step config: {'class': 'nirs4all.operators.augmentation.random.Rotate_Translate', 'params': {'p_range': 3}, '_runtime_instance': Rotate_Translate(p_range=3)}\n",
      "ğŸ“¦ Deserializing dict operation: class\n",
      "ğŸ”„ Executing controller TransformerMixinController for step: {'class': 'nirs4all.operators.augmentation.random.Rotate_Translate', 'params': {'p_range': 3}, '_runtime_instance': Rotate_Translate(p_range=3)}, operator: Rotate_Translate(p_range=3), source: -1, context: {'branch': 0, 'processing': 'raw_MinMaxScaler_1', 'step_id': 4, 'sample': [378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566]}\n",
      "ğŸ”„ Running single operator Rotate_Translate(p_range=3) for step: {'class': 'nirs4all.operators.augmentation.random.Rotate_Translate', 'params': {'p_range': 3}, '_runtime_instance': Rotate_Translate(p_range=3)}, source: 0\n",
      "Executing transformer operation\n",
      "ğŸ”„ Fitting operator Rotate_Translate_4 with data shape: (189, 0)\n",
      "ğŸ”„ Transforming data with operator Rotate_Translate_4 with data shape: (189, 0)\n",
      "âŒ Error applying transformation: zero-size array to reduction operation maximum which has no identity\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset state after step 4:\n",
      "FeatureBlock with 1 sources and 567 samples\n",
      "Source 0: FeatureSource(shape=(567, 1, 2151), dtype=float32, processing_ids=['raw_MinMaxScaler_1_Rotate_Translate_3'], mean=0.6830330491065979, variance=0.011796859093010426)\n",
      "Index:\n",
      "shape: (567, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ row â”† sample â”† origin â”† partition â”† group â”† branch â”† processing         â”‚\n",
      "â”‚ --- â”† ---    â”† ---    â”† ---       â”† ---   â”† ---    â”† ---                â”‚\n",
      "â”‚ i32 â”† i32    â”† i32    â”† cat       â”† i8    â”† i8     â”† cat                â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† 0      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 1   â”† 1      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 2   â”† 2      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 3   â”† 3      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 4   â”† 4      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ â€¦   â”† â€¦      â”† â€¦      â”† â€¦         â”† â€¦     â”† â€¦      â”† â€¦                  â”‚\n",
      "â”‚ 562 â”† 562    â”† 184    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 563 â”† 563    â”† 185    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 564 â”† 564    â”† 186    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 565 â”† 565    â”† 187    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 566 â”† 566    â”† 188    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "âŒ Error applying transformation: Pipeline step failed: zero-size array to reduction operation maximum which has no identity\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset state after step 4:\n",
      "FeatureBlock with 1 sources and 567 samples\n",
      "Source 0: FeatureSource(shape=(567, 1, 2151), dtype=float32, processing_ids=['raw_MinMaxScaler_1_Rotate_Translate_3'], mean=0.6830330491065979, variance=0.011796859093010426)\n",
      "Index:\n",
      "shape: (567, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ row â”† sample â”† origin â”† partition â”† group â”† branch â”† processing         â”‚\n",
      "â”‚ --- â”† ---    â”† ---    â”† ---       â”† ---   â”† ---    â”† ---                â”‚\n",
      "â”‚ i32 â”† i32    â”† i32    â”† cat       â”† i8    â”† i8     â”† cat                â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† 0      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 1   â”† 1      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 2   â”† 2      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 3   â”† 3      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 4   â”† 4      â”† null   â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ â€¦   â”† â€¦      â”† â€¦      â”† â€¦         â”† â€¦     â”† â€¦      â”† â€¦                  â”‚\n",
      "â”‚ 562 â”† 562    â”† 184    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 563 â”† 563    â”† 185    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 564 â”† 564    â”† 186    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 565 â”† 565    â”† 187    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â”‚ 566 â”† 566    â”† 188    â”† train     â”† 0     â”† 0      â”† raw_MinMaxScaler_1 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "âŒ Pipeline failed: Pipeline step failed: Pipeline step failed: zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 138, in _run_step\n",
      "    return self._execute_controller(controller, step, operator, dataset, context)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 195, in _execute_controller\n",
      "    return controller.execute(step, operator, dataset, context, self, source)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_transformermixin.py\", line 50, in execute\n",
      "    transformed_data = operator.transform(transformed_data)\n",
      "  File \"d:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\abc_augmenter.py\", line 113, in transform\n",
      "    return self.augment(X, self.apply_on)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\random.py\", line 99, in augment\n",
      "    increment = np.array([deformation(x) * np.std(x) for x in X])\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\random.py\", line 99, in <listcomp>\n",
      "    increment = np.array([deformation(x) * np.std(x) for x in X])\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\random.py\", line 91, in deformation\n",
      "    yI = self.random_gen.uniform(0, max(0, np.max(x) / self.y_factor))  # Ensure yI range is valid\n",
      "  File \"d:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py\", line 3199, in max\n",
      "    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n",
      "  File \"d:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py\", line 86, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "ValueError: zero-size array to reduction operation maximum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 138, in _run_step\n",
      "    return self._execute_controller(controller, step, operator, dataset, context)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 195, in _execute_controller\n",
      "    return controller.execute(step, operator, dataset, context, self, source)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_transformermixin.py\", line 50, in execute\n",
      "    transformed_data = operator.transform(transformed_data)\n",
      "  File \"d:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\abc_augmenter.py\", line 113, in transform\n",
      "    return self.augment(X, self.apply_on)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\random.py\", line 99, in augment\n",
      "    increment = np.array([deformation(x) * np.std(x) for x in X])\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\random.py\", line 99, in <listcomp>\n",
      "    increment = np.array([deformation(x) * np.std(x) for x in X])\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\random.py\", line 91, in deformation\n",
      "    yI = self.random_gen.uniform(0, max(0, np.max(x) / self.y_factor))  # Ensure yI range is valid\n",
      "  File \"d:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py\", line 3199, in max\n",
      "    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n",
      "  File \"d:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py\", line 86, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "ValueError: zero-size array to reduction operation maximum which has no identity\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 138, in _run_step\n",
      "    return self._execute_controller(controller, step, operator, dataset, context)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 195, in _execute_controller\n",
      "    return controller.execute(step, operator, dataset, context, self, source)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\dataset\\op_sample_augmentation.py\", line 56, in execute\n",
      "    runner.run_steps(steps, dataset, contexts, execution=\"sequential\")\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 70, in run_steps\n",
      "    self._run_step(step, dataset, ctx)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 151, in _run_step\n",
      "    raise RuntimeError(f\"Pipeline step failed: {str(e)}\") from e\n",
      "RuntimeError: Pipeline step failed: zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Pipeline step failed: Pipeline step failed: zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:138\u001b[0m, in \u001b[0;36mPipelineRunner._run_step\u001b[1;34m(self, step, dataset, context)\u001b[0m\n\u001b[0;32m    137\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_controller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# self.history.complete_step(step_execution.step_id)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:195\u001b[0m, in \u001b[0;36mPipelineRunner._execute_controller\u001b[1;34m(self, controller, step, operator, dataset, context, source)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ Running single operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, source: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontroller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_transformermixin.py:50\u001b[0m, in \u001b[0;36mTransformerMixinController.execute\u001b[1;34m(self, step, operator, dataset, context, runner, source)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ Transforming data with operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperator_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformed_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m \u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Transformation complete, transformed data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformed_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\abc_augmenter.py:113\u001b[0m, in \u001b[0;36mAugmenter.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    112\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_on\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\random.py:99\u001b[0m, in \u001b[0;36mRotate_Translate.augment\u001b[1;34m(self, X, apply_on)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     increment \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([deformation(x) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X])\n\u001b[0;32m    101\u001b[0m new_X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m+\u001b[39m increment\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\random.py:99\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     increment \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mdeformation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X])\n\u001b[0;32m    101\u001b[0m new_X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m+\u001b[39m increment\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\operators\\augmentation\\random.py:91\u001b[0m, in \u001b[0;36mRotate_Translate.augment.<locals>.deformation\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     90\u001b[0m xI \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_gen\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m yI \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_gen\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_factor))  \u001b[38;5;66;03m# Ensure yI range is valid\u001b[39;00m\n\u001b[0;32m     92\u001b[0m distor \u001b[38;5;241m=\u001b[39m v_angle_p(x_range, xI, yI, p1, p2)\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3199\u001b[0m, in \u001b[0;36mmax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;124;03mReturn the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   3086\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3197\u001b[0m \u001b[38;5;124;03m5\u001b[39;00m\n\u001b[0;32m   3198\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3200\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:138\u001b[0m, in \u001b[0;36mPipelineRunner._run_step\u001b[1;34m(self, step, dataset, context)\u001b[0m\n\u001b[0;32m    137\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_controller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# self.history.complete_step(step_execution.step_id)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:195\u001b[0m, in \u001b[0;36mPipelineRunner._execute_controller\u001b[1;34m(self, controller, step, operator, dataset, context, source)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ Running single operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, source: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontroller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\dataset\\op_sample_augmentation.py:56\u001b[0m, in \u001b[0;36mSampleAugmentationController.execute\u001b[1;34m(self, step, operator, dataset, context, runner, source)\u001b[0m\n\u001b[0;32m     54\u001b[0m     steps\u001b[38;5;241m.\u001b[39mappend(operation)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequential\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:70\u001b[0m, in \u001b[0;36mPipelineRunner.run_steps\u001b[1;34m(self, steps, dataset, context, execution)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, ctx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, context):\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:151\u001b[0m, in \u001b[0;36mPipelineRunner._run_step\u001b[1;34m(self, step, dataset, context)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline step failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Pipeline step failed: zero-size array to reduction operation maximum which has no identity",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# json_config = PipelineConfig(\"sample.json\")\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# yaml_config = PipelineConfig(\"sample.yaml\")\u001b[39;00m\n\u001b[0;32m     20\u001b[0m runner \u001b[38;5;241m=\u001b[39m PipelineRunner(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, continue_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 21\u001b[0m res_dataset, history, pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpy_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_py\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:49\u001b[0m, in \u001b[0;36mPipelineRunner.run\u001b[1;34m(self, config, dataset)\u001b[0m\n\u001b[0;32m     46\u001b[0m context \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbranch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequential\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# self.history.complete_execution()\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Pipeline completed successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:75\u001b[0m, in \u001b[0;36mPipelineRunner.run_steps\u001b[1;34m(self, steps, dataset, context, execution)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ Running steps sequentially with shared context\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m---> 75\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”¹ Updated context after step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:151\u001b[0m, in \u001b[0;36mPipelineRunner._run_step\u001b[1;34m(self, step, dataset, context)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš ï¸ Step failed but continuing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline step failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Pipeline step failed: Pipeline step failed: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "from nirs4all.pipeline.config import PipelineConfig\n",
    "from nirs4all.dataset import SpectroDataset\n",
    "from sample import config as python_config\n",
    "from nirs4all.dataset.loader import get_dataset\n",
    "from nirs4all.controllers.registry import reset_registry\n",
    "from nirs4all.controllers import *\n",
    "\n",
    "dataset_py = get_dataset(python_config[\"dataset\"])\n",
    "print(\"\\n\", \"=\"*200, \"\\nPython Dataset:\\n\", dataset_py)\n",
    "\n",
    "print(\"\\n\", \"=\"*200, \"\\nRunning Python Config:\\n\")\n",
    "py_config = PipelineConfig(python_config)\n",
    "# json_config = PipelineConfig(\"sample.json\")\n",
    "# yaml_config = PipelineConfig(\"sample.yaml\")\n",
    "\n",
    "runner = PipelineRunner(max_workers=4, continue_on_error=False)\n",
    "res_dataset, history, pipeline = runner.run(py_config, dataset_py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd8910",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (307681973.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(dataset_py.features.index[0]\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "print(dataset_py.features.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
