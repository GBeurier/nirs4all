{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d701b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STARTING PIPELINE ===\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mLoading dataset:\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "⚠️ Dataset does not have data for train_group.\n",
      "⚠️ Dataset does not have data for test_group.\n",
      "\u001b[97m📊 Dataset: sample_data\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw'], min=-0.265, max=1.436, mean=0.466, var=0.149)\n",
      "Targets:\n",
      "- samples=189, targets=1, processings=['raw', 'numeric'], min=1.33, max=128.31, mean=30.779, variance=505.168\n",
      "Indexes:\n",
      "- \"train\", ['raw']: 130 samples\n",
      "- \"test\", ['raw']: 59 samples\u001b[0m\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_demo_pipeline_a5af43 on dataset sample_data\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 1: Dict with 3 keys\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved 1_0_MinMaxScaler.pkl to results\\sample_data\\config_demo_pipeline_a5af43\\1_0_MinMaxScaler.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: sample_data\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler1'], min=0.1, max=0.89, mean=0.661, var=0.016)\n",
      "Targets:\n",
      "- samples=189, targets=1, processings=['raw', 'numeric'], min=1.33, max=128.31, mean=30.779, variance=505.168\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler1']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: Dict with 2 keys\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "🔄 Executing cross‑validation with ShuffleSplit\n",
      "🔄 Creating folds for 130 samples using ShuffleSplit\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[91m❌ Pipeline config_demo_pipeline_a5af43 on dataset sample_data failed: \n",
      "Pipeline step failed: 'SpectroDataset' object has no attribute 'set_folds'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 170, in run_step\n",
      "    return self._execute_controller(controller, step, operator, dataset, context)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 220, in _execute_controller\n",
      "    context, binaries = controller.execute(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_split.py\", line 114, in execute\n",
      "    dataset.set_folds(folds)\n",
      "AttributeError: 'SpectroDataset' object has no attribute 'set_folds'. Did you mean: '_folds'?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Pipeline step failed: 'SpectroDataset' object has no attribute 'set_folds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:170\u001b[0m, in \u001b[0;36mPipelineRunner.run_step\u001b[1;34m(self, step, dataset, context, is_substep)\u001b[0m\n\u001b[0;32m    169\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_controller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# self.history.complete_step(step_execution.step_id)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:220\u001b[0m, in \u001b[0;36mPipelineRunner._execute_controller\u001b[1;34m(self, controller, step, operator, dataset, context, source)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔹 Executing controller \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontroller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m without operator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 220\u001b[0m context, binaries \u001b[38;5;241m=\u001b[39m \u001b[43mcontroller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaver\u001b[38;5;241m.\u001b[39msave_binaries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubstep_number, binaries)\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_split.py:114\u001b[0m, in \u001b[0;36mCrossValidatorController.execute\u001b[1;34m(self, step, operator, dataset, context, runner, source)\u001b[0m\n\u001b[0;32m    113\u001b[0m folds \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39msplit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_folds\u001b[49m(folds)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Successfully created \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(fold_splits)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m CV folds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SpectroDataset' object has no attribute 'set_folds'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     config \u001b[38;5;241m=\u001b[39m PipelineConfig(pipeline_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemo_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PipelineRunner()\n\u001b[1;32m---> 28\u001b[0m     res_dataset, history, pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== PIPELINE FINISHED ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# json_config = PipelineConfig(\"sample.json\")\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# yaml_config = PipelineConfig(\"sample.yaml\")\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# Nettoyer le flag après exécution\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:69\u001b[0m, in \u001b[0;36mPipelineRunner.run\u001b[1;34m(self, config, dataset)\u001b[0m\n\u001b[0;32m     66\u001b[0m context \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m: [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m*\u001b[39m dataset\u001b[38;5;241m.\u001b[39mfeatures_sources()}\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequential\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# self.history.complete_execution()\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[94m✅ Pipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m completed successfully on dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:95\u001b[0m, in \u001b[0;36mPipelineRunner.run_steps\u001b[1;34m(self, steps, dataset, context, execution, is_substep)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(context, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# print(\"🔄 Running steps sequentially with shared context\")\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m---> 95\u001b[0m         context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_substep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_substep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;66;03m# print(f\"🔹 Updated context after step: {context}\")\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubstep_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Reset sub-step number after sequential execution\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:183\u001b[0m, in \u001b[0;36mPipelineRunner.run_step\u001b[1;34m(self, step, dataset, context, is_substep)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ Step failed but continuing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline step failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_substep:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Pipeline step failed: 'SpectroDataset' object has no attribute 'set_folds'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %reload_ext autoreload\n",
    "except:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "from nirs4all.pipeline.config import PipelineConfig\n",
    "from nirs4all.dataset import dataset\n",
    "from sample import dataset_config, pipeline_config\n",
    "from nirs4all.dataset.loader import get_dataset\n",
    "from nirs4all.controllers.registry import reset_registry\n",
    "from nirs4all.controllers import *\n",
    "\n",
    "data = get_dataset(dataset_config)\n",
    "config = PipelineConfig(pipeline_config, \"demo_pipeline\")\n",
    "\n",
    "runner = PipelineRunner()\n",
    "res_dataset, history, pipeline = runner.run(config, data)\n",
    "\n",
    "\n",
    "# json_config = PipelineConfig(\"sample.json\")\n",
    "# yaml_config = PipelineConfig(\"sample.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b9d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 3] TEST: [1 2 4]\n",
      "TRAIN: [1 2 4] TEST: [0 3]\n",
      "<generator object _BaseKFold.split at 0x00000232E56CD380>\n",
      "TRAIN: [0 3] TEST: [1 2 4]\n",
      "TRAIN: [1 2 4] TEST: [0 3]\n"
     ]
    }
   ],
   "source": [
    "# import kfold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# random data for kfold\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [1, 2, 3, 4, 5]\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "t = kf.split(X)\n",
    "print(t)\n",
    "l = list(t)\n",
    "for train_index, test_index in l:\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
