{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d701b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      ">> Browsing ./sample_data\n",
      "No train_group file found for ./sample_data.\n",
      "No test_group file found for ./sample_data.\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "Python Dataset:\n",
      " FeatureBlock with 1 sources and 189 samples\n",
      "Source 0: FeatureSource(shape=(189, 1, 2151), dtype=float32, processing_ids=['raw'], mean=0.46620577573776245, variance=0.1492786705493927)\n",
      "Unique augmentations: [None]\n",
      "Index:\n",
      "shape: (189, 8)\n",
      "┌─────┬────────┬────────┬───────────┬───────┬────────┬────────────┬──────────────┐\n",
      "│ row ┆ sample ┆ origin ┆ partition ┆ group ┆ branch ┆ processing ┆ augmentation │\n",
      "│ --- ┆ ---    ┆ ---    ┆ ---       ┆ ---   ┆ ---    ┆ ---        ┆ ---          │\n",
      "│ i32 ┆ i32    ┆ i32    ┆ cat       ┆ i8    ┆ i8     ┆ cat        ┆ cat          │\n",
      "╞═════╪════════╪════════╪═══════════╪═══════╪════════╪════════════╪══════════════╡\n",
      "│ 0   ┆ 0      ┆ null   ┆ train     ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "│ 1   ┆ 1      ┆ null   ┆ train     ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "│ 2   ┆ 2      ┆ null   ┆ train     ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "│ 3   ┆ 3      ┆ null   ┆ train     ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "│ 4   ┆ 4      ┆ null   ┆ train     ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "│ …   ┆ …      ┆ …      ┆ …         ┆ …     ┆ …      ┆ …          ┆ …            │\n",
      "│ 184 ┆ 184    ┆ null   ┆ test      ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "│ 185 ┆ 185    ┆ null   ┆ test      ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "│ 186 ┆ 186    ┆ null   ┆ test      ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "│ 187 ┆ 187    ┆ null   ┆ test      ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "│ 188 ┆ 188    ┆ null   ┆ test      ┆ 0     ┆ 0      ┆ raw        ┆ null         │\n",
      "└─────┴────────┴────────┴───────────┴───────┴────────┴────────────┴──────────────┘\n",
      "Targets: 189 samples\n",
      "  • numeric: (189, 1)\n",
      "  • raw: (189, 1)\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "Running Python Config:\n",
      "\n",
      "🚀 Starting Pipeline Runner\n",
      "🔄 Running 0 steps in sequential mode\n",
      "🔄 Running steps sequentially with shared context\n",
      "✅ Pipeline completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: CategoricalRemappingWarning: Local categoricals have different encodings, expensive re-encoding is done to perform this merge operation. Consider using a StringCache or an Enum type if the categories are known in advance\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "from nirs4all.pipeline.config import PipelineConfig\n",
    "from nirs4all.dataset import SpectroDataset\n",
    "from sample import config as python_config\n",
    "from nirs4all.dataset.loader import get_dataset\n",
    "from nirs4all.controllers.registry import reset_registry\n",
    "from nirs4all.controllers import *\n",
    "\n",
    "dataset_py = get_dataset(python_config[\"dataset\"])\n",
    "print(\"\\n\", \"=\"*200, \"\\nPython Dataset:\\n\", dataset_py)\n",
    "\n",
    "print(\"\\n\", \"=\"*200, \"\\nRunning Python Config:\\n\")\n",
    "py_config = PipelineConfig(python_config)\n",
    "# json_config = PipelineConfig(\"sample.json\")\n",
    "# yaml_config = PipelineConfig(\"sample.yaml\")\n",
    "\n",
    "runner = PipelineRunner(max_workers=4, continue_on_error=False)\n",
    "\n",
    "res_dataset, history, pipeline = runner.run(py_config, dataset_py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b9d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 3] TEST: [1 2 4]\n",
      "TRAIN: [1 2 4] TEST: [0 3]\n",
      "<generator object _BaseKFold.split at 0x000002006DE75070>\n",
      "TRAIN: [0 3] TEST: [1 2 4]\n",
      "TRAIN: [1 2 4] TEST: [0 3]\n"
     ]
    }
   ],
   "source": [
    "# import kfold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# random data for kfold\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [1, 2, 3, 4, 5]\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "t = kf.split(X)\n",
    "print(t)\n",
    "l = list(t)\n",
    "for train_index, test_index in l:\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
