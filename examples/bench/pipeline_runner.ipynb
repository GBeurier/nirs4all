{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d701b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mLoading dataset:\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "‚ö†Ô∏è Dataset does not have data for train_group.\n",
      "‚ö†Ô∏è Dataset does not have data for test_group.\n",
      "\u001b[97müìä Dataset: sample_data\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw'], min=-0.265, max=1.436, mean=0.466, var=0.149)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw']: 130 samples\n",
      "- \"test\", ['raw']: 59 samples\u001b[0m\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94müöÄ Starting pipeline config_demo_pipeline_c3a85c on dataset sample_data\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94müîÑ Running 3 steps in sequential mode\u001b[0m\n",
      "\u001b[92müî∑ Step 1: MinMaxScaler(feature_range=[0.1, 0.8])\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "üíæ Saved 1_0_MinMaxScaler.pkl to results\\sample_data\\config_demo_pipeline_c3a85c\\1_0_MinMaxScaler.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: sample_data\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler1'], min=0.1, max=0.89, mean=0.661, var=0.016)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler1']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 2: y_processing\u001b[0m\n",
      "üîπ Executing controller YTransformerMixinController with operator StandardScaler\n",
      "üíæ Saved 2_StandardScaler_numeric_StandardScaler2.pkl to results\\sample_data\\config_demo_pipeline_c3a85c\\2_StandardScaler_numeric_StandardScaler2.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: üìä Dataset: sample_data\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler1'], min=0.1, max=0.89, mean=0.661, var=0.016)\n",
      "Targets: (samples=189, targets=1, processings=['numeric', 'numeric_StandardScaler2'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "- numeric_StandardScaler2: min=-1.23, max=4.156, mean=0.019\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler1']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 3: (finetune) RandomForestRegressor(max_depth=10, random_state=42)\u001b[0m\n",
      "üîπ Executing controller DummyController with operator RandomForestRegressor\n",
      "üí• Executing dummy operation for step: {'model': {'class': 'sklearn.ensemble._forest.RandomForestRegressor', 'params': {'max_depth': 10, 'random_state': 42}, '_runtime_instance': RandomForestRegressor(max_depth=10, random_state=42)}, 'train_params': {'oob_score': True}, 'finetune_params': {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 20]}}, keyword: , source: -1\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m‚úÖ Pipeline config_demo_pipeline_c3a85c completed successfully on dataset sample_data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Reset autoreload completely\n",
    "try:\n",
    "    %reload_ext autoreload\n",
    "    %autoreload 0  # Disable autoreload\n",
    "    %autoreload 2  # Re-enable with full reload\n",
    "except:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "from nirs4all.pipeline.config import PipelineConfig\n",
    "from nirs4all.dataset import dataset\n",
    "from sample import dataset_config, pipeline_config\n",
    "from nirs4all.dataset.loader import get_dataset\n",
    "from nirs4all.controllers.registry import reset_registry\n",
    "from nirs4all.controllers import *\n",
    "\n",
    "data = get_dataset(dataset_config)\n",
    "config = PipelineConfig(pipeline_config, \"demo_pipeline\")\n",
    "\n",
    "runner = PipelineRunner()\n",
    "res_dataset, history, pipeline = runner.run(config, data)\n",
    "\n",
    "\n",
    "# json_config = PipelineConfig(\"sample.json\")\n",
    "# yaml_config = PipelineConfig(\"sample.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "641cff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "obj = RandomForestRegressor(max_depth=10, random_state=42)\n",
    "print(obj.__class__.__name__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
