{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7a6657",
   "metadata": {},
   "source": [
    "## âš ï¸ Important Configuration Note\n",
    "\n",
    "**NIRS4ALL Pipeline Configuration Format:**\n",
    "\n",
    "All configurations in this notebook use the correct NIRS4ALL pipeline format:\n",
    "\n",
    "```python\n",
    "config = {\n",
    "    \"pipeline\": [\n",
    "        # CV splitter (if needed)\n",
    "        ShuffleSplit(n_splits=3, test_size=0.25),\n",
    "        \n",
    "        # Model configuration\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_average\", \n",
    "                \"use_full_train_for_final\": True,  # Optional\n",
    "                \"n_trials\": 10,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 15)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "The key points:\n",
    "- Use `\"pipeline\"` as the top-level key (not \"name\" or \"steps\")\n",
    "- Pipeline is a **list** of transformers, splitters, and models\n",
    "- Model configurations are **dictionaries** within the pipeline list\n",
    "- `finetune_params` contains all optimization settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af21d027",
   "metadata": {},
   "source": [
    "# NIRS4ALL Finetuning Strategies Demo\n",
    "\n",
    "This notebook demonstrates all the different finetuning strategies and cross-validation modes available in NIRS4ALL.\n",
    "\n",
    "**Features Demonstrated:**\n",
    "- Cross-validation modes: `simple`, `per_fold`, `nested`\n",
    "- Parameter strategies: `per_fold_best`, `global_best`, `global_average`\n",
    "- Full training option: `use_full_train_for_final`\n",
    "- Different model types and parameter spaces\n",
    "\n",
    "All examples use small synthetic datasets for fast execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ccae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Demo dataset: 80 samples, 30 features\n",
      "ğŸ¯ Target range: -4.45 to 10.94\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "from nirs4all.pipeline.config import PipelineConfigs\n",
    "\n",
    "# Generate synthetic dataset for demonstrations\n",
    "np.random.seed(42)\n",
    "\n",
    "def create_demo_dataset():\n",
    "    \"\"\"Create small synthetic dataset for fast demos.\"\"\"\n",
    "    n_samples = 80\n",
    "    n_features = 30\n",
    "\n",
    "    # Create synthetic spectra\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "\n",
    "    # Add spectral-like structure\n",
    "    wavelengths = np.linspace(1000, 2000, n_features)\n",
    "    for i in range(n_samples):\n",
    "        X[i] += 0.3 * np.sin(wavelengths / 150) + 0.2 * np.cos(wavelengths / 200)\n",
    "\n",
    "    # Create target with relationship to spectra\n",
    "    y = (np.sum(X[:, 5:15], axis=1) +\n",
    "         0.5 * np.sum(X[:, 20:25], axis=1) +\n",
    "         0.3 * np.random.randn(n_samples))\n",
    "\n",
    "    return {\n",
    "        'X': X,\n",
    "        'y': y,\n",
    "        'folds': 3,\n",
    "        'train': 0.7,\n",
    "        'val': 0.15,\n",
    "        'test': 0.15,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "demo_data_config = create_demo_dataset()\n",
    "print(f\"ğŸ“Š Demo dataset: {demo_data_config['X'].shape[0]} samples, {demo_data_config['X'].shape[1]} features\")\n",
    "print(f\"ğŸ¯ Target range: {demo_data_config['y'].min():.2f} to {demo_data_config['y'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33cc8d4",
   "metadata": {},
   "source": [
    "## 1. Cross-Validation Modes\n",
    "\n",
    "NIRS4ALL supports three CV modes with different levels of rigor and computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e415392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 1. SIMPLE CV - Optimize on combined data, train on folds\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_simple_demo_1206ac on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 1: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 1_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\1_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: ğŸ“Š Dataset: synthetic_test_dataset\n",
      "Features (samples=80, sources=1):\n",
      "- Source 0: (80, 1, 30), processings=['raw'], min=-3.627, max=3.893, mean=0.06, var=1.071)\n",
      "Targets: (samples=80, targets=1, processings=['numeric'])\n",
      "- numeric: min=-4.451, max=10.943, mean=2.378\n",
      "Indexes:\n",
      "- \"train\", ['raw']: 56 samples\n",
      "- \"test\", ['raw']: 24 samples\n",
      "Folds: [(42, 14), (42, 14), (42, 14)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 2: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸ” Simple CV: Finetuning on full training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-09-26 15:06:53,557] A new study created in memory with name: no-name-32f12f4a-4da6-4e00-99b6-245e75db5b4c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Optimizing 1 parameters with random search (5 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,563] Trial 0 finished with value: 2.831748843780041 and parameters: {'n_components': 1}. Best is trial 0 with value: 2.831748843780041.\n",
      "[I 2025-09-26 15:06:53,568] Trial 1 finished with value: 0.13372231918262292 and parameters: {'n_components': 5}. Best is trial 1 with value: 0.13372231918262292.\n",
      "[I 2025-09-26 15:06:53,575] Trial 2 finished with value: 0.04757569019788793 and parameters: {'n_components': 8}. Best is trial 2 with value: 0.04757569019788793.\n",
      "[I 2025-09-26 15:06:53,580] Trial 3 finished with value: 2.831748843780041 and parameters: {'n_components': 1}. Best is trial 2 with value: 0.04757569019788793.\n",
      "[I 2025-09-26 15:06:53,586] Trial 4 finished with value: 0.09074267040675044 and parameters: {'n_components': 6}. Best is trial 2 with value: 0.04757569019788793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Best parameters found: {'n_components': 8}\n",
      "ğŸ”„ Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "âœ… Simple CV completed successfully\n",
      "ğŸ’¾ Saved 2_finetuned_PLSRegression_1.pkl to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_finetuned_PLSRegression_1.pkl\n",
      "ğŸ’¾ Saved 2_predictions_finetuned_2.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_predictions_finetuned_2.csv\n",
      "ğŸ’¾ Saved 2_trained_PLSRegression_3_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_trained_PLSRegression_3_simple_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 2_predictions_trained_4_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_predictions_trained_4_simple_cv_fold1.csv\n",
      "ğŸ’¾ Saved 2_trained_PLSRegression_5_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_trained_PLSRegression_5_simple_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 2_predictions_trained_6_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_predictions_trained_6_simple_cv_fold2.csv\n",
      "ğŸ’¾ Saved 2_trained_PLSRegression_7_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_trained_PLSRegression_7_simple_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 2_predictions_trained_8_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_simple_demo_1206ac\\2_predictions_trained_8_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_simple_demo_1206ac completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Simple CV completed in 0.2s\n",
      "ğŸ“Š Generated 4 prediction sets\n",
      "ğŸ”‘ Prediction keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2']\n"
     ]
    }
   ],
   "source": [
    "# 1. SIMPLE CV: Fastest, least rigorous\n",
    "print(\"ğŸš€ 1. SIMPLE CV - Optimize on combined data, train on folds\")\n",
    "\n",
    "simple_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),  # Create CV folds\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",  # ğŸ¯ SIMPLE MODE\n",
    "                \"param_strategy\": \"per_fold_best\",\n",
    "                \"n_trials\": 5,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "from nirs4all.dataset.loader import create_synthetic_dataset\n",
    "data = create_synthetic_dataset(demo_data_config)\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(simple_config, \"simple_demo\")\n",
    "runner = PipelineRunner()\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Simple CV completed in {elapsed:.1f}s\")\n",
    "print(f\"ğŸ“Š Generated {len(result._predictions)} prediction sets\")\n",
    "if result._predictions:\n",
    "    print(f\"ğŸ”‘ Prediction keys: {result._predictions.list_keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ee7e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,622] A new study created in memory with name: no-name-bd9baffc-0e32-401a-bc8e-8f624b8dd87a\n",
      "[I 2025-09-26 15:06:53,628] Trial 0 finished with value: 4.32007458039583 and parameters: {'n_components': 3}. Best is trial 0 with value: 4.32007458039583.\n",
      "[I 2025-09-26 15:06:53,634] Trial 1 finished with value: 2.9699056444356553 and parameters: {'n_components': 5}. Best is trial 1 with value: 2.9699056444356553.\n",
      "[I 2025-09-26 15:06:53,640] Trial 2 finished with value: 3.51816225848337 and parameters: {'n_components': 4}. Best is trial 1 with value: 2.9699056444356553.\n",
      "[I 2025-09-26 15:06:53,647] Trial 3 finished with value: 2.5745211957465703 and parameters: {'n_components': 6}. Best is trial 3 with value: 2.5745211957465703.\n",
      "[I 2025-09-26 15:06:53,648] A new study created in memory with name: no-name-efc94447-b19c-4d32-9741-60e03c385621\n",
      "[I 2025-09-26 15:06:53,653] Trial 0 finished with value: 3.2403212969365516 and parameters: {'n_components': 5}. Best is trial 0 with value: 3.2403212969365516.\n",
      "[I 2025-09-26 15:06:53,658] Trial 1 finished with value: 7.078851719046117 and parameters: {'n_components': 1}. Best is trial 0 with value: 3.2403212969365516.\n",
      "[I 2025-09-26 15:06:53,664] Trial 2 finished with value: 2.755811263948262 and parameters: {'n_components': 8}. Best is trial 2 with value: 2.755811263948262.\n",
      "[I 2025-09-26 15:06:53,671] Trial 3 finished with value: 3.9161610667922298 and parameters: {'n_components': 3}. Best is trial 2 with value: 2.755811263948262.\n",
      "[I 2025-09-26 15:06:53,674] A new study created in memory with name: no-name-e0b5a728-7c1c-494c-8eec-77a16cd721b2\n",
      "[I 2025-09-26 15:06:53,679] Trial 0 finished with value: 6.191467358595095 and parameters: {'n_components': 2}. Best is trial 0 with value: 6.191467358595095.\n",
      "[I 2025-09-26 15:06:53,684] Trial 1 finished with value: 6.191467358595095 and parameters: {'n_components': 2}. Best is trial 0 with value: 6.191467358595095.\n",
      "[I 2025-09-26 15:06:53,689] Trial 2 finished with value: 5.207951959181389 and parameters: {'n_components': 4}. Best is trial 2 with value: 5.207951959181389.\n",
      "[I 2025-09-26 15:06:53,694] Trial 3 finished with value: 6.191467358595095 and parameters: {'n_components': 2}. Best is trial 2 with value: 5.207951959181389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš–ï¸ 2. PER-FOLD CV - Optimize on each fold separately\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_per_fold_demo_4c61a9 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 3: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 3_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\3_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 4: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸ” Per-fold CV: Finetuning on each fold with per_fold_best strategy...\n",
      "ğŸ›ï¸ Finetuning fold 1/3...\n",
      "ğŸ” Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "ğŸ›ï¸ Finetuning fold 2/3...\n",
      "ğŸ” Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "ğŸ›ï¸ Finetuning fold 3/3...\n",
      "ğŸ” Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "âœ… Per-fold CV completed successfully\n",
      "ğŸ’¾ Saved 4_finetuned_PLSRegression_9_per_fold_cv_fold1.pkl to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_finetuned_PLSRegression_9_per_fold_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 4_predictions_finetuned_10_per_fold_cv_fold1.csv to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_predictions_finetuned_10_per_fold_cv_fold1.csv\n",
      "ğŸ’¾ Saved 4_finetuned_PLSRegression_11_per_fold_cv_fold2.pkl to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_finetuned_PLSRegression_11_per_fold_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 4_predictions_finetuned_12_per_fold_cv_fold2.csv to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_predictions_finetuned_12_per_fold_cv_fold2.csv\n",
      "ğŸ’¾ Saved 4_finetuned_PLSRegression_13_per_fold_cv_fold3.pkl to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_finetuned_PLSRegression_13_per_fold_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 4_predictions_finetuned_14_per_fold_cv_fold3.csv to results\\synthetic_test_dataset\\config_per_fold_demo_4c61a9\\4_predictions_finetuned_14_per_fold_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_per_fold_demo_4c61a9 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Per-fold CV completed in 0.1s\n",
      "ğŸ“Š Generated 7 prediction sets\n",
      "ğŸ”‘ Prediction keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_2']\n"
     ]
    }
   ],
   "source": [
    "# 2. PER-FOLD CV: Standard approach, good balance\n",
    "print(\"\\nâš–ï¸ 2. PER-FOLD CV - Optimize on each fold separately\")\n",
    "\n",
    "per_fold_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),  # Create CV folds\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",  # ğŸ¯ PER-FOLD MODE\n",
    "                \"param_strategy\": \"per_fold_best\",\n",
    "                \"n_trials\": 4,  # Fewer trials since it runs on each fold\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(per_fold_config, \"per_fold_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Per-fold CV completed in {elapsed:.1f}s\")\n",
    "print(f\"ğŸ“Š Generated {len(result._predictions)} prediction sets\")\n",
    "if result._predictions:\n",
    "    print(f\"ğŸ”‘ Prediction keys: {result._predictions.list_keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb28acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,732] A new study created in memory with name: no-name-47ba55bd-6a50-425a-a78b-906938284dba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¬ 3. NESTED CV - Inner CV for optimization, outer CV for evaluation\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_nested_demo_d52524 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 5: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 5_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_nested_demo_d52524\\5_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 6: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸ” Nested CV: 3 outer folds with inner CV finetuning...\n",
      "ğŸ“Š Parameter strategy: per_fold_best\n",
      "ğŸ‹ï¸ Outer fold 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,743] Trial 0 finished with value: 6.590670929381243 and parameters: {'n_components': 4}. Best is trial 0 with value: 6.590670929381243.\n",
      "[I 2025-09-26 15:06:53,751] Trial 1 finished with value: 6.590670929381243 and parameters: {'n_components': 4}. Best is trial 0 with value: 6.590670929381243.\n",
      "[I 2025-09-26 15:06:53,761] Trial 2 finished with value: 6.378044723814769 and parameters: {'n_components': 6}. Best is trial 2 with value: 6.378044723814769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‹ï¸ Outer fold 2/3..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,767] A new study created in memory with name: no-name-d880af6f-d287-4463-8533-a577757c6b59\n",
      "[I 2025-09-26 15:06:53,775] Trial 0 finished with value: 6.667593489768158 and parameters: {'n_components': 4}. Best is trial 0 with value: 6.667593489768158.\n",
      "[I 2025-09-26 15:06:53,785] Trial 1 finished with value: 6.667593489768158 and parameters: {'n_components': 4}. Best is trial 0 with value: 6.667593489768158.\n",
      "[I 2025-09-26 15:06:53,793] Trial 2 finished with value: 6.695758060721871 and parameters: {'n_components': 5}. Best is trial 0 with value: 6.667593489768158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‹ï¸ Outer fold 3/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,799] A new study created in memory with name: no-name-29aa942b-778d-4942-a6d5-b17451162c8c\n",
      "[I 2025-09-26 15:06:53,809] Trial 0 finished with value: 8.76296574269475 and parameters: {'n_components': 3}. Best is trial 0 with value: 8.76296574269475.\n",
      "[I 2025-09-26 15:06:53,817] Trial 1 finished with value: 8.76296574269475 and parameters: {'n_components': 3}. Best is trial 0 with value: 8.76296574269475.\n",
      "[I 2025-09-26 15:06:53,827] Trial 2 finished with value: 8.55846215593177 and parameters: {'n_components': 6}. Best is trial 2 with value: 8.55846215593177.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Nested CV completed successfully\n",
      "ğŸ’¾ Saved 6_nested_cv_outer_fold1_PLSRegression_15.pkl to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_nested_cv_outer_fold1_PLSRegression_15.pkl\n",
      "ğŸ’¾ Saved 6_predictions_nested_cv_outer_fold1_16.csv to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_predictions_nested_cv_outer_fold1_16.csv\n",
      "ğŸ’¾ Saved 6_nested_cv_outer_fold2_PLSRegression_17.pkl to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_nested_cv_outer_fold2_PLSRegression_17.pkl\n",
      "ğŸ’¾ Saved 6_predictions_nested_cv_outer_fold2_18.csv to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_predictions_nested_cv_outer_fold2_18.csv\n",
      "ğŸ’¾ Saved 6_nested_cv_outer_fold3_PLSRegression_19.pkl to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_nested_cv_outer_fold3_PLSRegression_19.pkl\n",
      "ğŸ’¾ Saved 6_predictions_nested_cv_outer_fold3_20.csv to results\\synthetic_test_dataset\\config_nested_demo_d52524\\6_predictions_nested_cv_outer_fold3_20.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_nested_demo_d52524 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Nested CV completed in 0.1s\n",
      "ğŸ“Š Generated 7 prediction sets\n",
      "ğŸ”‘ Prediction keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_2']\n",
      "\n",
      "â±ï¸ CV Mode Comparison (approximate times):\n",
      "  Simple CV:    Fastest\n",
      "  Per-fold CV:  3x slower\n",
      "  Nested CV:    5-10x slower\n"
     ]
    }
   ],
   "source": [
    "# 3. NESTED CV: Most rigorous, highest computational cost\n",
    "print(\"\\nğŸ”¬ 3. NESTED CV - Inner CV for optimization, outer CV for evaluation\")\n",
    "\n",
    "nested_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),  # Create CV folds\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"nested\",  # ğŸ¯ NESTED MODE\n",
    "                \"inner_cv\": 2,  # Small for demo\n",
    "                \"param_strategy\": \"per_fold_best\",\n",
    "                \"n_trials\": 3,  # Very small for demo\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 6)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(nested_config, \"nested_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Nested CV completed in {elapsed:.1f}s\")\n",
    "print(f\"ğŸ“Š Generated {len(result._predictions)} prediction sets\")\n",
    "if result._predictions:\n",
    "    print(f\"ğŸ”‘ Prediction keys: {result._predictions.list_keys()}\")\n",
    "\n",
    "print(f\"\\nâ±ï¸ CV Mode Comparison (approximate times):\")\n",
    "print(f\"  Simple CV:    Fastest\")\n",
    "print(f\"  Per-fold CV:  3x slower\")\n",
    "print(f\"  Nested CV:    5-10x slower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156262cf",
   "metadata": {},
   "source": [
    "## 2. Parameter Strategies\n",
    "\n",
    "Different strategies for aggregating parameters across cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b62c4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,870] A new study created in memory with name: no-name-5a72dbb9-3963-4172-9283-978c8b9d61d4\n",
      "[I 2025-09-26 15:06:53,876] Trial 0 finished with value: 3.1536673068704446 and parameters: {'n_components': 5}. Best is trial 0 with value: 3.1536673068704446.\n",
      "[I 2025-09-26 15:06:53,882] Trial 1 finished with value: 2.9214336046847986 and parameters: {'n_components': 6}. Best is trial 1 with value: 2.9214336046847986.\n",
      "[I 2025-09-26 15:06:53,887] Trial 2 finished with value: 3.3056925963368826 and parameters: {'n_components': 4}. Best is trial 1 with value: 2.9214336046847986.\n",
      "[I 2025-09-26 15:06:53,891] Trial 3 finished with value: 3.1536673068704446 and parameters: {'n_components': 5}. Best is trial 1 with value: 2.9214336046847986.\n",
      "[I 2025-09-26 15:06:53,893] A new study created in memory with name: no-name-744be270-befa-4e5e-9228-0a1e2eb09935\n",
      "[I 2025-09-26 15:06:53,899] Trial 0 finished with value: 3.8714537446639987 and parameters: {'n_components': 2}. Best is trial 0 with value: 3.8714537446639987.\n",
      "[I 2025-09-26 15:06:53,903] Trial 1 finished with value: 3.8714537446639987 and parameters: {'n_components': 2}. Best is trial 0 with value: 3.8714537446639987.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ 1. PER_FOLD_BEST - Each fold uses its own optimized parameters\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_per_fold_best_demo_4c61a9 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 7: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 7_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\7_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 8: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸ” Per-fold CV: Finetuning on each fold with per_fold_best strategy...\n",
      "ğŸ›ï¸ Finetuning fold 1/3...\n",
      "ğŸ” Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "ğŸ›ï¸ Finetuning fold 2/3...\n",
      "ğŸ” Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,907] Trial 2 finished with value: 3.050189854233274 and parameters: {'n_components': 3}. Best is trial 2 with value: 3.050189854233274.\n",
      "[I 2025-09-26 15:06:53,913] Trial 3 finished with value: 0.9683112065412375 and parameters: {'n_components': 8}. Best is trial 3 with value: 0.9683112065412375.\n",
      "[I 2025-09-26 15:06:53,915] A new study created in memory with name: no-name-14090daf-bc03-4e32-bce1-ccae842f78f6\n",
      "[I 2025-09-26 15:06:53,921] Trial 0 finished with value: 1.7624151984669005 and parameters: {'n_components': 6}. Best is trial 0 with value: 1.7624151984669005.\n",
      "[I 2025-09-26 15:06:53,926] Trial 1 finished with value: 1.9075781663768288 and parameters: {'n_components': 5}. Best is trial 0 with value: 1.7624151984669005.\n",
      "[I 2025-09-26 15:06:53,930] Trial 2 finished with value: 1.7624151984669005 and parameters: {'n_components': 6}. Best is trial 0 with value: 1.7624151984669005.\n",
      "[I 2025-09-26 15:06:53,935] Trial 3 finished with value: 3.7553081951153033 and parameters: {'n_components': 2}. Best is trial 0 with value: 1.7624151984669005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›ï¸ Finetuning fold 3/3...\n",
      "ğŸ” Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "âœ… Per-fold CV completed successfully\n",
      "ğŸ’¾ Saved 8_finetuned_PLSRegression_21_per_fold_cv_fold1.pkl to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_finetuned_PLSRegression_21_per_fold_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 8_predictions_finetuned_22_per_fold_cv_fold1.csv to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_predictions_finetuned_22_per_fold_cv_fold1.csv\n",
      "ğŸ’¾ Saved 8_finetuned_PLSRegression_23_per_fold_cv_fold2.pkl to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_finetuned_PLSRegression_23_per_fold_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 8_predictions_finetuned_24_per_fold_cv_fold2.csv to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_predictions_finetuned_24_per_fold_cv_fold2.csv\n",
      "ğŸ’¾ Saved 8_finetuned_PLSRegression_25_per_fold_cv_fold3.pkl to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_finetuned_PLSRegression_25_per_fold_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 8_predictions_finetuned_26_per_fold_cv_fold3.csv to results\\synthetic_test_dataset\\config_per_fold_best_demo_4c61a9\\8_predictions_finetuned_26_per_fold_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_per_fold_best_demo_4c61a9 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Per-fold best completed in 0.1s\n",
      "ğŸ“Š Generated 10 prediction sets\n"
     ]
    }
   ],
   "source": [
    "# Parameter Strategy 1: PER_FOLD_BEST (default)\n",
    "print(\"ğŸ¯ 1. PER_FOLD_BEST - Each fold uses its own optimized parameters\")\n",
    "\n",
    "per_fold_best_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"per_fold_best\",  # ğŸ¯ DEFAULT STRATEGY\n",
    "                \"n_trials\": 4,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(per_fold_best_config, \"per_fold_best_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Per-fold best completed in {elapsed:.1f}s\")\n",
    "print(f\"ğŸ“Š Generated {len(result._predictions)} prediction sets\")\n",
    "\n",
    "# Get performance\n",
    "if result._predictions:\n",
    "    combined = result._predictions.combine_folds(\n",
    "        \"sample_data\", config.name, \"PLSRegression\", \"test_fold\"\n",
    "    )\n",
    "    if combined:\n",
    "        y_true = combined['y_true'].flatten()\n",
    "        y_pred = combined['y_pred'].flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        print(f\"ğŸ¯ Performance: RMSE={rmse:.3f}, RÂ²={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0651a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:53,963] A new study created in memory with name: no-name-54213c7f-d0e3-4a4f-8f87-64cfbbb76ab2\n",
      "[I 2025-09-26 15:06:53,969] Trial 0 finished with value: 3.119835572618817 and parameters: {'n_components': 5}. Best is trial 0 with value: 3.119835572618817.\n",
      "[I 2025-09-26 15:06:53,974] Trial 1 finished with value: 2.4273903584050704 and parameters: {'n_components': 7}. Best is trial 1 with value: 2.4273903584050704.\n",
      "[I 2025-09-26 15:06:53,979] Trial 2 finished with value: 3.502549045081746 and parameters: {'n_components': 4}. Best is trial 1 with value: 2.4273903584050704.\n",
      "[I 2025-09-26 15:06:53,984] Trial 3 finished with value: 2.6440505475265668 and parameters: {'n_components': 6}. Best is trial 1 with value: 2.4273903584050704.\n",
      "[I 2025-09-26 15:06:53,986] A new study created in memory with name: no-name-6058c8d7-f695-469b-98d3-73b4dbffaa84\n",
      "[I 2025-09-26 15:06:53,991] Trial 0 finished with value: 2.6886753336663625 and parameters: {'n_components': 5}. Best is trial 0 with value: 2.6886753336663625.\n",
      "[I 2025-09-26 15:06:53,997] Trial 1 finished with value: 3.346063408408062 and parameters: {'n_components': 4}. Best is trial 0 with value: 2.6886753336663625.\n",
      "[I 2025-09-26 15:06:54,001] Trial 2 finished with value: 3.346063408408062 and parameters: {'n_components': 4}. Best is trial 0 with value: 2.6886753336663625.\n",
      "[I 2025-09-26 15:06:54,006] Trial 3 finished with value: 2.6886753336663625 and parameters: {'n_components': 5}. Best is trial 0 with value: 2.6886753336663625.\n",
      "[I 2025-09-26 15:06:54,009] A new study created in memory with name: no-name-0e89c2b1-a860-4924-a38f-feb3157c34e6\n",
      "[I 2025-09-26 15:06:54,014] Trial 0 finished with value: 3.3758056643189853 and parameters: {'n_components': 8}. Best is trial 0 with value: 3.3758056643189853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ† 2. GLOBAL_BEST - Single best parameter set for all folds\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_global_best_demo_c0374c on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 9: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 9_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\9_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 10: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸ” Per-fold CV: Finetuning on each fold with global_best strategy...\n",
      "ğŸ›ï¸ Finetuning fold 1/3...\n",
      "ğŸ” Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "ğŸ›ï¸ Finetuning fold 2/3...\n",
      "ğŸ” Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "ğŸ›ï¸ Finetuning fold 3/3...\n",
      "ğŸ” Optimizing 1 parameters with random search (4 trials)...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,020] Trial 1 finished with value: 3.3758056643189853 and parameters: {'n_components': 8}. Best is trial 0 with value: 3.3758056643189853.\n",
      "[I 2025-09-26 15:06:54,025] Trial 2 finished with value: 4.724794511830299 and parameters: {'n_components': 3}. Best is trial 0 with value: 3.3758056643189853.\n",
      "[I 2025-09-26 15:06:54,031] Trial 3 finished with value: 4.724794511830299 and parameters: {'n_components': 3}. Best is trial 0 with value: 3.3758056643189853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Global best parameters: {'n_components': 7}\n",
      "âœ… Per-fold CV completed successfully\n",
      "ğŸ’¾ Saved 10_finetuned_PLSRegression_27_per_fold_cv_fold1.pkl to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_finetuned_PLSRegression_27_per_fold_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 10_predictions_finetuned_28_per_fold_cv_fold1.csv to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_predictions_finetuned_28_per_fold_cv_fold1.csv\n",
      "ğŸ’¾ Saved 10_finetuned_PLSRegression_29_per_fold_cv_fold2.pkl to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_finetuned_PLSRegression_29_per_fold_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 10_predictions_finetuned_30_per_fold_cv_fold2.csv to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_predictions_finetuned_30_per_fold_cv_fold2.csv\n",
      "ğŸ’¾ Saved 10_finetuned_PLSRegression_31_per_fold_cv_fold3.pkl to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_finetuned_PLSRegression_31_per_fold_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 10_predictions_finetuned_32_per_fold_cv_fold3.csv to results\\synthetic_test_dataset\\config_global_best_demo_c0374c\\10_predictions_finetuned_32_per_fold_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_global_best_demo_c0374c completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Global best completed in 0.1s\n",
      "ğŸ“Š Generated 13 prediction sets\n"
     ]
    }
   ],
   "source": [
    "# Parameter Strategy 2: GLOBAL_BEST\n",
    "print(\"\\nğŸ† 2. GLOBAL_BEST - Single best parameter set for all folds\")\n",
    "\n",
    "global_best_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_best\",  # ğŸ¯ GLOBAL BEST STRATEGY\n",
    "                \"n_trials\": 4,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(global_best_config, \"global_best_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Global best completed in {elapsed:.1f}s\")\n",
    "print(f\"ğŸ“Š Generated {len(result._predictions)} prediction sets\")\n",
    "\n",
    "if result._predictions:\n",
    "    combined = result._predictions.combine_folds(\n",
    "        \"sample_data\", config.name, \"PLSRegression\", \"test_fold\"\n",
    "    )\n",
    "    if combined:\n",
    "        y_true = combined['y_true'].flatten()\n",
    "        y_pred = combined['y_pred'].flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        print(f\"ğŸ¯ Performance: RMSE={rmse:.3f}, RÂ²={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79f2733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,068] A new study created in memory with name: no-name-ea4b3d99-c209-4ee4-83e9-591d10e0ce1d\n",
      "[I 2025-09-26 15:06:54,082] Trial 0 finished with value: 10.513848496645641 and parameters: {'n_components': 4}. Best is trial 0 with value: 10.513848496645641.\n",
      "[I 2025-09-26 15:06:54,095] Trial 1 finished with value: 10.513848496645641 and parameters: {'n_components': 4}. Best is trial 0 with value: 10.513848496645641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ 3. GLOBAL_AVERAGE - Optimize by averaging across ALL folds\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_global_average_demo_d7f2f7 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 11: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 11_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\11_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 12: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸŒ Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "ğŸ¯ Optimizing with 3 trials, evaluating each on all 3 folds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,119] Trial 2 finished with value: 11.2829692139246 and parameters: {'n_components': 1}. Best is trial 0 with value: 10.513848496645641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Global best parameters: {'n_components': 4}\n",
      "ğŸ“Š Best average score: 10.5138\n",
      "ğŸ”„ Training 3 final models with global best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "âœ… Global Average CV completed successfully\n",
      "ğŸ’¾ Saved 12_trained_PLSRegression_33_global_avg_cv_fold1.pkl to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_trained_PLSRegression_33_global_avg_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 12_predictions_trained_34_global_avg_cv_fold1.csv to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_predictions_trained_34_global_avg_cv_fold1.csv\n",
      "ğŸ’¾ Saved 12_trained_PLSRegression_35_global_avg_cv_fold2.pkl to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_trained_PLSRegression_35_global_avg_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 12_predictions_trained_36_global_avg_cv_fold2.csv to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_predictions_trained_36_global_avg_cv_fold2.csv\n",
      "ğŸ’¾ Saved 12_trained_PLSRegression_37_global_avg_cv_fold3.pkl to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_trained_PLSRegression_37_global_avg_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 12_predictions_trained_38_global_avg_cv_fold3.csv to results\\synthetic_test_dataset\\config_global_average_demo_d7f2f7\\12_predictions_trained_38_global_avg_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_global_average_demo_d7f2f7 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Global average completed in 0.1s\n",
      "ğŸ“Š Generated 16 prediction sets\n",
      "\n",
      "ğŸ“Š Parameter Strategy Comparison:\n",
      "  per_fold_best:  Each fold optimized individually\n",
      "  global_best:    Best performing params used for all folds\n",
      "  global_average: Params optimized for average performance â­\n"
     ]
    }
   ],
   "source": [
    "# Parameter Strategy 3: GLOBAL_AVERAGE â­ NEW\n",
    "print(\"\\nğŸŒ 3. GLOBAL_AVERAGE - Optimize by averaging across ALL folds\")\n",
    "\n",
    "global_average_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_average\",  # ğŸ¯ NEW STRATEGY\n",
    "                \"n_trials\": 3,  # Fewer trials since more expensive per trial\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(global_average_config, \"global_average_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Global average completed in {elapsed:.1f}s\")\n",
    "print(f\"ğŸ“Š Generated {len(result._predictions)} prediction sets\")\n",
    "\n",
    "if result._predictions:\n",
    "    combined = result._predictions.combine_folds(\n",
    "        \"sample_data\", config.name, \"PLSRegression\", \"test_fold\"\n",
    "    )\n",
    "    if combined:\n",
    "        y_true = combined['y_true'].flatten()\n",
    "        y_pred = combined['y_pred'].flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        print(f\"ğŸ¯ Performance: RMSE={rmse:.3f}, RÂ²={r2:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Parameter Strategy Comparison:\")\n",
    "print(f\"  per_fold_best:  Each fold optimized individually\")\n",
    "print(f\"  global_best:    Best performing params used for all folds\")\n",
    "print(f\"  global_average: Params optimized for average performance â­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae7043",
   "metadata": {},
   "source": [
    "## 3. Full Training Option â­ NEW\n",
    "\n",
    "The `use_full_train_for_final` option lets you use CV for optimization but train the final model on all available training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e04c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,162] A new study created in memory with name: no-name-65d9b59b-4921-4f93-8c3d-c60b5ecb2bae\n",
      "[I 2025-09-26 15:06:54,177] Trial 0 finished with value: 11.53709932036127 and parameters: {'n_components': 4}. Best is trial 0 with value: 11.53709932036127.\n",
      "[I 2025-09-26 15:06:54,191] Trial 1 finished with value: 11.590515481026053 and parameters: {'n_components': 8}. Best is trial 0 with value: 11.53709932036127.\n",
      "[I 2025-09-26 15:06:54,204] Trial 2 finished with value: 11.543476125180026 and parameters: {'n_components': 3}. Best is trial 0 with value: 11.53709932036127.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ TRADITIONAL: Separate models per fold\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_traditional_demo_2f0f5c on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 13: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 13_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\13_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 14: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸŒ Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "ğŸ¯ Optimizing with 3 trials, evaluating each on all 3 folds...\n",
      "ğŸ† Global best parameters: {'n_components': 4}\n",
      "ğŸ“Š Best average score: 11.5371\n",
      "ğŸ”„ Training 3 final models with global best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "âœ… Global Average CV completed successfully\n",
      "ğŸ’¾ Saved 14_trained_PLSRegression_39_global_avg_cv_fold1.pkl to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_trained_PLSRegression_39_global_avg_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 14_predictions_trained_40_global_avg_cv_fold1.csv to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_predictions_trained_40_global_avg_cv_fold1.csv\n",
      "ğŸ’¾ Saved 14_trained_PLSRegression_41_global_avg_cv_fold2.pkl to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_trained_PLSRegression_41_global_avg_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 14_predictions_trained_42_global_avg_cv_fold2.csv to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_predictions_trained_42_global_avg_cv_fold2.csv\n",
      "ğŸ’¾ Saved 14_trained_PLSRegression_43_global_avg_cv_fold3.pkl to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_trained_PLSRegression_43_global_avg_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 14_predictions_trained_44_global_avg_cv_fold3.csv to results\\synthetic_test_dataset\\config_traditional_demo_2f0f5c\\14_predictions_trained_44_global_avg_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_traditional_demo_2f0f5c completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Traditional approach completed in 0.1s\n",
      "ğŸ“Š Generated 19 prediction sets\n",
      "ğŸ”‘ Keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_2']\n"
     ]
    }
   ],
   "source": [
    "# Traditional approach: separate models per fold\n",
    "print(\"ğŸ”„ TRADITIONAL: Separate models per fold\")\n",
    "\n",
    "traditional_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_average\",\n",
    "                \"use_full_train_for_final\": False,  # ğŸ¯ TRADITIONAL\n",
    "                \"n_trials\": 3,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(traditional_config, \"traditional_demo\")\n",
    "result_traditional, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Traditional approach completed in {elapsed:.1f}s\")\n",
    "print(f\"ğŸ“Š Generated {len(result_traditional._predictions)} prediction sets\")\n",
    "print(f\"ğŸ”‘ Keys: {result_traditional._predictions.list_keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5246a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,237] A new study created in memory with name: no-name-2b3dcbba-0aaf-4e7b-a996-223d833689b2\n",
      "[I 2025-09-26 15:06:54,253] Trial 0 finished with value: 9.578812769031337 and parameters: {'n_components': 6}. Best is trial 0 with value: 9.578812769031337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ FULL TRAINING: Single model on combined data â­\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_full_train_demo_c97b52 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 15: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 15_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_full_train_demo_c97b52\\15_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 16: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸŒ Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "ğŸ¯ Optimizing with 3 trials, evaluating each on all 3 folds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,266] Trial 1 finished with value: 9.792100848166182 and parameters: {'n_components': 3}. Best is trial 0 with value: 9.578812769031337.\n",
      "[I 2025-09-26 15:06:54,280] Trial 2 finished with value: 9.578812769031337 and parameters: {'n_components': 6}. Best is trial 0 with value: 9.578812769031337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Global best parameters: {'n_components': 6}\n",
      "ğŸ“Š Best average score: 9.5788\n",
      "ğŸ¯ Training single model on full training data (global_avg)...\n",
      "ğŸ“Š Combined training data: 126 samples\n",
      "ğŸ“Š Combined test data: 42 samples\n",
      "âœ… Applied optimized parameters: {'n_components': 6}\n",
      "ğŸ‹ï¸ Training model with 126 samples...\n",
      "âœ… Single model training on full data completed successfully\n",
      "ğŸ’¾ Saved 16_global_avg_model_PLSRegression_45.pkl to results\\synthetic_test_dataset\\config_full_train_demo_c97b52\\16_global_avg_model_PLSRegression_45.pkl\n",
      "ğŸ’¾ Saved 16_predictions_global_avg_model_46.csv to results\\synthetic_test_dataset\\config_full_train_demo_c97b52\\16_predictions_global_avg_model_46.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_full_train_demo_c97b52 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Full training approach completed in 0.1s\n",
      "ğŸ“Š Generated 20 prediction sets\n",
      "ğŸ”‘ Keys: ['synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_demo_4c61a9_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_per_fold_best_demo_4c61a9_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_global_best_demo_c0374c_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_global_average_demo_d7f2f7_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_0', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_1', 'synthetic_test_dataset_config_traditional_demo_2f0f5c_PLSRegression_test_fold_2', 'synthetic_test_dataset_config_full_train_demo_c97b52_PLSRegression_test_global_avg']\n",
      "\n",
      "ğŸ“Š COMPARISON:\n",
      "  Traditional: 20 prediction sets (multiple models)\n",
      "  Full Train:  20 prediction sets (single model)\n",
      "\n",
      "ğŸ’¡ Full Training Benefits:\n",
      "  âœ“ Uses all available training data\n",
      "  âœ“ Single model for deployment\n",
      "  âœ“ Often better performance\n",
      "  âœ“ Simpler model management\n"
     ]
    }
   ],
   "source": [
    "# NEW Full Training approach: single model on full data\n",
    "print(\"\\nğŸ¯ FULL TRAINING: Single model on combined data â­\")\n",
    "\n",
    "full_train_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",\n",
    "                \"param_strategy\": \"global_average\",\n",
    "                \"use_full_train_for_final\": True,  # ğŸ¯ NEW OPTION\n",
    "                \"n_trials\": 3,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(full_train_config, \"full_train_demo\")\n",
    "result_full_train, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Full training approach completed in {elapsed:.1f}s\")\n",
    "print(f\"ğŸ“Š Generated {len(result_full_train._predictions)} prediction sets\")\n",
    "print(f\"ğŸ”‘ Keys: {result_full_train._predictions.list_keys()}\")\n",
    "\n",
    "# Compare approaches\n",
    "print(f\"\\nğŸ“Š COMPARISON:\")\n",
    "print(f\"  Traditional: {len(result_traditional._predictions)} prediction sets (multiple models)\")\n",
    "print(f\"  Full Train:  {len(result_full_train._predictions)} prediction sets (single model)\")\n",
    "print(f\"\\nğŸ’¡ Full Training Benefits:\")\n",
    "print(f\"  âœ“ Uses all available training data\")\n",
    "print(f\"  âœ“ Single model for deployment\")\n",
    "print(f\"  âœ“ Often better performance\")\n",
    "print(f\"  âœ“ Simpler model management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82467f19",
   "metadata": {},
   "source": [
    "## 4. Different Model Types\n",
    "\n",
    "Test finetuning strategies with different model types and parameter spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aefff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,321] A new study created in memory with name: no-name-54b71f89-56b4-45b1-9fb2-4f5cc442086b\n",
      "[I 2025-09-26 15:06:54,327] Trial 0 finished with value: 0.06641292204265331 and parameters: {'n_components': 6}. Best is trial 0 with value: 0.06641292204265331.\n",
      "[I 2025-09-26 15:06:54,332] Trial 1 finished with value: 0.10276666343404751 and parameters: {'n_components': 5}. Best is trial 0 with value: 0.06641292204265331.\n",
      "[I 2025-09-26 15:06:54,337] Trial 2 finished with value: 0.4159393790482339 and parameters: {'n_components': 3}. Best is trial 0 with value: 0.06641292204265331.\n",
      "[I 2025-09-26 15:06:54,343] Trial 3 finished with value: 0.06641292204265331 and parameters: {'n_components': 6}. Best is trial 0 with value: 0.06641292204265331.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§® 1. PLS Regression - Continuous parameter optimization\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_pls_demo_febb66 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 17: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 17_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\17_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 18: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸ” Simple CV: Finetuning on full training data...\n",
      "ğŸ” Optimizing 1 parameters with random search (5 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,349] Trial 4 finished with value: 0.0409985299268884 and parameters: {'n_components': 8}. Best is trial 4 with value: 0.0409985299268884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Best parameters found: {'n_components': 8}\n",
      "ğŸ”„ Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "âœ… Simple CV completed successfully\n",
      "ğŸ’¾ Saved 18_finetuned_PLSRegression_47.pkl to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_finetuned_PLSRegression_47.pkl\n",
      "ğŸ’¾ Saved 18_predictions_finetuned_48.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_predictions_finetuned_48.csv\n",
      "ğŸ’¾ Saved 18_trained_PLSRegression_49_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_trained_PLSRegression_49_simple_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 18_predictions_trained_50_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_predictions_trained_50_simple_cv_fold1.csv\n",
      "ğŸ’¾ Saved 18_trained_PLSRegression_51_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_trained_PLSRegression_51_simple_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 18_predictions_trained_52_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_predictions_trained_52_simple_cv_fold2.csv\n",
      "ğŸ’¾ Saved 18_trained_PLSRegression_53_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_trained_PLSRegression_53_simple_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 18_predictions_trained_54_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_pls_demo_febb66\\18_predictions_trained_54_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_pls_demo_febb66 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… PLS completed in 0.1s\n",
      "ğŸ¯ PLS Performance: RMSE=0.267, RÂ²=0.995\n"
     ]
    }
   ],
   "source": [
    "# Model 1: PLS Regression (continuous parameter)\n",
    "print(\"ğŸ§® 1. PLS Regression - Continuous parameter optimization\")\n",
    "\n",
    "pls_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",  # Fast for demo\n",
    "                \"param_strategy\": \"global_average\",\n",
    "                \"n_trials\": 5,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 10)  # ğŸ¯ Integer parameter\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(pls_config, \"pls_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… PLS completed in {elapsed:.1f}s\")\n",
    "if result._predictions:\n",
    "    keys = result._predictions.list_keys()\n",
    "    if keys:\n",
    "        key_parts = keys[0].split('_', 3)\n",
    "        if len(key_parts) >= 4:\n",
    "            pred_data = result._predictions.get_prediction_data(*key_parts)\n",
    "            if pred_data:\n",
    "                y_true = pred_data['y_true'].flatten()\n",
    "                y_pred = pred_data['y_pred'].flatten()\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                print(f\"ğŸ¯ PLS Performance: RMSE={rmse:.3f}, RÂ²={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e73d790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,400] A new study created in memory with name: no-name-4a660835-4a59-4865-9879-2563a975a4a4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ 2. Ridge Regression - Float parameter optimization\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_ridge_demo_ca3b40 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 19: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 19_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\19_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 20: (finetune) Ridge()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator Ridge\n",
      "ğŸ” Simple CV: Finetuning on full training data...\n",
      "ğŸ” Optimizing 1 parameters with random search (5 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,405] Trial 0 finished with value: 0.23077033956845602 and parameters: {'alpha': 7.7804537396434705}. Best is trial 0 with value: 0.23077033956845602.\n",
      "[I 2025-09-26 15:06:54,411] Trial 1 finished with value: 0.11347101877133052 and parameters: {'alpha': 3.984846289449217}. Best is trial 1 with value: 0.11347101877133052.\n",
      "[I 2025-09-26 15:06:54,415] Trial 2 finished with value: 0.11366061866283417 and parameters: {'alpha': 3.991897068025448}. Best is trial 1 with value: 0.11347101877133052.\n",
      "[I 2025-09-26 15:06:54,419] Trial 3 finished with value: 0.22531107564767203 and parameters: {'alpha': 7.619147142300146}. Best is trial 1 with value: 0.11347101877133052.\n",
      "[I 2025-09-26 15:06:54,423] Trial 4 finished with value: 0.2102480779091517 and parameters: {'alpha': 7.168890403267846}. Best is trial 1 with value: 0.11347101877133052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Best parameters found: {'alpha': 3.984846289449217}\n",
      "ğŸ”„ Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "âœ… Simple CV completed successfully\n",
      "ğŸ’¾ Saved 20_finetuned_Ridge_55.pkl to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_finetuned_Ridge_55.pkl\n",
      "ğŸ’¾ Saved 20_predictions_finetuned_56.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_predictions_finetuned_56.csv\n",
      "ğŸ’¾ Saved 20_trained_Ridge_57_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_trained_Ridge_57_simple_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 20_predictions_trained_58_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_predictions_trained_58_simple_cv_fold1.csv\n",
      "ğŸ’¾ Saved 20_trained_Ridge_59_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_trained_Ridge_59_simple_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 20_predictions_trained_60_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_predictions_trained_60_simple_cv_fold2.csv\n",
      "ğŸ’¾ Saved 20_trained_Ridge_61_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_trained_Ridge_61_simple_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 20_predictions_trained_62_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_ridge_demo_ca3b40\\20_predictions_trained_62_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_ridge_demo_ca3b40 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Ridge completed in 0.0s\n",
      "ğŸ¯ Ridge Performance: RMSE=0.267, RÂ²=0.995\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Ridge Regression (float parameter)\n",
    "print(\"\\nğŸ“ 2. Ridge Regression - Float parameter optimization\")\n",
    "\n",
    "ridge_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": Ridge(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",\n",
    "                \"param_strategy\": \"global_average\",\n",
    "                \"n_trials\": 5,\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"alpha\": (\"float\", 0.1, 10.0)  # ğŸ¯ Float parameter\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(ridge_config, \"ridge_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Ridge completed in {elapsed:.1f}s\")\n",
    "if result._predictions:\n",
    "    keys = result._predictions.list_keys()\n",
    "    if keys:\n",
    "        key_parts = keys[0].split('_', 3)\n",
    "        if len(key_parts) >= 4:\n",
    "            pred_data = result._predictions.get_prediction_data(*key_parts)\n",
    "            if pred_data:\n",
    "                y_true = pred_data['y_true'].flatten()\n",
    "                y_pred = pred_data['y_pred'].flatten()\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                print(f\"ğŸ¯ Ridge Performance: RMSE={rmse:.3f}, RÂ²={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a49f881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,459] A new study created in memory with name: no-name-726571ba-5209-43e1-886c-3956ce3d8069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ² 3. Random Forest - Mixed parameter types\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_rf_demo_707130 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 21: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 21_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\21_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 22: (finetune) RandomForestRegressor(random_state=42)\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestRegressor\n",
      "ğŸ” Simple CV: Finetuning on full training data...\n",
      "ğŸ” Optimizing 2 parameters with grid search (4 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:54,554] Trial 0 finished with value: 2.900292467644007 and parameters: {'n_estimators': 30, 'max_depth': 3}. Best is trial 0 with value: 2.900292467644007.\n",
      "[I 2025-09-26 15:06:54,683] Trial 1 finished with value: 1.214873214161031 and parameters: {'n_estimators': 30, 'max_depth': 7}. Best is trial 1 with value: 1.214873214161031.\n",
      "[I 2025-09-26 15:06:54,732] Trial 2 finished with value: 1.4688841824561942 and parameters: {'n_estimators': 10, 'max_depth': 7}. Best is trial 1 with value: 1.214873214161031.\n",
      "[I 2025-09-26 15:06:54,773] Trial 3 finished with value: 3.169007985609278 and parameters: {'n_estimators': 10, 'max_depth': 3}. Best is trial 1 with value: 1.214873214161031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Best parameters found: {'n_estimators': 30, 'max_depth': 7}\n",
      "ğŸ”„ Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "âœ… Simple CV completed successfully\n",
      "ğŸ’¾ Saved 22_finetuned_RandomForestRegressor_63.pkl to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_finetuned_RandomForestRegressor_63.pkl\n",
      "ğŸ’¾ Saved 22_predictions_finetuned_64.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_predictions_finetuned_64.csv\n",
      "ğŸ’¾ Saved 22_trained_RandomForestRegressor_65_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_trained_RandomForestRegressor_65_simple_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 22_predictions_trained_66_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_predictions_trained_66_simple_cv_fold1.csv\n",
      "ğŸ’¾ Saved 22_trained_RandomForestRegressor_67_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_trained_RandomForestRegressor_67_simple_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 22_predictions_trained_68_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_predictions_trained_68_simple_cv_fold2.csv\n",
      "ğŸ’¾ Saved 22_trained_RandomForestRegressor_69_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_trained_RandomForestRegressor_69_simple_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 22_predictions_trained_70_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_rf_demo_707130\\22_predictions_trained_70_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_rf_demo_707130 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Random Forest completed in 0.6s\n",
      "ğŸ¯ RF Performance: RMSE=0.267, RÂ²=0.995\n",
      "\n",
      "ğŸ›ï¸ Parameter Type Summary:\n",
      "  PLS:     ('int', min, max) - Integer range\n",
      "  Ridge:   ('float', min, max) - Float range\n",
      "  RF:      [val1, val2, val3] - Categorical list\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Random Forest (categorical and integer parameters)\n",
    "print(\"\\nğŸŒ² 3. Random Forest - Mixed parameter types\")\n",
    "\n",
    "rf_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": RandomForestRegressor(random_state=42),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",\n",
    "                \"param_strategy\": \"per_fold_best\",  # Faster for RF\n",
    "                \"n_trials\": 4,  # RF can be slow\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_estimators\": [10, 20, 30],  # ğŸ¯ Categorical parameter\n",
    "                    \"max_depth\": [3, 5, 7]         # ğŸ¯ Categorical parameter\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(rf_config, \"rf_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"âœ… Random Forest completed in {elapsed:.1f}s\")\n",
    "if result._predictions:\n",
    "    keys = result._predictions.list_keys()\n",
    "    if keys:\n",
    "        key_parts = keys[0].split('_', 3)\n",
    "        if len(key_parts) >= 4:\n",
    "            pred_data = result._predictions.get_prediction_data(*key_parts)\n",
    "            if pred_data:\n",
    "                y_true = pred_data['y_true'].flatten()\n",
    "                y_pred = pred_data['y_pred'].flatten()\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                print(f\"ğŸ¯ RF Performance: RMSE={rmse:.3f}, RÂ²={r2:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ›ï¸ Parameter Type Summary:\")\n",
    "print(f\"  PLS:     ('int', min, max) - Integer range\")\n",
    "print(f\"  Ridge:   ('float', min, max) - Float range\")\n",
    "print(f\"  RF:      [val1, val2, val3] - Categorical list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31121745",
   "metadata": {},
   "source": [
    "## 5. Best Practice Combinations\n",
    "\n",
    "Recommended combinations for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b012969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:55,088] A new study created in memory with name: no-name-d32fd691-786c-4c7c-82dc-45250a413eb3\n",
      "[I 2025-09-26 15:06:55,095] Trial 0 finished with value: 0.14286875830932175 and parameters: {'n_components': 4}. Best is trial 0 with value: 0.14286875830932175.\n",
      "[I 2025-09-26 15:06:55,099] Trial 1 finished with value: 0.7513361955536707 and parameters: {'n_components': 2}. Best is trial 0 with value: 0.14286875830932175.\n",
      "[I 2025-09-26 15:06:55,110] Trial 2 finished with value: 0.14286875830932175 and parameters: {'n_components': 4}. Best is trial 0 with value: 0.14286875830932175.\n",
      "[I 2025-09-26 15:06:55,117] Trial 3 finished with value: 0.06591775050504516 and parameters: {'n_components': 6}. Best is trial 3 with value: 0.06591775050504516.\n",
      "[I 2025-09-26 15:06:55,125] Trial 4 finished with value: 0.05478362071166592 and parameters: {'n_components': 7}. Best is trial 4 with value: 0.05478362071166592.\n",
      "[I 2025-09-26 15:06:55,132] Trial 5 finished with value: 0.05478362071166592 and parameters: {'n_components': 7}. Best is trial 4 with value: 0.05478362071166592.\n",
      "[I 2025-09-26 15:06:55,138] Trial 6 finished with value: 0.33655481082615735 and parameters: {'n_components': 3}. Best is trial 4 with value: 0.05478362071166592.\n",
      "[I 2025-09-26 15:06:55,147] Trial 7 finished with value: 0.033882517664609445 and parameters: {'n_components': 10}. Best is trial 7 with value: 0.033882517664609445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ PROTOTYPING: Fast and simple\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_prototype_demo_608a92 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 23: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 23_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\23_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 24: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸ” Simple CV: Finetuning on full training data...\n",
      "ğŸ” Optimizing 1 parameters with random search (8 trials)...\n",
      "(126, 30) (126,) (14, 30) (14, 1)\n",
      "ğŸ† Best parameters found: {'n_components': 10}\n",
      "ğŸ”„ Training 3 fold models with best parameters...\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "(42, 30) (42,) (14, 30) (14, 1)\n",
      "âœ… Simple CV completed successfully\n",
      "ğŸ’¾ Saved 24_finetuned_PLSRegression_71.pkl to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_finetuned_PLSRegression_71.pkl\n",
      "ğŸ’¾ Saved 24_predictions_finetuned_72.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_predictions_finetuned_72.csv\n",
      "ğŸ’¾ Saved 24_trained_PLSRegression_73_simple_cv_fold1.pkl to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_trained_PLSRegression_73_simple_cv_fold1.pkl\n",
      "ğŸ’¾ Saved 24_predictions_trained_74_simple_cv_fold1.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_predictions_trained_74_simple_cv_fold1.csv\n",
      "ğŸ’¾ Saved 24_trained_PLSRegression_75_simple_cv_fold2.pkl to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_trained_PLSRegression_75_simple_cv_fold2.pkl\n",
      "ğŸ’¾ Saved 24_predictions_trained_76_simple_cv_fold2.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_predictions_trained_76_simple_cv_fold2.csv\n",
      "ğŸ’¾ Saved 24_trained_PLSRegression_77_simple_cv_fold3.pkl to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_trained_PLSRegression_77_simple_cv_fold3.pkl\n",
      "ğŸ’¾ Saved 24_predictions_trained_78_simple_cv_fold3.csv to results\\synthetic_test_dataset\\config_prototype_demo_608a92\\24_predictions_trained_78_simple_cv_fold3.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_prototype_demo_608a92 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Prototyping completed in 0.1s\n",
      "ğŸ’¡ Use for: Quick experiments, initial model testing\n"
     ]
    }
   ],
   "source": [
    "# Use Case 1: Quick Prototyping\n",
    "print(\"ğŸš€ PROTOTYPING: Fast and simple\")\n",
    "\n",
    "prototype_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"simple\",        # âš¡ Fastest CV mode\n",
    "                \"param_strategy\": \"per_fold_best\",  # ğŸ¯ Standard strategy\n",
    "                \"n_trials\": 8,              # ğŸ“Š More trials since it's fast\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 10)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(prototype_config, \"prototype_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "prototype_time = time.time() - start\n",
    "\n",
    "print(f\"âœ… Prototyping completed in {prototype_time:.1f}s\")\n",
    "print(\"ğŸ’¡ Use for: Quick experiments, initial model testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5235491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:55,183] A new study created in memory with name: no-name-1f9f64b2-d1c5-4049-95fc-86970aab3d7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:55,195] Trial 0 finished with value: 14.475699861645126 and parameters: {'n_components': 1}. Best is trial 0 with value: 14.475699861645126.\n",
      "[I 2025-09-26 15:06:55,211] Trial 1 finished with value: 14.389765533135874 and parameters: {'n_components': 8}. Best is trial 1 with value: 14.389765533135874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ PRODUCTION: Best generalization + Single model\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_production_demo_facf04 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 25: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 25_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_production_demo_facf04\\25_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 26: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸŒ Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "ğŸ¯ Optimizing with 6 trials, evaluating each on all 3 folds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 15:06:55,226] Trial 2 finished with value: 14.389765533135874 and parameters: {'n_components': 8}. Best is trial 1 with value: 14.389765533135874.\n",
      "[I 2025-09-26 15:06:55,237] Trial 3 finished with value: 14.475699861645126 and parameters: {'n_components': 1}. Best is trial 1 with value: 14.389765533135874.\n",
      "[I 2025-09-26 15:06:55,252] Trial 4 finished with value: 14.389158122016283 and parameters: {'n_components': 7}. Best is trial 4 with value: 14.389158122016283.\n",
      "[I 2025-09-26 15:06:55,264] Trial 5 finished with value: 14.189845278287764 and parameters: {'n_components': 2}. Best is trial 5 with value: 14.189845278287764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Global best parameters: {'n_components': 2}\n",
      "ğŸ“Š Best average score: 14.1898\n",
      "ğŸ¯ Training single model on full training data (global_avg)...\n",
      "ğŸ“Š Combined training data: 126 samples\n",
      "ğŸ“Š Combined test data: 42 samples\n",
      "âœ… Applied optimized parameters: {'n_components': 2}\n",
      "ğŸ‹ï¸ Training model with 126 samples...\n",
      "âœ… Single model training on full data completed successfully\n",
      "ğŸ’¾ Saved 26_global_avg_model_PLSRegression_79.pkl to results\\synthetic_test_dataset\\config_production_demo_facf04\\26_global_avg_model_PLSRegression_79.pkl\n",
      "ğŸ’¾ Saved 26_predictions_global_avg_model_80.csv to results\\synthetic_test_dataset\\config_production_demo_facf04\\26_predictions_global_avg_model_80.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_production_demo_facf04 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Production approach completed in 0.1s\n",
      "ğŸ’¡ Use for: Production deployment, single model needed\n",
      "ğŸ“Š Models generated: 37 (should be 1 for deployment)\n"
     ]
    }
   ],
   "source": [
    "# Use Case 2: Production Deployment\n",
    "print(\"\\nğŸ¯ PRODUCTION: Best generalization + Single model\")\n",
    "\n",
    "production_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",              # âš–ï¸ Good balance of rigor and speed\n",
    "                \"param_strategy\": \"global_average\", # ğŸŒ Most generalizable parameters\n",
    "                \"use_full_train_for_final\": True,  # ğŸ¯ Single model for deployment\n",
    "                \"n_trials\": 6,                     # ğŸ“Š Moderate trials\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 12)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(production_config, \"production_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "production_time = time.time() - start\n",
    "\n",
    "print(f\"âœ… Production approach completed in {production_time:.1f}s\")\n",
    "print(\"ğŸ’¡ Use for: Production deployment, single model needed\")\n",
    "print(f\"ğŸ“Š Models generated: {len(result._predictions)} (should be 1 for deployment)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ee973ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¬ RESEARCH: Maximum rigor\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_research_demo_4d2c11 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 27: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 27_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\27_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 28: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸ” Nested CV: 3 outer folds with inner CV finetuning...\n",
      "ğŸ“Š Parameter strategy: global_average\n",
      "ğŸ‹ï¸ Outer fold 1/3...\n",
      "ğŸ‹ï¸ Outer fold 2/3...\n",
      "ğŸ‹ï¸ Outer fold 3/3...\n",
      "âœ… Nested CV completed successfully\n",
      "ğŸ’¾ Saved 28_nested_cv_outer_fold1_PLSRegression_81.pkl to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_nested_cv_outer_fold1_PLSRegression_81.pkl\n",
      "ğŸ’¾ Saved 28_predictions_nested_cv_outer_fold1_82.csv to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_predictions_nested_cv_outer_fold1_82.csv\n",
      "ğŸ’¾ Saved 28_nested_cv_outer_fold2_PLSRegression_83.pkl to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_nested_cv_outer_fold2_PLSRegression_83.pkl\n",
      "ğŸ’¾ Saved 28_predictions_nested_cv_outer_fold2_84.csv to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_predictions_nested_cv_outer_fold2_84.csv\n",
      "ğŸ’¾ Saved 28_nested_cv_outer_fold3_PLSRegression_85.pkl to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_nested_cv_outer_fold3_PLSRegression_85.pkl\n",
      "ğŸ’¾ Saved 28_predictions_nested_cv_outer_fold3_86.csv to results\\synthetic_test_dataset\\config_research_demo_4d2c11\\28_predictions_nested_cv_outer_fold3_86.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_research_demo_4d2c11 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "âœ… Research approach completed in 0.1s\n",
      "ğŸ’¡ Use for: Academic publications, unbiased evaluation\n",
      "\n",
      "â±ï¸ Use Case Time Comparison:\n",
      "  Prototyping: 0.1s (fastest)\n",
      "  Production:  0.1s (balanced)\n",
      "  Research:    0.1s (most rigorous)\n"
     ]
    }
   ],
   "source": [
    "# Use Case 3: Research/Academic\n",
    "print(\"\\nğŸ”¬ RESEARCH: Maximum rigor\")\n",
    "\n",
    "research_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"nested\",                # ğŸ“ Most rigorous CV\n",
    "                \"inner_cv\": 2,                      # ğŸ”„ Inner folds (small for demo)\n",
    "                \"param_strategy\": \"global_average\", # ğŸŒ Unbiased parameter selection\n",
    "                \"n_trials\": 4,                      # ğŸ“Š Fewer trials due to high cost\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 8)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(research_config, \"research_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "research_time = time.time() - start\n",
    "\n",
    "print(f\"âœ… Research approach completed in {research_time:.1f}s\")\n",
    "print(\"ğŸ’¡ Use for: Academic publications, unbiased evaluation\")\n",
    "\n",
    "# Time comparison\n",
    "print(f\"\\nâ±ï¸ Use Case Time Comparison:\")\n",
    "print(f\"  Prototyping: {prototype_time:.1f}s (fastest)\")\n",
    "print(f\"  Production:  {production_time:.1f}s (balanced)\")\n",
    "print(f\"  Research:    {research_time:.1f}s (most rigorous)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66dc04",
   "metadata": {},
   "source": [
    "## 6. Summary and Recommendations\n",
    "\n",
    "**Quick Reference Guide:**\n",
    "\n",
    "### CV Modes:\n",
    "- **`simple`**: Fast prototyping, limited rigor\n",
    "- **`per_fold`**: Standard choice, good balance â­\n",
    "- **`nested`**: Research/academic, maximum rigor\n",
    "\n",
    "### Parameter Strategies:\n",
    "- **`per_fold_best`**: Default, each fold optimized individually\n",
    "- **`global_best`**: Consistent parameters across folds\n",
    "- **`global_average`**: Most generalizable parameters â­\n",
    "\n",
    "### Full Training Option:\n",
    "- **`use_full_train_for_final: True`**: Single model, more training data â­\n",
    "- **`use_full_train_for_final: False`**: Multiple models, traditional approach\n",
    "\n",
    "### Recommended Combinations:\n",
    "1. **Prototyping**: `simple` + `per_fold_best`\n",
    "2. **Production**: `per_fold` + `global_average` + `use_full_train_for_final: True` â­\n",
    "3. **Research**: `nested` + `global_average`\n",
    "\n",
    "### Parameter Types:\n",
    "- **Integer**: `(\"int\", min_val, max_val)`\n",
    "- **Float**: `(\"float\", min_val, max_val)`\n",
    "- **Categorical**: `[option1, option2, option3]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbf5ab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† RECOMMENDED SETUP: Production-ready configuration\n",
      "Configuration: {'cv_mode': 'per_fold', 'param_strategy': 'global_average', 'use_full_train_for_final': True, 'n_trials': 10, 'verbose': 1, 'model_params': {'n_components': ('int', 1, 15)}, 'train_params': {'verbose': 0}}\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_recommended_demo_7b54c0 on dataset synthetic_test_dataset\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mğŸ”„ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[92mğŸ”· Step 29: ShuffleSplit(n_splits=3, test_size=0.25)\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "ğŸ’¾ Saved 29_folds_ShuffleSplit.csv to results\\synthetic_test_dataset\\config_recommended_demo_7b54c0\\29_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 30: (finetune) PLSRegression()\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator PLSRegression\n",
      "ğŸŒ Global Average CV: Optimizing parameters across all 3 folds simultaneously...\n",
      "ğŸ¯ Optimizing with 10 trials, evaluating each on all 3 folds...\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 14 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 12 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "âš ï¸ Error in model evaluation: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 9. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 719, in fit\n",
      "    super().fit(X, y)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\", line 299, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 10. Got 11 instead. Reduce `n_components`.\n",
      "\n",
      "ğŸ† Global best parameters: {'n_components': 14}\n",
      "ğŸ“Š Best average score: 0.2513\n",
      "ğŸ¯ Training single model on full training data (global_avg)...\n",
      "ğŸ“Š Combined training data: 126 samples\n",
      "ğŸ“Š Combined test data: 42 samples\n",
      "âœ… Applied optimized parameters: {'n_components': 14}\n",
      "ğŸ‹ï¸ Training model with 126 samples...\n",
      "âœ… Single model training on full data completed successfully\n",
      "ğŸ’¾ Saved 30_global_avg_model_PLSRegression_87.pkl to results\\synthetic_test_dataset\\config_recommended_demo_7b54c0\\30_global_avg_model_PLSRegression_87.pkl\n",
      "ğŸ’¾ Saved 30_predictions_global_avg_model_88.csv to results\\synthetic_test_dataset\\config_recommended_demo_7b54c0\\30_predictions_global_avg_model_88.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94mâœ… Pipeline config_recommended_demo_7b54c0 completed successfully on dataset synthetic_test_dataset\u001b[0m\n",
      "\n",
      "âœ… Recommended setup completed in 0.1s\n",
      "ğŸ“Š Generated 38 prediction sets\n",
      "ğŸ”‘ Final prediction key: synthetic_test_dataset_config_simple_demo_1206ac_PLSRegression_test\n",
      "\n",
      "ğŸ¯ Final Model Performance:\n",
      "  RMSE: 0.2670\n",
      "  RÂ²:   0.9947\n",
      "  Test samples: 14\n",
      "\n",
      "ğŸ‰ Demo completed! You've seen all the finetuning strategies in action.\n",
      "ğŸ’¡ Try different combinations for your specific use case.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n",
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n",
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n",
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n",
      "c:\\Workspace\\ML\\nirs4all\\.venv\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py:348: UserWarning: y residual is constant at iteration 8\n",
      "  warnings.warn(f\"y residual is constant at iteration {k}\")\n"
     ]
    }
   ],
   "source": [
    "# Final demonstration: The recommended production setup\n",
    "print(\"ğŸ† RECOMMENDED SETUP: Production-ready configuration\")\n",
    "\n",
    "recommended_config = {\n",
    "    \"pipeline\": [\n",
    "        ShuffleSplit(n_splits=3, test_size=.25),\n",
    "        {\n",
    "            \"model\": PLSRegression(),\n",
    "            \"finetune_params\": {\n",
    "                \"cv_mode\": \"per_fold\",               # âš–ï¸ Good balance\n",
    "                \"param_strategy\": \"global_average\",  # ğŸŒ Best generalization\n",
    "                \"use_full_train_for_final\": True,   # ğŸ¯ Single deployment model\n",
    "                \"n_trials\": 10,                     # ğŸ“Š Thorough optimization\n",
    "                \"verbose\": 1,\n",
    "                \"model_params\": {\n",
    "                    \"n_components\": (\"int\", 1, 15)\n",
    "                },\n",
    "                \"train_params\": {\"verbose\": 0}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Configuration:\", recommended_config[\"pipeline\"][1][\"finetune_params\"])\n",
    "\n",
    "start = time.time()\n",
    "config = PipelineConfigs(recommended_config, \"recommended_demo\")\n",
    "result, _, _ = runner.run(config, data)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"\\nâœ… Recommended setup completed in {elapsed:.1f}s\")\n",
    "print(f\"ğŸ“Š Generated {len(result._predictions)} prediction sets\")\n",
    "\n",
    "if result._predictions:\n",
    "    keys = result._predictions.list_keys()\n",
    "    print(f\"ğŸ”‘ Final prediction key: {keys[0] if keys else 'None'}\")\n",
    "\n",
    "    if keys:\n",
    "        key_parts = keys[0].split('_', 3)\n",
    "        if len(key_parts) >= 4:\n",
    "            pred_data = result._predictions.get_prediction_data(*key_parts)\n",
    "            if pred_data:\n",
    "                y_true = pred_data['y_true'].flatten()\n",
    "                y_pred = pred_data['y_pred'].flatten()\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "                print(f\"\\nğŸ¯ Final Model Performance:\")\n",
    "                print(f\"  RMSE: {rmse:.4f}\")\n",
    "                print(f\"  RÂ²:   {r2:.4f}\")\n",
    "                print(f\"  Test samples: {len(y_true)}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Demo completed! You've seen all the finetuning strategies in action.\")\n",
    "print(f\"ğŸ’¡ Try different combinations for your specific use case.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
