{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4280f4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 14:42:02,328 - INFO - ================================================================================\n",
      "2025-04-04 14:42:02,328 - INFO - Running config: Config(dataset='../sample_data/binary', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<function nicon_classification at 0x0000023DA3D91120>, experiment={'action': 'finetune', 'task': 'classification', 'finetune_params': {'n_trials': 5, 'model_params': {'filters_1': [8, 16, 32, 64], 'filters_2': [8, 16, 32, 64], 'filters_3': [8, 16, 32, 64]}}, 'training_params': {'epochs': 5, 'verbose': 0}}, seed=246918912)\n",
      "2025-04-04 14:42:02,332 - INFO - ================================================================================\n",
      "2025-04-04 14:42:02,332 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Config 0: config1\n",
      "####################\n",
      ">> Browsing ../sample_data/binary\n",
      "No train_group file found for ../sample_data/binary.\n",
      "No test_group file found for ../sample_data/binary.\n",
      "Attention : Faible score de numéricité (0.00). Le fichier ne semble pas contenir majoritairement de nombres après le header potentiel.\n",
      "Erreur détaillée dans load_csv pour ../sample_data/binary/Xval.csv:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\workspace\\ml\\nirs4all_wizard\\nirs4all\\data\\csv_loader.py\", line 330, in load_csv\n",
      "    data = pd.read_csv(\n",
      "  File \"c:\\Workspace\\ML\\nirs4all_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "  File \"c:\\Workspace\\ML\\nirs4all_env\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py\", line 288, in read\n",
      "    alldata = self._rows_to_cols(content)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all_env\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py\", line 1063, in _rows_to_cols\n",
      "    self._alert_malformed(msg, row_num + 1)\n",
      "  File \"c:\\Workspace\\ML\\nirs4all_env\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py\", line 781, in _alert_malformed\n",
      "    raise ParserError(msg)\n",
      "pandas.errors.ParserError: Expected 1 fields in line 2, saw 1665\n",
      "\n",
      "Error loading test data: Invalid data: x contains errors: Expected 1 fields in line 2, saw 1665\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid data: x contains errors: Expected 1 fields in line 2, saw 1665",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 203\u001b[0m\n\u001b[0;32m    201\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    202\u001b[0m runner \u001b[38;5;241m=\u001b[39m ExperimentRunner([config], resume_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 203\u001b[0m datasets, predictions, scores, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\workspace\\ml\\nirs4all_wizard\\nirs4all\\core\\runner.py:73\u001b[0m, in \u001b[0;36mExperimentRunner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning config: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, config)\n\u001b[1;32m---> 73\u001b[0m dataset_, preds_, scores_, best_params_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m datasets\u001b[38;5;241m.\u001b[39mappend(dataset_)\n\u001b[0;32m     76\u001b[0m predictions\u001b[38;5;241m.\u001b[39mappend(preds_)\n",
      "File \u001b[1;32mc:\\workspace\\ml\\nirs4all_wizard\\nirs4all\\core\\runner.py:28\u001b[0m, in \u001b[0;36mExperimentRunner._run_config\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### LOADING DATASET ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(dataset)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### PROCESSING DATASET ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\workspace\\ml\\nirs4all_wizard\\nirs4all\\data\\dataset_loader.py:167\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m(data_config)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     x_train, y_train \u001b[38;5;241m=\u001b[39m handle_data(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 167\u001b[0m     x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mx_train \u001b[38;5;241m=\u001b[39m x_train\n\u001b[0;32m    169\u001b[0m     dataset\u001b[38;5;241m.\u001b[39my_train_init \u001b[38;5;241m=\u001b[39m y_train\n",
      "File \u001b[1;32mc:\\workspace\\ml\\nirs4all_wizard\\nirs4all\\data\\dataset_loader.py:145\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(config, t_set)\u001b[0m\n\u001b[0;32m    143\u001b[0m x_params \u001b[38;5;241m=\u001b[39m _merge_params(config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_x_params\u001b[39m\u001b[38;5;124m'\u001b[39m), config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_params\u001b[39m\u001b[38;5;124m'\u001b[39m), config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_params\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    144\u001b[0m y_params \u001b[38;5;241m=\u001b[39m _merge_params(config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_y_params\u001b[39m\u001b[38;5;124m'\u001b[39m), config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_params\u001b[39m\u001b[38;5;124m'\u001b[39m), config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_params\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m--> 145\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_XY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mt_set\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mt_set\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_x_filter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m               \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mt_set\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mt_set\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_y_filter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "File \u001b[1;32mc:\\workspace\\ml\\nirs4all_wizard\\nirs4all\\data\\dataset_loader.py:54\u001b[0m, in \u001b[0;36mload_XY\u001b[1;34m(x_path, x_filter, x_params, y_path, y_filter, y_params)\u001b[0m\n\u001b[0;32m     51\u001b[0m x, report \u001b[38;5;241m=\u001b[39m load_csv(x_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx_params)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m report \u001b[38;5;129;01mand\u001b[39;00m report[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid data: x contains errors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid data: x is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid data: x contains errors: Expected 1 fields in line 2, saw 1665"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "import time\n",
    "from nirs4all.presets.ref_models import decon, nicon, customizable_nicon, nicon_classification\n",
    "from nirs4all.presets.preprocessings import decon_set, nicon_set\n",
    "from nirs4all.data_splitters import KennardStoneSplitter\n",
    "from nirs4all.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG, Gaussian as GS, Derivate as  Dv\n",
    "from nirs4all.transformations import Rotate_Translate as RT, Spline_X_Simplification as SXS, Random_X_Operation as RXO\n",
    "from nirs4all.transformations import CropTransformer\n",
    "from nirs4all.core.runner import ExperimentRunner\n",
    "from nirs4all.core.config import Config\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold, RepeatedStratifiedKFold, ShuffleSplit, GroupKFold, StratifiedShuffleSplit, BaseCrossValidator, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "model_sklearn = {\n",
    "    \"class\": \"sklearn.cross_decomposition.PLSRegression\",\n",
    "    \"model_params\": {\n",
    "        \"n_components\": 21,\n",
    "    }\n",
    "}\n",
    "    \n",
    "finetune_pls_experiment = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_components': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "bacon_train = {\"action\": \"train\", \"training_params\": {\"epochs\": 2000, \"batch_size\": 500, \"patience\": 200, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 400}}\n",
    "bacon_train_short = {\"action\": \"train\", \"training_params\": {\"epochs\": 10, \"batch_size\": 500, \"patience\": 20, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 40}}\n",
    "bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 10,\n",
    "        \"verbose\":0\n",
    "    }\n",
    "}\n",
    "\n",
    "full_bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 500,\n",
    "        \"patience\": 100,\n",
    "    },\n",
    "    \"finetune_params\": {\n",
    "        \"nb_trials\": 150,\n",
    "        \"model_params\": {\n",
    "            'spatial_dropout': (float, 0.01, 0.5),\n",
    "            'filters1': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'kernel_size1': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides1': [1, 2, 3, 4, 5],\n",
    "            # 'activation1': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'dropout_rate': (float, 0.01, 0.5),\n",
    "            'filters2': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size2': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides2': [1, 2, 3, 4, 5],\n",
    "            'activation2': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'normalization_method1': ['BatchNormalization', 'LayerNormalization'],\n",
    "            'filters3': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size3': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides3': [1, 2, 3, 4, 5],\n",
    "            'activation3': ['relu', 'selu', 'elu', 'swish'],\n",
    "            # 'normalization_method2': ['BatchNormalization', 'LayerNormalization'],\n",
    "            # 'dense_units': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'dense_activation': ['relu', 'selu', 'elu', 'swish'],\n",
    "        },\n",
    "        # \"training_params\": {\n",
    "        #     \"batch_size\": [32, 64, 128, 256, 512],\n",
    "        #     \"cyclic_lr\": [True, False],\n",
    "        #     \"base_lr\": (float, 1e-6, 1e-2),\n",
    "        #     \"max_lr\": (float, 1e-3, 1e-1),\n",
    "        #     \"step_size\": (int, 500, 5000),\n",
    "        # },\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "x_pipeline_full = [\n",
    "    RobustScaler(),\n",
    "    {\"samples\": [None, None, None, None, SXS, RXO]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "\n",
    "bacon_finetune_classif = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 5,\n",
    "        \"verbose\":0\n",
    "    }\n",
    "}\n",
    "\n",
    "finetune_randomForestclassifier = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_estimators': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "x_pipeline_PLS = [\n",
    "    RobustScaler(),\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "            \n",
    "            \n",
    "x_pipeline = [\n",
    "    RobustScaler(), \n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)}, \n",
    "    # bacon_set(),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "x_pipelineb = [\n",
    "    RobustScaler(), \n",
    "    {\"samples\": [RT(6)], \"balance\": True},\n",
    "    # {\"samples\": [None, RT]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)}, \n",
    "    # {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "\n",
    "y_pipeline = MinMaxScaler()\n",
    "\n",
    "seed = 123459456\n",
    "\n",
    "# processing only\n",
    "config1 = Config(\"../sample_data/regression\", x_pipeline_full, y_pipeline, None, None, seed)\n",
    "## TRAINING\n",
    "# regression\n",
    "config2 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, nicon, bacon_train_short, seed)\n",
    "config3 = Config(\"../sample_data/regression\", x_pipeline_PLS, y_pipeline, model_sklearn, None, seed)\n",
    "# classification\n",
    "config4 = Config(\"../sample_data/classification\", x_pipeline, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":10, \"patience\": 100, \"verbose\":0}}, seed*2)\n",
    "config4b = Config(\"../sample_data/binary\", x_pipelineb, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":10, \"patience\": 100, \"verbose\":0}}, seed*2)\n",
    "config5 = Config(\"../sample_data/binary\", x_pipeline, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":5}, \"verbose\":0}, seed*2)\n",
    "config6 = Config(\"../sample_data/classification\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "config7 = Config(\"../sample_data/binary\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "## FINETUNING\n",
    "# regression\n",
    "config8 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, nicon, bacon_finetune, seed)\n",
    "config9 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, model_sklearn, finetune_pls_experiment, seed)\n",
    "# classification\n",
    "config10 = Config(\"../sample_data/classification\", x_pipeline, None, nicon_classification, bacon_finetune_classif, seed*2)\n",
    "config10b = Config(\"../sample_data/binary\", x_pipeline, None, nicon_classification, bacon_finetune_classif, seed*2)\n",
    "config11 = Config(\"../sample_data/classification\", x_pipelineb, None, RandomForestClassifier, finetune_randomForestclassifier, seed*2)\n",
    "config11b = Config(\"../sample_data/binary\", x_pipeline, None, RandomForestClassifier, finetune_randomForestclassifier, seed*2)\n",
    "\n",
    "\n",
    "# configs = [config1, config2, config3, config4, config4b, config5, config6, config7, config8, config9, config10, config10b, config11, config11b]\n",
    "configs = [config10b, config11, config11b]\n",
    "config_names = [\"config1\", \"config2\", \"config3\", \"config4\", \"config4b\", \"config5\", \"config6\", \"config7\", \"config8\", \"config9\", \"config10\", \"config10b\", \"config11\", \"config11b\"]\n",
    "for i, config in enumerate(configs):\n",
    "    print(\"#\" * 20)\n",
    "    print(f\"Config {i}: {config_names[i]}\")\n",
    "    print(\"#\" * 20)\n",
    "    start = time.time()\n",
    "    runner = ExperimentRunner([config], resume_mode=\"restart\")\n",
    "    datasets, predictions, scores, best_params = runner.run()\n",
    "    end = time.time()\n",
    "    print(f\"Time elapsed: {end-start} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nirs4all_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
