{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4280f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "import time\n",
    "from nirs4all.presets.ref_models import decon, nicon, customizable_nicon, nicon_classification\n",
    "from nirs4all.presets.preprocessings import decon_set, nicon_set\n",
    "from nirs4all.data_splitters import KennardStoneSplitter\n",
    "from nirs4all.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG, Gaussian as GS, Derivate as  Dv\n",
    "from nirs4all.transformations import Rotate_Translate as RT, Spline_X_Simplification as SXS, Random_X_Operation as RXO\n",
    "from nirs4all.transformations import CropTransformer\n",
    "from nirs4all.core.runner import ExperimentRunner\n",
    "from nirs4all.core.config import Config\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold, RepeatedStratifiedKFold, ShuffleSplit, GroupKFold, StratifiedShuffleSplit, BaseCrossValidator, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "model_sklearn = {\n",
    "    \"class\": \"sklearn.cross_decomposition.PLSRegression\",\n",
    "    \"model_params\": {\n",
    "        \"n_components\": 21,\n",
    "    }\n",
    "}\n",
    "    \n",
    "finetune_pls_experiment = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_components': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "bacon_train = {\"action\": \"train\", \"training_params\": {\"epochs\": 2000, \"batch_size\": 500, \"patience\": 200, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 400}}\n",
    "bacon_train_short = {\"action\": \"train\", \"training_params\": {\"epochs\": 10, \"batch_size\": 500, \"patience\": 20, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 40}}\n",
    "bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 10,\n",
    "        \"verbose\":0\n",
    "    }\n",
    "}\n",
    "\n",
    "full_bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 500,\n",
    "        \"patience\": 100,\n",
    "    },\n",
    "    \"finetune_params\": {\n",
    "        \"nb_trials\": 150,\n",
    "        \"model_params\": {\n",
    "            'spatial_dropout': (float, 0.01, 0.5),\n",
    "            'filters1': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'kernel_size1': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides1': [1, 2, 3, 4, 5],\n",
    "            # 'activation1': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'dropout_rate': (float, 0.01, 0.5),\n",
    "            'filters2': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size2': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides2': [1, 2, 3, 4, 5],\n",
    "            'activation2': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'normalization_method1': ['BatchNormalization', 'LayerNormalization'],\n",
    "            'filters3': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size3': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides3': [1, 2, 3, 4, 5],\n",
    "            'activation3': ['relu', 'selu', 'elu', 'swish'],\n",
    "            # 'normalization_method2': ['BatchNormalization', 'LayerNormalization'],\n",
    "            # 'dense_units': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'dense_activation': ['relu', 'selu', 'elu', 'swish'],\n",
    "        },\n",
    "        # \"training_params\": {\n",
    "        #     \"batch_size\": [32, 64, 128, 256, 512],\n",
    "        #     \"cyclic_lr\": [True, False],\n",
    "        #     \"base_lr\": (float, 1e-6, 1e-2),\n",
    "        #     \"max_lr\": (float, 1e-3, 1e-1),\n",
    "        #     \"step_size\": (int, 500, 5000),\n",
    "        # },\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "x_pipeline_full = [\n",
    "    RobustScaler(),\n",
    "    {\"samples\": [None, None, None, None, SXS, RXO]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "\n",
    "bacon_finetune_classif = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 5,\n",
    "        \"verbose\":0\n",
    "    }\n",
    "}\n",
    "\n",
    "finetune_randomForestclassifier = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_estimators': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "x_pipeline_PLS = [\n",
    "    RobustScaler(),\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "            \n",
    "            \n",
    "x_pipeline = [\n",
    "    RobustScaler(), \n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)}, \n",
    "    # bacon_set(),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "x_pipelineb = [\n",
    "    RobustScaler(), \n",
    "    {\"samples\": [RT(6)], \"balance\": True},\n",
    "    # {\"samples\": [None, RT]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)}, \n",
    "    # {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "\n",
    "y_pipeline = MinMaxScaler()\n",
    "\n",
    "seed = 123459456\n",
    "\n",
    "# processing only\n",
    "config1 = Config(\"../sample_data/regression\", x_pipeline_full, y_pipeline, None, None, seed)\n",
    "## TRAINING\n",
    "# regression\n",
    "config2 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, nicon, bacon_train_short, seed)\n",
    "config3 = Config(\"../sample_data/regression\", x_pipeline_PLS, y_pipeline, PLSRegression(n_components=10), None, seed)\n",
    "# classification\n",
    "config4 = Config(\"../sample_data/classification\", x_pipeline, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":10, \"patience\": 100, \"verbose\":0}}, seed*2)\n",
    "config4b = Config(\"../sample_data/binary\", x_pipelineb, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":10, \"patience\": 100, \"verbose\":0}}, seed*2)\n",
    "config5 = Config(\"../sample_data/binary\", x_pipeline, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":5}, \"verbose\":0}, seed*2)\n",
    "config6 = Config(\"../sample_data/classification\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "config7 = Config(\"../sample_data/binary\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "## FINETUNING\n",
    "# regression\n",
    "config8 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, nicon, bacon_finetune, seed)\n",
    "config9 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, model_sklearn, finetune_pls_experiment, seed)\n",
    "# classification\n",
    "config10 = Config(\"../sample_data/classification\", x_pipeline, None, nicon_classification, bacon_finetune_classif, seed*2)\n",
    "config10b = Config(\"../sample_data/binary\", x_pipeline, None, nicon_classification, bacon_finetune_classif, seed*2)\n",
    "config11 = Config(\"../sample_data/classification\", x_pipelineb, None, RandomForestClassifier, finetune_randomForestclassifier, seed*2)\n",
    "config11b = Config(\"../sample_data/binary\", x_pipeline, None, RandomForestClassifier, finetune_randomForestclassifier, seed*2)\n",
    "\n",
    "\n",
    "# configs = [config1, config2, config3, config4, config4b, config5, config6, config7, config8, config9, config10, config10b, config11, config11b]\n",
    "# configs = [config10b, config11, config11b]\n",
    "# configs = [config3]\n",
    "# config_names = [\"config1\", \"config2\", \"config3\", \"config4\", \"config4b\", \"config5\", \"config6\", \"config7\", \"config8\", \"config9\", \"config10\", \"config10b\", \"config11\", \"config11b\"]\n",
    "# for i, config in enumerate(configs):\n",
    "#     print(\"#\" * 20)\n",
    "#     print(f\"Config {i}: {config_names[i]}\")\n",
    "#     print(\"#\" * 20)\n",
    "#     start = time.time()\n",
    "#     runner = ExperimentRunner([config], resume_mode=\"restart\")\n",
    "#     datasets, predictions, scores, best_params = runner.run()\n",
    "#     end = time.time()\n",
    "#     print(f\"Time elapsed: {end-start} seconds\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15c4e548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "####################\n",
      "Config(dataset='../sample_data/classification', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<function nicon_classification at 0x00000226D9EEBD00>, experiment={'task': 'classification', 'training_params': {'epochs': 10, 'patience': 100, 'verbose': 0}}, seed=246918912)\n",
      "RobustScaler()\n",
      "obj.__dict__: {'with_centering': True, 'with_scaling': True, 'quantile_range': (25.0, 75.0), 'unit_variance': False, 'copy': True}\n",
      "> get_params: {'copy': True, 'quantile_range': (25.0, 75.0), 'unit_variance': False, 'with_centering': True, 'with_scaling': True}\n",
      "> inspect init: (self, *, with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True, unit_variance=False)\n",
      "> inspect dict: {'with_centering': True, 'with_scaling': True, 'quantile_range': (25.0, 75.0), 'unit_variance': False, 'copy': True}\n",
      "RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)\n",
      "obj.__dict__: {'cv': <class 'sklearn.model_selection._split.KFold'>, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}\n",
      "> inspect init: (self, *, n_splits=5, n_repeats=10, random_state=None)\n",
      "> inspect dict: {'cv': <class 'sklearn.model_selection._split.KFold'>, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}\n",
      "MinMaxScaler()\n",
      "obj.__dict__: {'feature_range': (0, 1), 'copy': True, 'clip': False}\n",
      "> get_params: {'clip': False, 'copy': True, 'feature_range': (0, 1)}\n",
      "> inspect init: (self, feature_range=(0, 1), *, copy=True, clip=False)\n",
      "> inspect dict: {'feature_range': (0, 1), 'copy': True, 'clip': False}\n",
      "####################\n",
      "{'dataset': '../sample_data/classification', 'x_pipeline': [{'class': 'sklearn.preprocessing._data.RobustScaler', 'params': {'copy': True, 'quantile_range': ['__tuple__', 25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection._split.RepeatedKFold', 'params': {'n_repeats': 1}}}, {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': ['__tuple__', 0, 1]}}], 'model': {'type': 'function', 'module': 'nirs4all.presets.ref_models', 'name': 'nicon_classification'}, 'experiment': {'task': 'classification', 'training_params': {'epochs': 10, 'patience': 100, 'verbose': 0}}, 'seed': 246918912}\n",
      "####################\n",
      "Config(dataset='../sample_data/classification', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=5, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<function nicon_classification at 0x00000226D9EEBD00>, experiment={'task': 'classification', 'training_params': {'epochs': 10, 'patience': 100, 'verbose': 0}}, seed=246918912)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(\"#\" * 20)\n",
    "print(config4)\n",
    "config_dict = config4.to_dict()\n",
    "print(\"#\" * 20)\n",
    "print(config_dict)\n",
    "new_config10 = Config.from_dict(config_dict)\n",
    "print(\"#\" * 20)\n",
    "print(new_config10)\n",
    "# runner = ExperimentRunner([new_config10], resume_mode=\"restart\")\n",
    "# datasets, predictions, scores, best_params = runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad55f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (1, <class 'int'>), 'b': ('test', <class 'str'>), 'c': (3.14, <class 'float'>)}\n",
      ">> a\n",
      "<class 'int'>\n",
      ">> b\n",
      "<class 'str'>\n",
      ">> c\n",
      "<class 'float'>\n",
      "{'n_splits': (3, <class 'int'>), 'n_repeats': (1, <class 'int'>)}\n",
      ">> n_splits\n",
      "<class 'int'>\n",
      ">> n_repeats\n",
      "<class 'int'>\n",
      "{}\n",
      ">> with_mean\n",
      "<class 'bool'>\n",
      ">> with_std\n",
      "<class 'bool'>\n",
      "{'feature_range': ((0, 0.9), <class 'tuple'>)}\n",
      ">> feature_range\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "def changed_kwargs(obj):\n",
    "    \"\"\"Return {param: value} for every __init__ param whose current\n",
    "    value differs from its default.\"\"\"\n",
    "    sig = inspect.signature(obj.__class__.__init__)\n",
    "    out = {}\n",
    "\n",
    "    for name, param in sig.parameters.items():\n",
    "        if name == \"self\":\n",
    "            continue\n",
    "\n",
    "        # default may be `inspect._empty`\n",
    "        default = param.default if param.default is not inspect._empty else None\n",
    "\n",
    "        # getattr() sees properties as well as real attributes\n",
    "        try:\n",
    "            current = getattr(obj, name)\n",
    "        except AttributeError:\n",
    "            # fall back to what's in cvargs if it exists\n",
    "            current = obj.__dict__.get(\"cvargs\", {}).get(name, default)\n",
    "\n",
    "        if current != default:\n",
    "            current_type = type(current)\n",
    "            out[name] = (current, current_type)\n",
    "    return out\n",
    "\n",
    "from typing import Any, get_type_hints\n",
    "import inspect\n",
    "\n",
    "def resolve_type(obj_or_cls: Any, name: str) -> type | Any | None:\n",
    "    cls = obj_or_cls if inspect.isclass(obj_or_cls) else obj_or_cls.__class__\n",
    "    sig = inspect.signature(obj_or_cls.__class__.__init__)\n",
    "    if name in sig.parameters:\n",
    "        print(\">>\", name)\n",
    "        if sig.parameters[name].default is inspect._empty:\n",
    "            if sig.parameters[name].annotation is not inspect._empty:\n",
    "                return sig.parameters[name].annotation\n",
    "            else:\n",
    "                if hasattr(obj_or_cls, name):\n",
    "                    return type(getattr(obj_or_cls, name))\n",
    "                else:\n",
    "                    return None\n",
    "        else:\n",
    "            return type(sig.parameters[name].default)\n",
    "    \n",
    "    class_hints = get_type_hints(cls, include_extras=True)\n",
    "    if name in class_hints:\n",
    "        return class_hints[name]\n",
    "    \n",
    "    init_hints = get_type_hints(cls.__init__, include_extras=True)\n",
    "    init_hints.pop('return', None)\n",
    "    if name in init_hints:\n",
    "        return init_hints[name]\n",
    "\n",
    "    if not inspect.isclass(obj_or_cls) and hasattr(obj_or_cls, name):\n",
    "        return type(getattr(obj_or_cls, name))\n",
    "\n",
    "    return None\n",
    "\n",
    "class custom_obj:\n",
    "    def __init__(self, a, b: str, c = 0.0):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        \n",
    "obj = custom_obj(1, \"test\", 3.14)\n",
    "print(changed_kwargs(obj))\n",
    "print(resolve_type(obj, \"a\"))\n",
    "print(resolve_type(obj, \"b\"))\n",
    "print(resolve_type(obj, \"c\"))\n",
    "\n",
    "obj = RepeatedKFold(n_splits=3, n_repeats=1)\n",
    "print(changed_kwargs(obj))\n",
    "print(resolve_type(obj, \"n_splits\"))\n",
    "print(resolve_type(obj, \"n_repeats\"))\n",
    "obj = StandardScaler()\n",
    "print(changed_kwargs(obj))\n",
    "print(resolve_type(obj, \"with_mean\"))\n",
    "print(resolve_type(obj, \"with_std\"))\n",
    "obj = MinMaxScaler(feature_range=(0, 0.9))\n",
    "print(changed_kwargs(obj))\n",
    "print(resolve_type(obj, \"feature_range\"))\n",
    "\n",
    "\n",
    "# print(obj)  # RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)\n",
    "# sig = inspect.signature(obj.__class__.__init__)\n",
    "# print(sig)  # (self, *, n_splits=5, n_repeats=10, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nirs4all.core.config import Config\n",
    "from nirs4all.core.runner import ExperimentRunner\n",
    "\n",
    "config = Config.from_json_file(\"../nirs4all/presets/configs/fast_train.json\")\n",
    "config.dataset = \"../sample_data/regression\"\n",
    "print(config)\n",
    "runner = ExperimentRunner(config, resume_mode=\"restart\")\n",
    "datasets, predictions, scores, best_params = runner.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
