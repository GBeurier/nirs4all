{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280f4b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1489348473.py, line 182)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 182\u001b[1;36m\u001b[0m\n\u001b[1;33m    config3 = Config(dataset1 x_pipeline_PLS, y_pipeline, PLSRegression(n_components=10), None, seed)\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "import time\n",
    "from nirs4all.presets.ref_models import decon, nicon, customizable_nicon, nicon_classification\n",
    "from nirs4all.presets.preprocessings import decon_set, nicon_set\n",
    "from nirs4all.data_splitters import KennardStoneSplitter\n",
    "from nirs4all.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG, Gaussian as GS, Derivate as  Dv\n",
    "from nirs4all.transformations import Rotate_Translate as RT, Spline_X_Simplification as SXS, Random_X_Operation as RXO\n",
    "from nirs4all.transformations import CropTransformer\n",
    "from nirs4all.core.runner import ExperimentRunner\n",
    "from nirs4all.core.config import Config\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold, RepeatedStratifiedKFold, ShuffleSplit, GroupKFold, StratifiedShuffleSplit, BaseCrossValidator, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "model_sklearn = {\n",
    "    \"class\": \"sklearn.cross_decomposition.PLSRegression\",\n",
    "    \"model_params\": {\n",
    "        \"n_components\": 21,\n",
    "    }\n",
    "}\n",
    "    \n",
    "finetune_pls_experiment = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_components': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "bacon_train = {\"action\": \"train\", \"training_params\": {\"epochs\": 2000, \"batch_size\": 500, \"patience\": 200, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 400}}\n",
    "bacon_train_short = {\"action\": \"train\", \"training_params\": {\"epochs\": 10, \"batch_size\": 500, \"patience\": 20, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 40}}\n",
    "bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 10,\n",
    "        \"verbose\":0\n",
    "    }\n",
    "}\n",
    "\n",
    "full_bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 500,\n",
    "        \"patience\": 100,\n",
    "    },\n",
    "    \"finetune_params\": {\n",
    "        \"nb_trials\": 150,\n",
    "        \"model_params\": {\n",
    "            'spatial_dropout': (float, 0.01, 0.5),\n",
    "            'filters1': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'kernel_size1': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides1': [1, 2, 3, 4, 5],\n",
    "            # 'activation1': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'dropout_rate': (float, 0.01, 0.5),\n",
    "            'filters2': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size2': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides2': [1, 2, 3, 4, 5],\n",
    "            'activation2': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'normalization_method1': ['BatchNormalization', 'LayerNormalization'],\n",
    "            'filters3': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size3': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides3': [1, 2, 3, 4, 5],\n",
    "            'activation3': ['relu', 'selu', 'elu', 'swish'],\n",
    "            # 'normalization_method2': ['BatchNormalization', 'LayerNormalization'],\n",
    "            # 'dense_units': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'dense_activation': ['relu', 'selu', 'elu', 'swish'],\n",
    "        },\n",
    "        # \"training_params\": {\n",
    "        #     \"batch_size\": [32, 64, 128, 256, 512],\n",
    "        #     \"cyclic_lr\": [True, False],\n",
    "        #     \"base_lr\": (float, 1e-6, 1e-2),\n",
    "        #     \"max_lr\": (float, 1e-3, 1e-1),\n",
    "        #     \"step_size\": (int, 500, 5000),\n",
    "        # },\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "x_pipeline_full = [\n",
    "    RobustScaler(),\n",
    "    {\"samples\": [None, None, None, None, SXS, RXO]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "\n",
    "bacon_finetune_classif = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 5,\n",
    "        \"verbose\":0\n",
    "    }\n",
    "}\n",
    "\n",
    "finetune_randomForestclassifier = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_estimators': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "x_pipeline_PLS = [\n",
    "    RobustScaler(),\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "            \n",
    "            \n",
    "x_pipeline = [\n",
    "    RobustScaler(), \n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)}, \n",
    "    # bacon_set(),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "x_pipelineb = [\n",
    "    RobustScaler(), \n",
    "    {\"samples\": [RT(6)], \"balance\": True},\n",
    "    # {\"samples\": [None, RT]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)}, \n",
    "    # {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "\n",
    "y_pipeline = MinMaxScaler()\n",
    "\n",
    "seed = 123459456\n",
    "\n",
    "dataset1 = {\n",
    "    \"path\": \"../sample_data/regression\",\n",
    "    \"params\": {}\n",
    "}\n",
    "\n",
    "# processing only\n",
    "config1 = Config(\"../sample_data/regression\", x_pipeline_full, y_pipeline, None, None, seed)\n",
    "## TRAINING\n",
    "# regression\n",
    "config2 = Config(dataset1, x_pipeline, y_pipeline, nicon, bacon_train_short, seed)\n",
    "config3 = Config(dataset1, x_pipeline_PLS, y_pipeline, PLSRegression(n_components=10), None, seed)\n",
    "# classification\n",
    "config4 = Config(\"../sample_data/classification\", x_pipeline, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":10, \"patience\": 100, \"verbose\":0}}, seed*2)\n",
    "config4b = Config(\"../sample_data/binary\", x_pipelineb, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":10, \"patience\": 100, \"verbose\":0}}, seed*2)\n",
    "config5 = Config(\"../sample_data/binary\", x_pipeline, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":5}, \"verbose\":0}, seed*2)\n",
    "config6 = Config(\"../sample_data/classification\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "config7 = Config(\"../sample_data/binary\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "## FINETUNING\n",
    "# regression\n",
    "config8 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, nicon, bacon_finetune, seed)\n",
    "config9 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, model_sklearn, finetune_pls_experiment, seed)\n",
    "# classification\n",
    "config10 = Config(\"../sample_data/classification\", x_pipeline, None, nicon_classification, bacon_finetune_classif, seed*2)\n",
    "config10b = Config(\"../sample_data/binary\", x_pipeline, None, nicon_classification, bacon_finetune_classif, seed*2)\n",
    "config11 = Config(\"../sample_data/classification\", x_pipelineb, None, RandomForestClassifier, finetune_randomForestclassifier, seed*2)\n",
    "config11b = Config(\"../sample_data/binary\", x_pipeline, None, RandomForestClassifier, finetune_randomForestclassifier, seed*2)\n",
    "\n",
    "\n",
    "# configs = [config1, config2, config3, config4, config4b, config5, config6, config7, config8, config9, config10, config10b, config11, config11b]\n",
    "# configs = [config10b, config11, config11b]\n",
    "configs = [config1, config2, config3]\n",
    "config_names = [\"config1\", \"config2\", \"config3\", \"config4\", \"config4b\", \"config5\", \"config6\", \"config7\", \"config8\", \"config9\", \"config10\", \"config10b\", \"config11\", \"config11b\"]\n",
    "for i, config in enumerate(configs):\n",
    "    print(\"#\" * 20)\n",
    "    print(f\"Config {i}: {config_names[i]}\")\n",
    "    print(\"#\" * 20)\n",
    "    start = time.time()\n",
    "    runner = ExperimentRunner([config], resume_mode=\"restart\")\n",
    "    datasets, predictions, scores, best_params = runner.run()\n",
    "    end = time.time()\n",
    "    print(f\"Time elapsed: {end-start} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
