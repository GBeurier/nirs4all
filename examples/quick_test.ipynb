{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4280f4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Workspace\\ML\\NIRS\\nirs4all\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-13 13:44:18,513 - INFO - ================================================================================\n",
      "2025-05-13 13:44:18,513 - INFO - Running config: Config(dataset='../sample_data/regression', x_pipeline=[RobustScaler(), {'samples': [None, None, None, None, <class 'nirs4all.transformations._spline_augmentation.Spline_X_Simplification'>, <class 'nirs4all.transformations._random_augmentation.Random_X_Operation'>]}, {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, {'features': [None, Gaussian(), <class 'nirs4all.transformations._nirs.SavitzkyGolay'>, <class 'sklearn.preprocessing._data.StandardScaler'>, <class 'nirs4all.transformations._scaler.Derivate'>, [<class 'nirs4all.transformations._standard.Gaussian'>, <class 'sklearn.preprocessing._data.StandardScaler'>], [<class 'nirs4all.transformations._standard.Gaussian'>, <class 'nirs4all.transformations._standard.Gaussian'>], [<class 'nirs4all.transformations._standard.Gaussian'>, <class 'nirs4all.transformations._nirs.SavitzkyGolay'>], [<class 'nirs4all.transformations._nirs.SavitzkyGolay'>, <class 'sklearn.preprocessing._data.StandardScaler'>], [<class 'nirs4all.transformations._standard.Gaussian'>, <class 'nirs4all.transformations._scaler.Derivate'>], [<class 'nirs4all.transformations._nirs.SavitzkyGolay'>, <class 'nirs4all.transformations._scaler.Derivate'>]]}, MinMaxScaler()], y_pipeline=MinMaxScaler(), model=None, experiment=None, seed=123459456)\n",
      "2025-05-13 13:44:18,515 - INFO - ================================================================================\n",
      "2025-05-13 13:44:18,515 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Config 0: config1\n",
      "####################\n",
      ">> Browsing ../sample_data/regression\n",
      "No train_group file found for ../sample_data/regression.\n",
      "No test_group file found for ../sample_data/regression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:19,660 - INFO - Dataset(x_train:(130, 2151) - y_train:(130, 1), x_test:(59, 2151) - y_test:(59, 1))\n",
      "2025-05-13 13:44:19,660 - INFO - ### PROCESSING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>\n",
      "[0.97754324 0.97708536 0.99443555 ... 1.02971265 1.01004455 1.00526501]\n",
      "Augmented Data Range: -30.98248674419553 3.129359016191828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:20,338 - INFO - Dataset(x_train:(780, 23661) - y_train:(780, 1), x_test:(59, 23661) - y_test:(59, 1))\n",
      "Folds size: 86-44, 87-43, 87-43\n",
      "2025-05-13 13:44:20,339 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:44:20,340 - INFO - Running config > {'dataset': '../sample_data/regression', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'samples': [None, None, None, None, {'class': 'nirs4all.transformations.Spline_X_Simplification', 'params': None}, {'class': 'nirs4all.transformations.Random_X_Operation', 'params': None}]}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'features': [None, {'class': 'nirs4all.transformations.Gaussian', 'params': {'copy': True, 'order': 2, 'sigma': 1}}, {'class': 'nirs4all.transformations.SavitzkyGolay', 'params': None}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': None}, {'class': 'nirs4all.transformations.Derivate', 'params': None}, [{'class': 'nirs4all.transformations.Gaussian', 'params': None}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': None}], [{'class': 'nirs4all.transformations.Gaussian', 'params': None}, {'class': 'nirs4all.transformations.Gaussian', 'params': None}], [{'class': 'nirs4all.transformations.Gaussian', 'params': None}, {'class': 'nirs4all.transformations.SavitzkyGolay', 'params': None}], [{'class': 'nirs4all.transformations.SavitzkyGolay', 'params': None}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': None}], [{'class': 'nirs4all.transformations.Gaussian', 'params': None}, {'class': 'nirs4all.transformations.Derivate', 'params': None}], [{'class': 'nirs4all.transformations.SavitzkyGolay', 'params': None}, {'class': 'nirs4all.transformations.Derivate', 'params': None}]]}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}, 'model': None, 'experiment': {'metrics': ['mse', 'mae'], 'task': 'regression'}, 'seed': 123459456}\n",
      "2025-05-13 13:44:20,342 - INFO - Starting new experiment experiment_31d84bd5.\n",
      "2025-05-13 13:44:20,343 - INFO - Experiment prepared at results\\sample_dataregression\\unknown_model\\experiment_31d84bd5\n",
      "2025-05-13 13:44:20,344 - WARNING - No model manager found. Skipping training/prediction.\n",
      "2025-05-13 13:44:20,344 - INFO - All experiments completed.\n",
      "2025-05-13 13:44:20,357 - INFO - ================================================================================\n",
      "2025-05-13 13:44:20,358 - INFO - Running config: Config(dataset='../sample_data/regression', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=MinMaxScaler(), model=<function nicon at 0x000001EE1CBEB1C0>, experiment={'action': 'train', 'training_params': {'epochs': 10, 'batch_size': 500, 'patience': 20, 'cyclic_lr': True, 'base_lr': 1e-06, 'max_lr': 0.001, 'step_size': 40}}, seed=123459456)\n",
      "2025-05-13 13:44:20,359 - INFO - ================================================================================\n",
      "2025-05-13 13:44:20,359 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.8325753211975098 seconds\n",
      "####################\n",
      "Config 1: config2\n",
      "####################\n",
      ">> Browsing ../sample_data/regression\n",
      "No train_group file found for ../sample_data/regression.\n",
      "No test_group file found for ../sample_data/regression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:21,333 - INFO - Dataset(x_train:(130, 2151) - y_train:(130, 1), x_test:(59, 2151) - y_test:(59, 1))\n",
      "2025-05-13 13:44:21,334 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:44:21,494 - INFO - Dataset(x_train:(130, 2151) - y_train:(130, 1), x_test:(59, 2151) - y_test:(59, 1))\n",
      "Folds size: 86-44, 87-43, 87-43\n",
      "2025-05-13 13:44:21,495 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:44:21,638 - INFO - Running config > {'dataset': '../sample_data/regression', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}, 'model': {'function': 'nirs4all.presets.ref_models.nicon'}, 'experiment': {'action': 'train', 'training_params': {'epochs': 10, 'batch_size': 500, 'patience': 20, 'cyclic_lr': True, 'base_lr': 1e-06, 'max_lr': 0.001, 'step_size': 40}, 'metrics': ['mse', 'mae'], 'task': 'regression'}, 'seed': 123459456}\n",
      "2025-05-13 13:44:21,640 - INFO - Starting new experiment experiment_53114d61.\n",
      "2025-05-13 13:44:21,641 - INFO - Experiment prepared at results\\sample_dataregression\\nicon\\experiment_53114d61\n",
      "2025-05-13 13:44:21,643 - INFO - Training the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Training fold with shapes: (86, 2151, 1), (86, 1), (44, 2151, 1), (44, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (86, 2151, 1) (86, 1) (44, 2151, 1) (44, 1)\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.1863 - mae: 0.4063 - mse: 0.1863 - val_loss: 0.1355 - val_mae: 0.3380 - val_mse: 0.1355 - learning_rate: 1.0000e-06\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1785 - mae: 0.3993 - mse: 0.1785 - val_loss: 0.1355 - val_mae: 0.3381 - val_mse: 0.1355 - learning_rate: 2.5975e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1800 - mae: 0.3998 - mse: 0.1800 - val_loss: 0.1356 - val_mae: 0.3382 - val_mse: 0.1356 - learning_rate: 5.0950e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1820 - mae: 0.4048 - mse: 0.1820 - val_loss: 0.1358 - val_mae: 0.3384 - val_mse: 0.1358 - learning_rate: 7.5925e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1760 - mae: 0.3983 - mse: 0.1760 - val_loss: 0.1358 - val_mae: 0.3384 - val_mse: 0.1358 - learning_rate: 1.0090e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1747 - mae: 0.3868 - mse: 0.1747 - val_loss: 0.1358 - val_mae: 0.3386 - val_mse: 0.1358 - learning_rate: 1.2587e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1774 - mae: 0.4015 - mse: 0.1774 - val_loss: 0.1360 - val_mae: 0.3388 - val_mse: 0.1360 - learning_rate: 1.5085e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1737 - mae: 0.3916 - mse: 0.1737 - val_loss: 0.1362 - val_mae: 0.3391 - val_mse: 0.1362 - learning_rate: 1.7583e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1572 - mae: 0.3728 - mse: 0.1572 - val_loss: 0.1364 - val_mae: 0.3394 - val_mse: 0.1364 - learning_rate: 2.0080e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1704 - mae: 0.3892 - mse: 0.1704 - val_loss: 0.1363 - val_mae: 0.3394 - val_mse: 0.1363 - learning_rate: 2.2578e-04\n",
      "Training fold with shapes: (87, 2151, 1), (87, 1), (43, 2151, 1), (43, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (87, 2151, 1) (87, 1) (43, 2151, 1) (43, 1)\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.1253 - mae: 0.3156 - mse: 0.1253 - val_loss: 0.1588 - val_mae: 0.3799 - val_mse: 0.1588 - learning_rate: 1.0000e-06\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1192 - mae: 0.3107 - mse: 0.1192 - val_loss: 0.1582 - val_mae: 0.3792 - val_mse: 0.1582 - learning_rate: 2.5975e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1255 - mae: 0.3280 - mse: 0.1255 - val_loss: 0.1571 - val_mae: 0.3777 - val_mse: 0.1571 - learning_rate: 5.0950e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1312 - mae: 0.3255 - mse: 0.1312 - val_loss: 0.1552 - val_mae: 0.3754 - val_mse: 0.1552 - learning_rate: 7.5925e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.1360 - mae: 0.3391 - mse: 0.1360 - val_loss: 0.1529 - val_mae: 0.3724 - val_mse: 0.1529 - learning_rate: 1.0090e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.1108 - mae: 0.3016 - mse: 0.1108 - val_loss: 0.1496 - val_mae: 0.3682 - val_mse: 0.1496 - learning_rate: 1.2587e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1252 - mae: 0.3168 - mse: 0.1252 - val_loss: 0.1453 - val_mae: 0.3626 - val_mse: 0.1453 - learning_rate: 1.5085e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1135 - mae: 0.3039 - mse: 0.1135 - val_loss: 0.1411 - val_mae: 0.3569 - val_mse: 0.1411 - learning_rate: 1.7583e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1138 - mae: 0.3077 - mse: 0.1138 - val_loss: 0.1373 - val_mae: 0.3517 - val_mse: 0.1373 - learning_rate: 2.0080e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.1085 - mae: 0.2905 - mse: 0.1085 - val_loss: 0.1325 - val_mae: 0.3450 - val_mse: 0.1325 - learning_rate: 2.2578e-04\n",
      "Training fold with shapes: (87, 2151, 1), (87, 1), (43, 2151, 1), (43, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (87, 2151, 1) (87, 1) (43, 2151, 1) (43, 1)\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.1435 - mae: 0.3464 - mse: 0.1435 - val_loss: 0.1642 - val_mae: 0.3817 - val_mse: 0.1642 - learning_rate: 1.0000e-06\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1420 - mae: 0.3450 - mse: 0.1420 - val_loss: 0.1634 - val_mae: 0.3808 - val_mse: 0.1634 - learning_rate: 2.5975e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1389 - mae: 0.3413 - mse: 0.1389 - val_loss: 0.1622 - val_mae: 0.3792 - val_mse: 0.1622 - learning_rate: 5.0950e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1389 - mae: 0.3428 - mse: 0.1389 - val_loss: 0.1606 - val_mae: 0.3770 - val_mse: 0.1606 - learning_rate: 7.5925e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1443 - mae: 0.3500 - mse: 0.1443 - val_loss: 0.1585 - val_mae: 0.3744 - val_mse: 0.1585 - learning_rate: 1.0090e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1370 - mae: 0.3373 - mse: 0.1370 - val_loss: 0.1567 - val_mae: 0.3719 - val_mse: 0.1567 - learning_rate: 1.2587e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1387 - mae: 0.3406 - mse: 0.1387 - val_loss: 0.1547 - val_mae: 0.3693 - val_mse: 0.1547 - learning_rate: 1.5085e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1329 - mae: 0.3291 - mse: 0.1329 - val_loss: 0.1532 - val_mae: 0.3673 - val_mse: 0.1532 - learning_rate: 1.7583e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1241 - mae: 0.3243 - mse: 0.1241 - val_loss: 0.1511 - val_mae: 0.3645 - val_mse: 0.1511 - learning_rate: 2.0080e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1213 - mae: 0.3209 - mse: 0.1213 - val_loss: 0.1493 - val_mae: 0.3620 - val_mse: 0.1493 - learning_rate: 2.2578e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:30,013 - INFO - Saved model to results\\sample_dataregression\\nicon\\experiment_53114d61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EE21228550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EE21228550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:30,654 - INFO - Evaluation Metrics fold_0: {'mse': 2162.3778213311807, 'mae': 42.47361162088685}\n",
      "2025-05-13 13:44:30,655 - INFO - Evaluation Metrics fold_1: {'mse': 1625.2625265856555, 'mae': 36.28390213271319}\n",
      "2025-05-13 13:44:30,656 - INFO - Evaluation Metrics fold_2: {'mse': 2098.759109345956, 'mae': 41.84231892213983}\n",
      "2025-05-13 13:44:30,657 - INFO - Evaluation Metrics mean: {'mse': 1952.3138579854158, 'mae': 40.197744482008076}\n",
      "2025-05-13 13:44:30,658 - INFO - Evaluation Metrics best: {'mse': 1625.2625265856555, 'mae': 36.28390213271319}\n",
      "2025-05-13 13:44:30,659 - INFO - Evaluation Metrics weighted: {'mse': 1919.7367527622632, 'mae': 39.82706229401942}\n",
      "2025-05-13 13:44:30,660 - INFO - Metrics saved to results\\sample_dataregression\\nicon\\experiment_53114d61\\metrics.json\n",
      "2025-05-13 13:44:30,663 - INFO - Predictions saved to results\\sample_dataregression\\nicon\\experiment_53114d61\\predictions.csv\n",
      "2025-05-13 13:44:30,673 - INFO - Updated experiments at results\\sample_dataregression\\nicon\\experiments.json\n",
      "2025-05-13 13:44:30,683 - INFO - Updated experiments at results\\sample_dataregression\\experiments.json\n",
      "2025-05-13 13:44:30,684 - INFO - Updated experiments at results\\sample_dataregression\\nicon\\experiments.json and results\\sample_dataregression\\experiments.json\n",
      "2025-05-13 13:44:30,685 - INFO - All experiments completed.\n",
      "2025-05-13 13:44:30,691 - INFO - ================================================================================\n",
      "2025-05-13 13:44:30,691 - INFO - Running config: Config(dataset='../sample_data/regression', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, {'features': [None, Gaussian(), <class 'nirs4all.transformations._nirs.SavitzkyGolay'>, <class 'sklearn.preprocessing._data.StandardScaler'>, <class 'nirs4all.transformations._scaler.Derivate'>, [<class 'nirs4all.transformations._standard.Gaussian'>, <class 'sklearn.preprocessing._data.StandardScaler'>], [<class 'nirs4all.transformations._standard.Gaussian'>, <class 'nirs4all.transformations._standard.Gaussian'>], [<class 'nirs4all.transformations._standard.Gaussian'>, <class 'nirs4all.transformations._nirs.SavitzkyGolay'>], [<class 'nirs4all.transformations._nirs.SavitzkyGolay'>, <class 'sklearn.preprocessing._data.StandardScaler'>], [<class 'nirs4all.transformations._standard.Gaussian'>, <class 'nirs4all.transformations._scaler.Derivate'>], [<class 'nirs4all.transformations._nirs.SavitzkyGolay'>, <class 'nirs4all.transformations._scaler.Derivate'>]]}, MinMaxScaler()], y_pipeline=MinMaxScaler(), model={'class': 'sklearn.cross_decomposition.PLSRegression', 'model_params': {'n_components': 21}}, experiment=None, seed=123459456)\n",
      "2025-05-13 13:44:30,693 - INFO - ================================================================================\n",
      "2025-05-13 13:44:30,694 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 10.345049858093262 seconds\n",
      "####################\n",
      "Config 2: config3\n",
      "####################\n",
      ">> Browsing ../sample_data/regression\n",
      "No train_group file found for ../sample_data/regression.\n",
      "No test_group file found for ../sample_data/regression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:31,871 - INFO - Dataset(x_train:(130, 2151) - y_train:(130, 1), x_test:(59, 2151) - y_test:(59, 1))\n",
      "2025-05-13 13:44:31,872 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:44:32,164 - INFO - Dataset(x_train:(130, 23661) - y_train:(130, 1), x_test:(59, 23661) - y_test:(59, 1))\n",
      "Folds size: 86-44, 87-43, 87-43\n",
      "2025-05-13 13:44:32,165 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:44:32,169 - INFO - Running config > {'dataset': '../sample_data/regression', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'features': [None, {'class': 'nirs4all.transformations.Gaussian', 'params': {'copy': True, 'order': 2, 'sigma': 1}}, {'class': 'nirs4all.transformations.SavitzkyGolay', 'params': None}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': None}, {'class': 'nirs4all.transformations.Derivate', 'params': None}, [{'class': 'nirs4all.transformations.Gaussian', 'params': None}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': None}], [{'class': 'nirs4all.transformations.Gaussian', 'params': None}, {'class': 'nirs4all.transformations.Gaussian', 'params': None}], [{'class': 'nirs4all.transformations.Gaussian', 'params': None}, {'class': 'nirs4all.transformations.SavitzkyGolay', 'params': None}], [{'class': 'nirs4all.transformations.SavitzkyGolay', 'params': None}, {'class': 'sklearn.preprocessing.StandardScaler', 'params': None}], [{'class': 'nirs4all.transformations.Gaussian', 'params': None}, {'class': 'nirs4all.transformations.Derivate', 'params': None}], [{'class': 'nirs4all.transformations.SavitzkyGolay', 'params': None}, {'class': 'nirs4all.transformations.Derivate', 'params': None}]]}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}, 'model': {'class': 'sklearn.cross_decomposition.PLSRegression', 'model_params': {'n_components': 21}}, 'experiment': {'metrics': ['mse', 'mae'], 'task': 'regression'}, 'seed': 123459456}\n",
      "2025-05-13 13:44:32,171 - INFO - Starting new experiment experiment_43d43033.\n",
      "2025-05-13 13:44:32,173 - INFO - Experiment prepared at results\\sample_dataregression\\PLSRegression\\experiment_43d43033\n",
      "2025-05-13 13:44:32,174 - INFO - Training the model\n",
      "2025-05-13 13:44:32,319 - INFO - Saved model to results\\sample_dataregression\\PLSRegression\\experiment_43d43033\n",
      "2025-05-13 13:44:32,349 - INFO - Evaluation Metrics fold_0: {'mse': 440.33869084784163, 'mae': 16.784876039604065}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework: sklearn\n",
      "Training fold 1, with shapes: (86, 23661) (86, 1) (44, 23661) (44, 1)\n",
      "Training fold 2, with shapes: (87, 23661) (87, 1) (43, 23661) (43, 1)\n",
      "Training fold 3, with shapes: (87, 23661) (87, 1) (43, 23661) (43, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:32,350 - INFO - Evaluation Metrics fold_1: {'mse': 409.13591180110353, 'mae': 16.506575169548245}\n",
      "2025-05-13 13:44:32,351 - INFO - Evaluation Metrics fold_2: {'mse': 416.4678047932354, 'mae': 16.760012252911505}\n",
      "2025-05-13 13:44:32,352 - INFO - Evaluation Metrics mean: {'mse': 412.03189123416234, 'mae': 16.530850446711}\n",
      "2025-05-13 13:44:32,353 - INFO - Evaluation Metrics best: {'mse': 409.13591180110353, 'mae': 16.506575169548245}\n",
      "2025-05-13 13:44:32,355 - INFO - Evaluation Metrics weighted: {'mse': 411.5494147168, 'mae': 16.52973825921971}\n",
      "2025-05-13 13:44:32,356 - INFO - Metrics saved to results\\sample_dataregression\\PLSRegression\\experiment_43d43033\\metrics.json\n",
      "2025-05-13 13:44:32,359 - INFO - Predictions saved to results\\sample_dataregression\\PLSRegression\\experiment_43d43033\\predictions.csv\n",
      "2025-05-13 13:44:32,370 - INFO - Updated experiments at results\\sample_dataregression\\PLSRegression\\experiments.json\n",
      "2025-05-13 13:44:32,382 - INFO - Updated experiments at results\\sample_dataregression\\experiments.json\n",
      "2025-05-13 13:44:32,383 - INFO - Updated experiments at results\\sample_dataregression\\PLSRegression\\experiments.json and results\\sample_dataregression\\experiments.json\n",
      "2025-05-13 13:44:32,384 - INFO - All experiments completed.\n",
      "2025-05-13 13:44:32,386 - INFO - ================================================================================\n",
      "2025-05-13 13:44:32,387 - INFO - Running config: Config(dataset='../sample_data/classification', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<function nicon_classification at 0x000001EE1CBEB6D0>, experiment={'task': 'classification', 'training_params': {'epochs': 10, 'patience': 100, 'verbose': 0}}, seed=246918912)\n",
      "2025-05-13 13:44:32,388 - INFO - ================================================================================\n",
      "2025-05-13 13:44:32,389 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.694850206375122 seconds\n",
      "####################\n",
      "Config 3: config4\n",
      "####################\n",
      ">> Browsing ../sample_data/classification\n",
      "No train_group file found for ../sample_data/classification.\n",
      "No test_group file found for ../sample_data/classification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:33,206 - INFO - Dataset(x_train:(48, 2152) - y_train:(48, 1), x_test:(18, 2152) - y_test:(18, 1))\n",
      "2025-05-13 13:44:33,207 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:44:33,353 - INFO - Dataset(x_train:(48, 2152) - y_train:(48, 1), x_test:(18, 2152) - y_test:(18, 1))\n",
      "Folds size: 32-16, 32-16, 32-16\n",
      "2025-05-13 13:44:33,354 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:44:33,471 - INFO - Running config > {'dataset': '../sample_data/classification', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'function': 'nirs4all.presets.ref_models.nicon_classification'}, 'experiment': {'task': 'classification', 'training_params': {'epochs': 10, 'patience': 100, 'verbose': 0, 'loss': 'sparse_categorical_crossentropy'}, 'metrics': ['accuracy'], 'num_classes': 10}, 'seed': 246918912}\n",
      "2025-05-13 13:44:33,473 - INFO - Starting new experiment experiment_691eedde.\n",
      "2025-05-13 13:44:33,474 - INFO - Experiment prepared at results\\sample_dataclassification\\nicon_classification\\experiment_691eedde\n",
      "2025-05-13 13:44:33,475 - INFO - Training the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Training fold with shapes: (32, 2152, 1), (32, 1), (16, 2152, 1), (16, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training with shapes: (32, 2152, 1) (32,) (16, 2152, 1) (16,)\n",
      "Training fold with shapes: (32, 2152, 1), (32, 1), (16, 2152, 1), (16, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training with shapes: (32, 2152, 1) (32,) (16, 2152, 1) (16,)\n",
      "Training fold with shapes: (32, 2152, 1), (32, 1), (16, 2152, 1), (16, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training with shapes: (32, 2152, 1) (32,) (16, 2152, 1) (16,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:41,225 - INFO - Saved model to results\\sample_dataclassification\\nicon_classification\\experiment_691eedde\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:41,619 - INFO - Evaluation Metrics fold_0: {'accuracy': 0.2222222222222222}\n",
      "2025-05-13 13:44:41,620 - INFO - Evaluation Metrics fold_1: {'accuracy': 0.1111111111111111}\n",
      "2025-05-13 13:44:41,622 - INFO - Evaluation Metrics fold_2: {'accuracy': 0.2777777777777778}\n",
      "2025-05-13 13:44:41,622 - INFO - Evaluation Metrics mean: {'accuracy': 0.1111111111111111}\n",
      "2025-05-13 13:44:41,623 - INFO - Evaluation Metrics best: {'accuracy': 0.2777777777777778}\n",
      "2025-05-13 13:44:41,624 - INFO - Evaluation Metrics weighted: {'accuracy': 0.16666666666666666}\n",
      "2025-05-13 13:44:41,625 - INFO - Metrics saved to results\\sample_dataclassification\\nicon_classification\\experiment_691eedde\\metrics.json\n",
      "2025-05-13 13:44:41,627 - INFO - Predictions saved to results\\sample_dataclassification\\nicon_classification\\experiment_691eedde\\predictions.csv\n",
      "2025-05-13 13:44:41,635 - INFO - Updated experiments at results\\sample_dataclassification\\nicon_classification\\experiments.json\n",
      "2025-05-13 13:44:41,646 - INFO - Updated experiments at results\\sample_dataclassification\\experiments.json\n",
      "2025-05-13 13:44:41,647 - INFO - Updated experiments at results\\sample_dataclassification\\nicon_classification\\experiments.json and results\\sample_dataclassification\\experiments.json\n",
      "2025-05-13 13:44:41,647 - INFO - All experiments completed.\n",
      "2025-05-13 13:44:41,649 - INFO - ================================================================================\n",
      "2025-05-13 13:44:41,650 - INFO - Running config: Config(dataset='../sample_data/binary', x_pipeline=[RobustScaler(), {'samples': [Rotate_Translate(apply_on=6)], 'balance': True}, {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<function nicon_classification at 0x000001EE1CBEB6D0>, experiment={'task': 'classification', 'training_params': {'epochs': 10, 'patience': 100, 'verbose': 0}}, seed=246918912)\n",
      "2025-05-13 13:44:41,652 - INFO - ================================================================================\n",
      "2025-05-13 13:44:41,652 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 9.264177322387695 seconds\n",
      "####################\n",
      "Config 4: config4b\n",
      "####################\n",
      ">> Browsing ../sample_data/binary\n",
      "No train_group file found for ../sample_data/binary.\n",
      "No test_group file found for ../sample_data/binary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:42,528 - INFO - Dataset(x_train:(300, 1665) - y_train:(300, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "2025-05-13 13:44:42,529 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:44:43,496 - INFO - Dataset(x_train:(574, 1665) - y_train:(574, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "Folds size: 382-192, 383-191, 383-191\n",
      "2025-05-13 13:44:43,497 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:44:43,617 - INFO - Running config > {'dataset': '../sample_data/binary', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'samples': [{'class': 'nirs4all.transformations.Rotate_Translate', 'params': {'apply_on': 6, 'copy': True, 'p_range': 2, 'random_state': None, 'y_factor': 3}}], 'balance': True}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'function': 'nirs4all.presets.ref_models.nicon_classification'}, 'experiment': {'task': 'classification', 'training_params': {'epochs': 10, 'patience': 100, 'verbose': 0, 'loss': 'binary_crossentropy'}, 'metrics': ['accuracy'], 'num_classes': 2}, 'seed': 246918912}\n",
      "2025-05-13 13:44:43,619 - INFO - Starting new experiment experiment_dcbae6db.\n",
      "2025-05-13 13:44:43,620 - INFO - Experiment prepared at results\\sample_databinary\\nicon_classification\\experiment_dcbae6db\n",
      "2025-05-13 13:44:43,621 - INFO - Training the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300, 1, 1665) (300, 1)\n",
      "{np.int64(0): 287, np.int64(1): 13}\n",
      "{np.int64(0): 0, np.int64(1): 274}\n",
      "(1, 574, 1, 1665) (574, 1)\n",
      "{np.int64(0): 287, np.int64(1): 287}\n",
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Training fold with shapes: (382, 1665, 1), (382, 1), (192, 1665, 1), (192, 1)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (382, 1665, 1) (382, 1) (192, 1665, 1) (192, 1)\n",
      "Training fold with shapes: (383, 1665, 1), (383, 1), (191, 1665, 1), (191, 1)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (383, 1665, 1) (383, 1) (191, 1665, 1) (191, 1)\n",
      "Training fold with shapes: (383, 1665, 1), (383, 1), (191, 1665, 1), (191, 1)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (383, 1665, 1) (383, 1) (191, 1665, 1) (191, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:53,342 - INFO - Saved model to results\\sample_databinary\\nicon_classification\\experiment_dcbae6db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:53,997 - INFO - Evaluation Metrics fold_0: {'accuracy': 0.046511627906976744}\n",
      "2025-05-13 13:44:53,998 - INFO - Evaluation Metrics fold_1: {'accuracy': 0.046511627906976744}\n",
      "2025-05-13 13:44:53,999 - INFO - Evaluation Metrics fold_2: {'accuracy': 0.046511627906976744}\n",
      "2025-05-13 13:44:54,000 - INFO - Evaluation Metrics mean: {'accuracy': 0.046511627906976744}\n",
      "2025-05-13 13:44:54,002 - INFO - Evaluation Metrics best: {'accuracy': 0.046511627906976744}\n",
      "2025-05-13 13:44:54,003 - INFO - Evaluation Metrics weighted: {'accuracy': 0.046511627906976744}\n",
      "2025-05-13 13:44:54,004 - INFO - Metrics saved to results\\sample_databinary\\nicon_classification\\experiment_dcbae6db\\metrics.json\n",
      "2025-05-13 13:44:54,007 - INFO - Predictions saved to results\\sample_databinary\\nicon_classification\\experiment_dcbae6db\\predictions.csv\n",
      "2025-05-13 13:44:54,008 - INFO - Updated experiments at results\\sample_databinary\\nicon_classification\\experiments.json\n",
      "2025-05-13 13:44:54,018 - INFO - Updated experiments at results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:44:54,019 - INFO - Updated experiments at results\\sample_databinary\\nicon_classification\\experiments.json and results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:44:54,020 - INFO - All experiments completed.\n",
      "2025-05-13 13:44:54,021 - INFO - ================================================================================\n",
      "2025-05-13 13:44:54,022 - INFO - Running config: Config(dataset='../sample_data/binary', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<function nicon_classification at 0x000001EE1CBEB6D0>, experiment={'task': 'classification', 'training_params': {'epochs': 5}, 'verbose': 0}, seed=246918912)\n",
      "2025-05-13 13:44:54,023 - INFO - ================================================================================\n",
      "2025-05-13 13:44:54,024 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 12.372164011001587 seconds\n",
      "####################\n",
      "Config 5: config5\n",
      "####################\n",
      ">> Browsing ../sample_data/binary\n",
      "No train_group file found for ../sample_data/binary.\n",
      "No test_group file found for ../sample_data/binary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:44:54,885 - INFO - Dataset(x_train:(300, 1665) - y_train:(300, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "2025-05-13 13:44:54,886 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:44:55,031 - INFO - Dataset(x_train:(300, 1665) - y_train:(300, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "Folds size: 200-100, 200-100, 200-100\n",
      "2025-05-13 13:44:55,031 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:44:55,164 - INFO - Running config > {'dataset': '../sample_data/binary', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'function': 'nirs4all.presets.ref_models.nicon_classification'}, 'experiment': {'task': 'classification', 'training_params': {'epochs': 5, 'loss': 'binary_crossentropy'}, 'verbose': 0, 'metrics': ['accuracy'], 'num_classes': 2}, 'seed': 246918912}\n",
      "2025-05-13 13:44:55,166 - INFO - Starting new experiment experiment_cc3c5e9c.\n",
      "2025-05-13 13:44:55,168 - INFO - Experiment prepared at results\\sample_databinary\\nicon_classification\\experiment_cc3c5e9c\n",
      "2025-05-13 13:44:55,170 - INFO - Training the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Training fold with shapes: (200, 1665, 1), (200, 1), (100, 1665, 1), (100, 1)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (200, 1665, 1) (200, 1) (100, 1665, 1) (100, 1)\n",
      "Epoch 1/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6371 - loss: 0.6068 - val_accuracy: 0.6200 - val_loss: 0.6965\n",
      "Epoch 2/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8958 - loss: 0.3748 - val_accuracy: 0.7800 - val_loss: 0.6522\n",
      "Epoch 3/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9133 - loss: 0.2987 - val_accuracy: 0.8800 - val_loss: 0.6013\n",
      "Epoch 4/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9326 - loss: 0.2609 - val_accuracy: 0.9300 - val_loss: 0.5510\n",
      "Epoch 5/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9254 - loss: 0.2507 - val_accuracy: 0.9400 - val_loss: 0.5395\n",
      "Training fold with shapes: (200, 1665, 1), (200, 1), (100, 1665, 1), (100, 1)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (200, 1665, 1) (200, 1) (100, 1665, 1) (100, 1)\n",
      "Epoch 1/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7940 - loss: 0.5018 - val_accuracy: 0.9800 - val_loss: 0.4762\n",
      "Epoch 2/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8939 - loss: 0.3456 - val_accuracy: 0.9600 - val_loss: 0.4117\n",
      "Epoch 3/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9294 - loss: 0.2429 - val_accuracy: 0.9800 - val_loss: 0.3680\n",
      "Epoch 4/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9252 - loss: 0.2800 - val_accuracy: 0.9600 - val_loss: 0.4215\n",
      "Epoch 5/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9322 - loss: 0.2675 - val_accuracy: 0.9800 - val_loss: 0.3706\n",
      "Training fold with shapes: (200, 1665, 1), (200, 1), (100, 1665, 1), (100, 1)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (200, 1665, 1) (200, 1) (100, 1665, 1) (100, 1)\n",
      "Epoch 1/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9568 - loss: 0.2691 - val_accuracy: 0.9300 - val_loss: 0.3069\n",
      "Epoch 2/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9739 - loss: 0.1495 - val_accuracy: 0.9300 - val_loss: 0.2847\n",
      "Epoch 3/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9590 - loss: 0.1419 - val_accuracy: 0.9300 - val_loss: 0.2840\n",
      "Epoch 4/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9673 - loss: 0.1512 - val_accuracy: 0.9300 - val_loss: 0.3082\n",
      "Epoch 5/5\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9817 - loss: 0.1055 - val_accuracy: 0.9300 - val_loss: 0.2856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:02,074 - INFO - Saved model to results\\sample_databinary\\nicon_classification\\experiment_cc3c5e9c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:02,992 - INFO - Evaluation Metrics fold_0: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:02,993 - INFO - Evaluation Metrics fold_1: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:02,994 - INFO - Evaluation Metrics fold_2: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:02,995 - INFO - Evaluation Metrics mean: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:02,995 - INFO - Evaluation Metrics best: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:02,997 - INFO - Evaluation Metrics weighted: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:02,998 - INFO - Metrics saved to results\\sample_databinary\\nicon_classification\\experiment_cc3c5e9c\\metrics.json\n",
      "2025-05-13 13:45:03,000 - INFO - Predictions saved to results\\sample_databinary\\nicon_classification\\experiment_cc3c5e9c\\predictions.csv\n",
      "2025-05-13 13:45:03,009 - INFO - Updated experiments at results\\sample_databinary\\nicon_classification\\experiments.json\n",
      "2025-05-13 13:45:03,017 - INFO - Updated experiments at results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:45:03,018 - INFO - Updated experiments at results\\sample_databinary\\nicon_classification\\experiments.json and results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:45:03,019 - INFO - All experiments completed.\n",
      "2025-05-13 13:45:03,021 - INFO - ================================================================================\n",
      "2025-05-13 13:45:03,021 - INFO - Running config: Config(dataset='../sample_data/classification', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<class 'sklearn.ensemble._forest.RandomForestClassifier'>, experiment={'task': 'classification'}, seed=246918912)\n",
      "2025-05-13 13:45:03,022 - INFO - ================================================================================\n",
      "2025-05-13 13:45:03,023 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 8.998077630996704 seconds\n",
      "####################\n",
      "Config 6: config6\n",
      "####################\n",
      ">> Browsing ../sample_data/classification\n",
      "No train_group file found for ../sample_data/classification.\n",
      "No test_group file found for ../sample_data/classification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:03,849 - INFO - Dataset(x_train:(48, 2152) - y_train:(48, 1), x_test:(18, 2152) - y_test:(18, 1))\n",
      "2025-05-13 13:45:03,850 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:45:03,995 - INFO - Dataset(x_train:(48, 2152) - y_train:(48, 1), x_test:(18, 2152) - y_test:(18, 1))\n",
      "Folds size: 32-16, 32-16, 32-16\n",
      "2025-05-13 13:45:03,995 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:45:03,997 - INFO - Running config > {'dataset': '../sample_data/classification', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'class': 'sklearn.ensemble.RandomForestClassifier', 'params': None}, 'experiment': {'task': 'classification', 'metrics': ['accuracy'], 'num_classes': 10}, 'seed': 246918912}\n",
      "2025-05-13 13:45:03,998 - INFO - Starting new experiment experiment_2e0f1461.\n",
      "2025-05-13 13:45:03,999 - INFO - Experiment prepared at results\\sample_dataclassification\\RandomForestClassifier\\experiment_2e0f1461\n",
      "2025-05-13 13:45:04,000 - INFO - Training the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework: sklearn\n",
      "Training fold 1, with shapes: (32, 2152) (32, 1) (16, 2152) (16, 1)\n",
      "Training fold 2, with shapes: (32, 2152) (32, 1) (16, 2152) (16, 1)\n",
      "Training fold 3, with shapes: (32, 2152) (32, 1) (16, 2152) (16, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:04,487 - INFO - Saved model to results\\sample_dataclassification\\RandomForestClassifier\\experiment_2e0f1461\n",
      "2025-05-13 13:45:04,507 - INFO - Evaluation Metrics fold_0: {'accuracy': 0.2222222222222222}\n",
      "2025-05-13 13:45:04,509 - INFO - Evaluation Metrics fold_1: {'accuracy': 0.16666666666666666}\n",
      "2025-05-13 13:45:04,510 - INFO - Evaluation Metrics fold_2: {'accuracy': 0.16666666666666666}\n",
      "2025-05-13 13:45:04,511 - INFO - Evaluation Metrics mean: {'accuracy': 0.2222222222222222}\n",
      "2025-05-13 13:45:04,511 - INFO - Evaluation Metrics best: {'accuracy': 0.2222222222222222}\n",
      "2025-05-13 13:45:04,512 - INFO - Evaluation Metrics weighted: {'accuracy': 0.2222222222222222}\n",
      "2025-05-13 13:45:04,514 - INFO - Metrics saved to results\\sample_dataclassification\\RandomForestClassifier\\experiment_2e0f1461\\metrics.json\n",
      "2025-05-13 13:45:04,515 - INFO - Predictions saved to results\\sample_dataclassification\\RandomForestClassifier\\experiment_2e0f1461\\predictions.csv\n",
      "2025-05-13 13:45:04,525 - INFO - Updated experiments at results\\sample_dataclassification\\RandomForestClassifier\\experiments.json\n",
      "2025-05-13 13:45:04,535 - INFO - Updated experiments at results\\sample_dataclassification\\experiments.json\n",
      "2025-05-13 13:45:04,536 - INFO - Updated experiments at results\\sample_dataclassification\\RandomForestClassifier\\experiments.json and results\\sample_dataclassification\\experiments.json\n",
      "2025-05-13 13:45:04,537 - INFO - All experiments completed.\n",
      "2025-05-13 13:45:04,538 - INFO - ================================================================================\n",
      "2025-05-13 13:45:04,539 - INFO - Running config: Config(dataset='../sample_data/binary', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<class 'sklearn.ensemble._forest.RandomForestClassifier'>, experiment={'task': 'classification'}, seed=246918912)\n",
      "2025-05-13 13:45:04,540 - INFO - ================================================================================\n",
      "2025-05-13 13:45:04,541 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.5184814929962158 seconds\n",
      "####################\n",
      "Config 7: config7\n",
      "####################\n",
      ">> Browsing ../sample_data/binary\n",
      "No train_group file found for ../sample_data/binary.\n",
      "No test_group file found for ../sample_data/binary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:05,387 - INFO - Dataset(x_train:(300, 1665) - y_train:(300, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "2025-05-13 13:45:05,388 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:45:05,535 - INFO - Dataset(x_train:(300, 1665) - y_train:(300, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "Folds size: 200-100, 200-100, 200-100\n",
      "2025-05-13 13:45:05,536 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:45:05,537 - INFO - Running config > {'dataset': '../sample_data/binary', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'class': 'sklearn.ensemble.RandomForestClassifier', 'params': None}, 'experiment': {'task': 'classification', 'metrics': ['accuracy'], 'num_classes': 2}, 'seed': 246918912}\n",
      "2025-05-13 13:45:05,540 - INFO - Starting new experiment experiment_a24a3b00.\n",
      "2025-05-13 13:45:05,541 - INFO - Experiment prepared at results\\sample_databinary\\RandomForestClassifier\\experiment_a24a3b00\n",
      "2025-05-13 13:45:05,542 - INFO - Training the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework: sklearn\n",
      "Training fold 1, with shapes: (200, 1665) (200, 1) (100, 1665) (100, 1)\n",
      "Training fold 2, with shapes: (200, 1665) (200, 1) (100, 1665) (100, 1)\n",
      "Training fold 3, with shapes: (200, 1665) (200, 1) (100, 1665) (100, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:06,317 - INFO - Saved model to results\\sample_databinary\\RandomForestClassifier\\experiment_a24a3b00\n",
      "2025-05-13 13:45:06,337 - INFO - Evaluation Metrics fold_0: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:06,339 - INFO - Evaluation Metrics fold_1: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:06,339 - INFO - Evaluation Metrics fold_2: {'accuracy': 0.9457364341085271}\n",
      "2025-05-13 13:45:06,341 - INFO - Evaluation Metrics mean: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:06,342 - INFO - Evaluation Metrics best: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:06,344 - INFO - Evaluation Metrics weighted: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:45:06,346 - INFO - Metrics saved to results\\sample_databinary\\RandomForestClassifier\\experiment_a24a3b00\\metrics.json\n",
      "2025-05-13 13:45:06,348 - INFO - Predictions saved to results\\sample_databinary\\RandomForestClassifier\\experiment_a24a3b00\\predictions.csv\n",
      "2025-05-13 13:45:06,356 - INFO - Updated experiments at results\\sample_databinary\\RandomForestClassifier\\experiments.json\n",
      "2025-05-13 13:45:06,365 - INFO - Updated experiments at results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:45:06,366 - INFO - Updated experiments at results\\sample_databinary\\RandomForestClassifier\\experiments.json and results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:45:06,367 - INFO - All experiments completed.\n",
      "2025-05-13 13:45:06,368 - INFO - ================================================================================\n",
      "2025-05-13 13:45:06,369 - INFO - Running config: Config(dataset='../sample_data/regression', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=MinMaxScaler(), model=<function nicon at 0x000001EE1CBEB1C0>, experiment={'action': 'finetune', 'finetune_params': {'n_trials': 5, 'model_params': {'filters_1': [8, 16, 32, 64], 'filters_2': [8, 16, 32, 64], 'filters_3': [8, 16, 32, 64]}}, 'training_params': {'epochs': 10, 'verbose': 0}}, seed=123459456)\n",
      "2025-05-13 13:45:06,370 - INFO - ================================================================================\n",
      "2025-05-13 13:45:06,371 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.830524206161499 seconds\n",
      "####################\n",
      "Config 8: config8\n",
      "####################\n",
      ">> Browsing ../sample_data/regression\n",
      "No train_group file found for ../sample_data/regression.\n",
      "No test_group file found for ../sample_data/regression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:07,374 - INFO - Dataset(x_train:(130, 2151) - y_train:(130, 1), x_test:(59, 2151) - y_test:(59, 1))\n",
      "2025-05-13 13:45:07,375 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:45:07,534 - INFO - Dataset(x_train:(130, 2151) - y_train:(130, 1), x_test:(59, 2151) - y_test:(59, 1))\n",
      "Folds size: 86-44, 87-43, 87-43\n",
      "2025-05-13 13:45:07,535 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:45:07,663 - INFO - Running config > {'dataset': '../sample_data/regression', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}, 'model': {'function': 'nirs4all.presets.ref_models.nicon'}, 'experiment': {'action': 'finetune', 'finetune_params': {'n_trials': 5, 'model_params': {'filters_1': [8, 16, 32, 64], 'filters_2': [8, 16, 32, 64], 'filters_3': [8, 16, 32, 64]}}, 'training_params': {'epochs': 10, 'verbose': 0}, 'metrics': ['mse', 'mae'], 'task': 'regression'}, 'seed': 123459456}\n",
      "2025-05-13 13:45:07,664 - INFO - Starting new experiment experiment_155c7472.\n",
      "2025-05-13 13:45:07,665 - INFO - Experiment prepared at results\\sample_dataregression\\nicon\\experiment_155c7472\n",
      "2025-05-13 13:45:07,666 - INFO - Finetuning the model\n",
      "[I 2025-05-13 13:45:07,785] A new study created in memory with name: no-name-76b3fa5d-00b9-40e3-8e6b-2de1943708fd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Training fold with shapes: (130, 2151, 1), (130, 1), (59, 2151, 1), (59, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (130, 2151, 1) (130, 1) (59, 2151, 1) (59, 1)\n",
      "Training fold with shapes: (130, 2151, 1), (130, 1), (59, 2151, 1), (59, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (130, 2151, 1) (130, 1) (59, 2151, 1) (59, 1)\n",
      "Training fold with shapes: (130, 2151, 1), (130, 1), (59, 2151, 1), (59, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (130, 2151, 1) (130, 1) (59, 2151, 1) (59, 1)\n",
      "Training fold with shapes: (130, 2151, 1), (130, 1), (59, 2151, 1), (59, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (130, 2151, 1) (130, 1) (59, 2151, 1) (59, 1)\n",
      "Training fold with shapes: (130, 2151, 1), (130, 1), (59, 2151, 1), (59, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (130, 2151, 1) (130, 1) (59, 2151, 1) (59, 1)\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:16,704] Trial 1 finished with value: 0.02851066926742472 and parameters: {'filters_1': 64, 'filters_2': 32, 'filters_3': 16}. Best is trial 1 with value: 0.02851066926742472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:16,925] Trial 0 finished with value: 0.028249484174671515 and parameters: {'filters_1': 32, 'filters_2': 16, 'filters_3': 8}. Best is trial 0 with value: 0.028249484174671515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:17,070] Trial 4 finished with value: 0.027544127828307292 and parameters: {'filters_1': 32, 'filters_2': 32, 'filters_3': 8}. Best is trial 4 with value: 0.027544127828307292.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:17,202] Trial 3 finished with value: 0.02624005754120466 and parameters: {'filters_1': 64, 'filters_2': 32, 'filters_3': 64}. Best is trial 3 with value: 0.02624005754120466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:17,470] Trial 2 finished with value: 0.02624005754120466 and parameters: {'filters_1': 16, 'filters_2': 32, 'filters_3': 32}. Best is trial 3 with value: 0.02624005754120466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: {'filters_1': 64, 'filters_2': 32, 'filters_3': 64}\n",
      "Model cloned\n",
      "Model cloned\n",
      "Training fold with shapes: (86, 2151, 1), (86, 1), (44, 2151, 1), (44, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (86, 2151, 1) (86, 1) (44, 2151, 1) (44, 1)\n",
      "Training fold with shapes: (87, 2151, 1), (87, 1), (43, 2151, 1), (43, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (87, 2151, 1) (87, 1) (43, 2151, 1) (43, 1)\n",
      "Training fold with shapes: (87, 2151, 1), (87, 1), (43, 2151, 1), (43, 1)\n",
      "mse ['mse', 'mae']\n",
      "Training with shapes: (87, 2151, 1) (87, 1) (43, 2151, 1) (43, 1)\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:26,450 - INFO - Evaluation Metrics fold_0: {'mse': 584.8327834884916, 'mae': 20.07789805137505}\n",
      "2025-05-13 13:45:26,452 - INFO - Evaluation Metrics fold_1: {'mse': 581.1890833727418, 'mae': 20.117717057567535}\n",
      "2025-05-13 13:45:26,452 - INFO - Evaluation Metrics fold_2: {'mse': 577.1784410390445, 'mae': 20.035011147967843}\n",
      "2025-05-13 13:45:26,453 - INFO - Evaluation Metrics mean: {'mse': 579.9496804636982, 'mae': 20.073040745622023}\n",
      "2025-05-13 13:45:26,454 - INFO - Evaluation Metrics best: {'mse': 577.1784410390445, 'mae': 20.035011147967843}\n",
      "2025-05-13 13:45:26,456 - INFO - Evaluation Metrics weighted: {'mse': 579.9350783478428, 'mae': 20.072916011201634}\n",
      "2025-05-13 13:45:26,458 - INFO - Metrics saved to results\\sample_dataregression\\nicon\\experiment_155c7472\\metrics.json\n",
      "2025-05-13 13:45:26,460 - INFO - Best parameters {'filters_1': 64, 'filters_2': 32, 'filters_3': 64} saved to results\\sample_dataregression\\nicon\\experiment_155c7472\\best_params.json\n",
      "2025-05-13 13:45:26,462 - INFO - Predictions saved to results\\sample_dataregression\\nicon\\experiment_155c7472\\predictions.csv\n",
      "2025-05-13 13:45:26,472 - INFO - Updated experiments at results\\sample_dataregression\\nicon\\experiments.json\n",
      "2025-05-13 13:45:26,484 - INFO - Updated experiments at results\\sample_dataregression\\experiments.json\n",
      "2025-05-13 13:45:26,485 - INFO - Updated experiments at results\\sample_dataregression\\nicon\\experiments.json and results\\sample_dataregression\\experiments.json\n",
      "2025-05-13 13:45:26,486 - INFO - All experiments completed.\n",
      "2025-05-13 13:45:26,487 - INFO - ================================================================================\n",
      "2025-05-13 13:45:26,488 - INFO - Running config: Config(dataset='../sample_data/regression', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=MinMaxScaler(), model={'class': 'sklearn.cross_decomposition.PLSRegression', 'model_params': {'n_components': 21}}, experiment={'action': 'finetune', 'finetune_params': {'model_params': {'n_components': ('int', 5, 20)}, 'training_params': {}, 'tuner': 'sklearn'}}, seed=123459456)\n",
      "2025-05-13 13:45:26,489 - INFO - ================================================================================\n",
      "2025-05-13 13:45:26,490 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 20.11732006072998 seconds\n",
      "####################\n",
      "Config 9: config9\n",
      "####################\n",
      ">> Browsing ../sample_data/regression\n",
      "No train_group file found for ../sample_data/regression.\n",
      "No test_group file found for ../sample_data/regression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:27,500 - INFO - Dataset(x_train:(130, 2151) - y_train:(130, 1), x_test:(59, 2151) - y_test:(59, 1))\n",
      "2025-05-13 13:45:27,501 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:45:27,662 - INFO - Dataset(x_train:(130, 2151) - y_train:(130, 1), x_test:(59, 2151) - y_test:(59, 1))\n",
      "Folds size: 86-44, 87-43, 87-43\n",
      "2025-05-13 13:45:27,662 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:45:27,664 - INFO - Running config > {'dataset': '../sample_data/regression', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}, 'model': {'class': 'sklearn.cross_decomposition.PLSRegression', 'model_params': {'n_components': 21}}, 'experiment': {'action': 'finetune', 'finetune_params': {'model_params': {'n_components': ['int', 5, 20]}, 'training_params': {}, 'tuner': 'sklearn'}, 'metrics': ['mse', 'mae'], 'task': 'regression'}, 'seed': 123459456}\n",
      "2025-05-13 13:45:27,666 - INFO - Starting new experiment experiment_b6fd49bc.\n",
      "2025-05-13 13:45:27,667 - INFO - Experiment prepared at results\\sample_dataregression\\PLSRegression\\experiment_b6fd49bc\n",
      "2025-05-13 13:45:27,668 - INFO - Finetuning the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework: sklearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:30,945 - INFO - Evaluation Metrics fold_0: {'mse': 164.43483652671077, 'mae': 9.938006697923807}\n",
      "2025-05-13 13:45:30,946 - INFO - Evaluation Metrics fold_1: {'mse': 201.5321401654454, 'mae': 11.037931824573585}\n",
      "2025-05-13 13:45:30,947 - INFO - Evaluation Metrics fold_2: {'mse': 184.16310795013413, 'mae': 10.090131466650492}\n",
      "2025-05-13 13:45:30,948 - INFO - Evaluation Metrics mean: {'mse': 125.88287894420644, 'mae': 8.61287605770704}\n",
      "2025-05-13 13:45:30,949 - INFO - Evaluation Metrics best: {'mse': 164.43483652671077, 'mae': 9.938006697923807}\n",
      "2025-05-13 13:45:30,950 - INFO - Evaluation Metrics weighted: {'mse': 124.85239769013474, 'mae': 8.534863992415692}\n",
      "2025-05-13 13:45:30,951 - INFO - Metrics saved to results\\sample_dataregression\\PLSRegression\\experiment_b6fd49bc\\metrics.json\n",
      "2025-05-13 13:45:30,952 - INFO - Best parameters {'n_components': 19} saved to results\\sample_dataregression\\PLSRegression\\experiment_b6fd49bc\\best_params.json\n",
      "2025-05-13 13:45:30,954 - INFO - Predictions saved to results\\sample_dataregression\\PLSRegression\\experiment_b6fd49bc\\predictions.csv\n",
      "2025-05-13 13:45:30,964 - INFO - Updated experiments at results\\sample_dataregression\\PLSRegression\\experiments.json\n",
      "2025-05-13 13:45:30,976 - INFO - Updated experiments at results\\sample_dataregression\\experiments.json\n",
      "2025-05-13 13:45:30,977 - INFO - Updated experiments at results\\sample_dataregression\\PLSRegression\\experiments.json and results\\sample_dataregression\\experiments.json\n",
      "2025-05-13 13:45:30,978 - INFO - All experiments completed.\n",
      "2025-05-13 13:45:30,979 - INFO - ================================================================================\n",
      "2025-05-13 13:45:30,979 - INFO - Running config: Config(dataset='../sample_data/classification', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<function nicon_classification at 0x000001EE1CBEB6D0>, experiment={'action': 'finetune', 'task': 'classification', 'finetune_params': {'n_trials': 5, 'model_params': {'filters_1': [8, 16, 32, 64], 'filters_2': [8, 16, 32, 64], 'filters_3': [8, 16, 32, 64]}}, 'training_params': {'epochs': 5, 'verbose': 0}}, seed=246918912)\n",
      "2025-05-13 13:45:30,981 - INFO - ================================================================================\n",
      "2025-05-13 13:45:30,982 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: {'n_components': 19}\n",
      "Training fold 1, with shapes: (86, 2151) (86, 1) (44, 2151) (44, 1)\n",
      "Training fold 2, with shapes: (87, 2151) (87, 1) (43, 2151) (43, 1)\n",
      "Training fold 3, with shapes: (87, 2151) (87, 1) (43, 2151) (43, 1)\n",
      "Time elapsed: 4.491666793823242 seconds\n",
      "####################\n",
      "Config 10: config10\n",
      "####################\n",
      ">> Browsing ../sample_data/classification\n",
      "No train_group file found for ../sample_data/classification.\n",
      "No test_group file found for ../sample_data/classification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:31,779 - INFO - Dataset(x_train:(48, 2152) - y_train:(48, 1), x_test:(18, 2152) - y_test:(18, 1))\n",
      "2025-05-13 13:45:31,780 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:45:31,927 - INFO - Dataset(x_train:(48, 2152) - y_train:(48, 1), x_test:(18, 2152) - y_test:(18, 1))\n",
      "Folds size: 32-16, 32-16, 32-16\n",
      "2025-05-13 13:45:31,928 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:45:32,050 - INFO - Running config > {'dataset': '../sample_data/classification', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'function': 'nirs4all.presets.ref_models.nicon_classification'}, 'experiment': {'action': 'finetune', 'task': 'classification', 'finetune_params': {'n_trials': 5, 'model_params': {'filters_1': [8, 16, 32, 64], 'filters_2': [8, 16, 32, 64], 'filters_3': [8, 16, 32, 64]}}, 'training_params': {'epochs': 5, 'verbose': 0, 'loss': 'sparse_categorical_crossentropy'}, 'metrics': ['accuracy'], 'num_classes': 10}, 'seed': 246918912}\n",
      "2025-05-13 13:45:32,052 - INFO - Starting new experiment experiment_31520049.\n",
      "2025-05-13 13:45:32,053 - INFO - Experiment prepared at results\\sample_dataclassification\\nicon_classification\\experiment_31520049\n",
      "2025-05-13 13:45:32,054 - INFO - Finetuning the model\n",
      "[I 2025-05-13 13:45:32,177] A new study created in memory with name: no-name-8271a89b-dfec-441a-8573-2b3938e7b2cd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Training fold with shapes: (48, 2152, 1), (48, 1), (18, 2152, 1), (18, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training fold with shapes: (48, 2152, 1), (48, 1), (18, 2152, 1), (18, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training fold with shapes: (48, 2152, 1), (48, 1), (18, 2152, 1), (18, 1)\n",
      "Training fold with shapes: (48, 2152, 1), (48, 1), (18, 2152, 1), (18, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training fold with shapes: (48, 2152, 1), (48, 1), (18, 2152, 1), (18, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training with shapes: (48, 2152, 1) (48,) (18, 2152, 1) (18,)\n",
      "Training with shapes: (48, 2152, 1) (48,) (18, 2152, 1) (18,)\n",
      "Training with shapes: (48, 2152, 1) (48,) (18, 2152, 1) (18,)\n",
      "Training with shapes: (48, 2152, 1) (48,) (18, 2152, 1) (18,)\n",
      "Training with shapes: (48, 2152, 1) (48,) (18, 2152, 1) (18,)\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x000001EE9E359BD0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:39,968] Trial 0 finished with value: 0.0 and parameters: {'filters_1': 16, 'filters_2': 8, 'filters_3': 64}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:40,293] Trial 1 finished with value: 0.0 and parameters: {'filters_1': 32, 'filters_2': 8, 'filters_3': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:40,456] Trial 2 finished with value: 0.0 and parameters: {'filters_1': 16, 'filters_2': 64, 'filters_3': 16}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-13 13:45:40,467] Trial 4 finished with value: 0.0 and parameters: {'filters_1': 8, 'filters_2': 32, 'filters_3': 64}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:40,544] Trial 3 finished with value: 0.0 and parameters: {'filters_1': 16, 'filters_2': 64, 'filters_3': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: {'filters_1': 16, 'filters_2': 8, 'filters_3': 64}\n",
      "Model cloned\n",
      "Model cloned\n",
      "Training fold with shapes: (32, 2152, 1), (32, 1), (16, 2152, 1), (16, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training with shapes: (32, 2152, 1) (32,) (16, 2152, 1) (16,)\n",
      "Training fold with shapes: (32, 2152, 1), (32, 1), (16, 2152, 1), (16, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training with shapes: (32, 2152, 1) (32,) (16, 2152, 1) (16,)\n",
      "Training fold with shapes: (32, 2152, 1), (32, 1), (16, 2152, 1), (16, 1)\n",
      "sparse_categorical_crossentropy ['accuracy']\n",
      "Training with shapes: (32, 2152, 1) (32,) (16, 2152, 1) (16,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:47,414 - INFO - Evaluation Metrics fold_0: {'accuracy': 0.0}\n",
      "2025-05-13 13:45:47,415 - INFO - Evaluation Metrics fold_1: {'accuracy': 0.0}\n",
      "2025-05-13 13:45:47,416 - INFO - Evaluation Metrics fold_2: {'accuracy': 0.0}\n",
      "2025-05-13 13:45:47,417 - INFO - Evaluation Metrics mean: {'accuracy': 0.0}\n",
      "2025-05-13 13:45:47,418 - INFO - Evaluation Metrics best: {'accuracy': 0.0}\n",
      "2025-05-13 13:45:47,419 - INFO - Evaluation Metrics weighted: {'accuracy': 0.0}\n",
      "2025-05-13 13:45:47,421 - INFO - Metrics saved to results\\sample_dataclassification\\nicon_classification\\experiment_31520049\\metrics.json\n",
      "2025-05-13 13:45:47,423 - INFO - Best parameters {'filters_1': 16, 'filters_2': 8, 'filters_3': 64} saved to results\\sample_dataclassification\\nicon_classification\\experiment_31520049\\best_params.json\n",
      "2025-05-13 13:45:47,425 - INFO - Predictions saved to results\\sample_dataclassification\\nicon_classification\\experiment_31520049\\predictions.csv\n",
      "2025-05-13 13:45:47,435 - INFO - Updated experiments at results\\sample_dataclassification\\nicon_classification\\experiments.json\n",
      "2025-05-13 13:45:47,444 - INFO - Updated experiments at results\\sample_dataclassification\\experiments.json\n",
      "2025-05-13 13:45:47,446 - INFO - Updated experiments at results\\sample_dataclassification\\nicon_classification\\experiments.json and results\\sample_dataclassification\\experiments.json\n",
      "2025-05-13 13:45:47,446 - INFO - All experiments completed.\n",
      "2025-05-13 13:45:47,448 - INFO - ================================================================================\n",
      "2025-05-13 13:45:47,448 - INFO - Running config: Config(dataset='../sample_data/binary', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<function nicon_classification at 0x000001EE1CBEB6D0>, experiment={'action': 'finetune', 'task': 'classification', 'finetune_params': {'n_trials': 5, 'model_params': {'filters_1': [8, 16, 32, 64], 'filters_2': [8, 16, 32, 64], 'filters_3': [8, 16, 32, 64]}}, 'training_params': {'epochs': 5, 'verbose': 0, 'loss': 'sparse_categorical_crossentropy'}, 'metrics': ['accuracy'], 'num_classes': 10}, seed=246918912)\n",
      "2025-05-13 13:45:47,450 - INFO - ================================================================================\n",
      "2025-05-13 13:45:47,450 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 16.469086170196533 seconds\n",
      "####################\n",
      "Config 11: config10b\n",
      "####################\n",
      ">> Browsing ../sample_data/binary\n",
      "No train_group file found for ../sample_data/binary.\n",
      "No test_group file found for ../sample_data/binary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:45:48,302 - INFO - Dataset(x_train:(300, 1665) - y_train:(300, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "2025-05-13 13:45:48,303 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:45:48,450 - INFO - Dataset(x_train:(300, 1665) - y_train:(300, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "Folds size: 200-100, 200-100, 200-100\n",
      "2025-05-13 13:45:48,451 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:45:48,566 - INFO - Running config > {'dataset': '../sample_data/binary', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'function': 'nirs4all.presets.ref_models.nicon_classification'}, 'experiment': {'action': 'finetune', 'task': 'classification', 'finetune_params': {'n_trials': 5, 'model_params': {'filters_1': [8, 16, 32, 64], 'filters_2': [8, 16, 32, 64], 'filters_3': [8, 16, 32, 64]}}, 'training_params': {'epochs': 5, 'verbose': 0, 'loss': 'sparse_categorical_crossentropy'}, 'metrics': ['accuracy'], 'num_classes': 2}, 'seed': 246918912}\n",
      "2025-05-13 13:45:48,568 - INFO - Starting new experiment experiment_07602e30.\n",
      "2025-05-13 13:45:48,571 - INFO - Experiment prepared at results\\sample_databinary\\nicon_classification\\experiment_07602e30\n",
      "2025-05-13 13:45:48,572 - INFO - Finetuning the model\n",
      "[I 2025-05-13 13:45:48,702] A new study created in memory with name: no-name-db91f676-0bb1-4877-be23-1e259574adde\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Model cloned\n",
      "Model cloned\n",
      "Using framework: tensorflow\n",
      "Training fold with shapes: (300, 1665, 1), (300, 1), (129, 1665, 1), (129, 1)\n",
      "[INFO] Overriding loss 'sparse_categorical_crossentropy' with 'binary_crossentropy' for TensorFlow classification (num_classes=2)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (300, 1665, 1) (300, 1) (129, 1665, 1) (129, 1)\n",
      "Training fold with shapes: (300, 1665, 1), (300, 1), (129, 1665, 1), (129, 1)\n",
      "[INFO] Overriding loss 'sparse_categorical_crossentropy' with 'binary_crossentropy' for TensorFlow classification (num_classes=2)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (300, 1665, 1) (300, 1) (129, 1665, 1) (129, 1)\n",
      "Training fold with shapes: (300, 1665, 1), (300, 1), (129, 1665, 1), (129, 1)\n",
      "[INFO] Overriding loss 'sparse_categorical_crossentropy' with 'binary_crossentropy' for TensorFlow classification (num_classes=2)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (300, 1665, 1) (300, 1) (129, 1665, 1) (129, 1)\n",
      "Training fold with shapes: (300, 1665, 1), (300, 1), (129, 1665, 1), (129, 1)\n",
      "[INFO] Overriding loss 'sparse_categorical_crossentropy' with 'binary_crossentropy' for TensorFlow classification (num_classes=2)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training fold with shapes: (300, 1665, 1), (300, 1), (129, 1665, 1), (129, 1)\n",
      "[INFO] Overriding loss 'sparse_categorical_crossentropy' with 'binary_crossentropy' for TensorFlow classification (num_classes=2)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (300, 1665, 1) (300, 1) (129, 1665, 1) (129, 1)\n",
      "Training with shapes: (300, 1665, 1) (300, 1) (129, 1665, 1) (129, 1)\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:57,136] Trial 4 finished with value: 0.5426356589147286 and parameters: {'filters_1': 16, 'filters_2': 16, 'filters_3': 8}. Best is trial 4 with value: 0.5426356589147286.\n",
      "[I 2025-05-13 13:45:57,139] Trial 0 finished with value: 0.6046511627906976 and parameters: {'filters_1': 64, 'filters_2': 32, 'filters_3': 32}. Best is trial 4 with value: 0.5426356589147286.\n",
      "[I 2025-05-13 13:45:57,141] Trial 1 finished with value: 0.7131782945736435 and parameters: {'filters_1': 8, 'filters_2': 16, 'filters_3': 32}. Best is trial 4 with value: 0.5426356589147286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:57,420] Trial 2 finished with value: 0.4806201550387597 and parameters: {'filters_1': 16, 'filters_2': 32, 'filters_3': 8}. Best is trial 2 with value: 0.4806201550387597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 13:45:57,729] Trial 3 finished with value: 0.7131782945736435 and parameters: {'filters_1': 16, 'filters_2': 8, 'filters_3': 64}. Best is trial 2 with value: 0.4806201550387597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: {'filters_1': 16, 'filters_2': 32, 'filters_3': 8}\n",
      "Model cloned\n",
      "Model cloned\n",
      "Training fold with shapes: (200, 1665, 1), (200, 1), (100, 1665, 1), (100, 1)\n",
      "[INFO] Overriding loss 'sparse_categorical_crossentropy' with 'binary_crossentropy' for TensorFlow classification (num_classes=2)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (200, 1665, 1) (200, 1) (100, 1665, 1) (100, 1)\n",
      "Training fold with shapes: (200, 1665, 1), (200, 1), (100, 1665, 1), (100, 1)\n",
      "[INFO] Overriding loss 'sparse_categorical_crossentropy' with 'binary_crossentropy' for TensorFlow classification (num_classes=2)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (200, 1665, 1) (200, 1) (100, 1665, 1) (100, 1)\n",
      "Training fold with shapes: (200, 1665, 1), (200, 1), (100, 1665, 1), (100, 1)\n",
      "[INFO] Overriding loss 'sparse_categorical_crossentropy' with 'binary_crossentropy' for TensorFlow classification (num_classes=2)\n",
      "binary_crossentropy ['accuracy']\n",
      "Training with shapes: (200, 1665, 1) (200, 1) (100, 1665, 1) (100, 1)\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:46:05,863 - INFO - Evaluation Metrics fold_0: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:05,864 - INFO - Evaluation Metrics fold_1: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:05,865 - INFO - Evaluation Metrics fold_2: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:05,866 - INFO - Evaluation Metrics mean: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:05,867 - INFO - Evaluation Metrics best: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:05,868 - INFO - Evaluation Metrics weighted: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:05,871 - INFO - Metrics saved to results\\sample_databinary\\nicon_classification\\experiment_07602e30\\metrics.json\n",
      "2025-05-13 13:46:05,872 - INFO - Best parameters {'filters_1': 16, 'filters_2': 32, 'filters_3': 8} saved to results\\sample_databinary\\nicon_classification\\experiment_07602e30\\best_params.json\n",
      "2025-05-13 13:46:05,874 - INFO - Predictions saved to results\\sample_databinary\\nicon_classification\\experiment_07602e30\\predictions.csv\n",
      "2025-05-13 13:46:05,884 - INFO - Updated experiments at results\\sample_databinary\\nicon_classification\\experiments.json\n",
      "2025-05-13 13:46:05,893 - INFO - Updated experiments at results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:46:05,894 - INFO - Updated experiments at results\\sample_databinary\\nicon_classification\\experiments.json and results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:46:05,895 - INFO - All experiments completed.\n",
      "2025-05-13 13:46:05,896 - INFO - ================================================================================\n",
      "2025-05-13 13:46:05,897 - INFO - Running config: Config(dataset='../sample_data/classification', x_pipeline=[RobustScaler(), {'samples': [Rotate_Translate(apply_on=6)], 'balance': True}, {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<class 'sklearn.ensemble._forest.RandomForestClassifier'>, experiment={'action': 'finetune', 'task': 'classification', 'finetune_params': {'model_params': {'n_estimators': ('int', 5, 20)}, 'training_params': {}, 'tuner': 'sklearn'}}, seed=246918912)\n",
      "2025-05-13 13:46:05,899 - INFO - ================================================================================\n",
      "2025-05-13 13:46:05,899 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 18.448750019073486 seconds\n",
      "####################\n",
      "Config 12: config11\n",
      "####################\n",
      ">> Browsing ../sample_data/classification\n",
      "No train_group file found for ../sample_data/classification.\n",
      "No test_group file found for ../sample_data/classification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:46:06,724 - INFO - Dataset(x_train:(48, 2152) - y_train:(48, 1), x_test:(18, 2152) - y_test:(18, 1))\n",
      "2025-05-13 13:46:06,724 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:46:07,027 - INFO - Dataset(x_train:(90, 2152) - y_train:(90, 1), x_test:(18, 2152) - y_test:(18, 1))\n",
      "Folds size: 60-30, 60-30, 60-30\n",
      "2025-05-13 13:46:07,029 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:46:07,031 - INFO - Running config > {'dataset': '../sample_data/classification', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'samples': [{'class': 'nirs4all.transformations.Rotate_Translate', 'params': {'apply_on': 6, 'copy': True, 'p_range': 2, 'random_state': None, 'y_factor': 3}}], 'balance': True}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'class': 'sklearn.ensemble.RandomForestClassifier', 'params': None}, 'experiment': {'action': 'finetune', 'task': 'classification', 'finetune_params': {'model_params': {'n_estimators': ['int', 5, 20]}, 'training_params': {}, 'tuner': 'sklearn'}, 'metrics': ['accuracy'], 'num_classes': 10}, 'seed': 246918912}\n",
      "2025-05-13 13:46:07,032 - INFO - Starting new experiment experiment_2d6a5a41.\n",
      "2025-05-13 13:46:07,034 - INFO - Experiment prepared at results\\sample_dataclassification\\RandomForestClassifier\\experiment_2d6a5a41\n",
      "2025-05-13 13:46:07,035 - INFO - Finetuning the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 1, 2152) (48, 1)\n",
      "{np.int64(0): 9, np.int64(1): 7, np.int64(2): 7, np.int64(3): 8, np.int64(4): 6, np.int64(5): 3, np.int64(6): 3, np.int64(7): 1, np.int64(8): 2, np.int64(9): 2}\n",
      "{np.int64(0): 0, np.int64(1): 2, np.int64(2): 2, np.int64(3): 1, np.int64(4): 3, np.int64(5): 6, np.int64(6): 6, np.int64(7): 8, np.int64(8): 7, np.int64(9): 7}\n",
      "(1, 90, 1, 2152) (90, 1)\n",
      "{np.int64(0): 9, np.int64(1): 9, np.int64(2): 9, np.int64(3): 9, np.int64(4): 9, np.int64(5): 9, np.int64(6): 9, np.int64(7): 9, np.int64(8): 9, np.int64(9): 9}\n",
      "Using framework: sklearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:46:07,671 - INFO - Evaluation Metrics fold_0: {'accuracy': 0.16666666666666666}\n",
      "2025-05-13 13:46:07,672 - INFO - Evaluation Metrics fold_1: {'accuracy': 0.16666666666666666}\n",
      "2025-05-13 13:46:07,673 - INFO - Evaluation Metrics fold_2: {'accuracy': 0.2222222222222222}\n",
      "2025-05-13 13:46:07,674 - INFO - Evaluation Metrics mean: {'accuracy': 0.2222222222222222}\n",
      "2025-05-13 13:46:07,674 - INFO - Evaluation Metrics best: {'accuracy': 0.2222222222222222}\n",
      "2025-05-13 13:46:07,675 - INFO - Evaluation Metrics weighted: {'accuracy': 0.2222222222222222}\n",
      "2025-05-13 13:46:07,677 - INFO - Metrics saved to results\\sample_dataclassification\\RandomForestClassifier\\experiment_2d6a5a41\\metrics.json\n",
      "2025-05-13 13:46:07,677 - INFO - Best parameters {'n_estimators': 17, 'num_classes': 10} saved to results\\sample_dataclassification\\RandomForestClassifier\\experiment_2d6a5a41\\best_params.json\n",
      "2025-05-13 13:46:07,679 - INFO - Predictions saved to results\\sample_dataclassification\\RandomForestClassifier\\experiment_2d6a5a41\\predictions.csv\n",
      "2025-05-13 13:46:07,688 - INFO - Updated experiments at results\\sample_dataclassification\\RandomForestClassifier\\experiments.json\n",
      "2025-05-13 13:46:07,698 - INFO - Updated experiments at results\\sample_dataclassification\\experiments.json\n",
      "2025-05-13 13:46:07,699 - INFO - Updated experiments at results\\sample_dataclassification\\RandomForestClassifier\\experiments.json and results\\sample_dataclassification\\experiments.json\n",
      "2025-05-13 13:46:07,700 - INFO - All experiments completed.\n",
      "2025-05-13 13:46:07,701 - INFO - ================================================================================\n",
      "2025-05-13 13:46:07,702 - INFO - Running config: Config(dataset='../sample_data/binary', x_pipeline=[RobustScaler(), {'split': RepeatedKFold(n_repeats=1, n_splits=3, random_state=None)}, MinMaxScaler()], y_pipeline=None, model=<class 'sklearn.ensemble._forest.RandomForestClassifier'>, experiment={'action': 'finetune', 'task': 'classification', 'finetune_params': {'model_params': {'n_estimators': ('int', 5, 20)}, 'training_params': {'loss': 'sparse_categorical_crossentropy'}, 'tuner': 'sklearn'}, 'metrics': ['accuracy'], 'num_classes': 10}, seed=246918912)\n",
      "2025-05-13 13:46:07,704 - INFO - ================================================================================\n",
      "2025-05-13 13:46:07,705 - INFO - ### LOADING DATASET ###\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: {'n_estimators': 17, 'num_classes': 10}\n",
      "Training fold 1, with shapes: (60, 2152) (60, 1) (30, 2152) (30, 1)\n",
      "Training fold 2, with shapes: (60, 2152) (60, 1) (30, 2152) (30, 1)\n",
      "Training fold 3, with shapes: (60, 2152) (60, 1) (30, 2152) (30, 1)\n",
      "Time elapsed: 1.804358959197998 seconds\n",
      "####################\n",
      "Config 13: config11b\n",
      "####################\n",
      ">> Browsing ../sample_data/binary\n",
      "No train_group file found for ../sample_data/binary.\n",
      "No test_group file found for ../sample_data/binary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:46:08,538 - INFO - Dataset(x_train:(300, 1665) - y_train:(300, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "2025-05-13 13:46:08,538 - INFO - ### PROCESSING DATASET ###\n",
      "2025-05-13 13:46:08,683 - INFO - Dataset(x_train:(300, 1665) - y_train:(300, 1), x_test:(129, 1665) - y_test:(129, 1))\n",
      "Folds size: 200-100, 200-100, 200-100\n",
      "2025-05-13 13:46:08,684 - INFO - ### PREPARING MODEL ###\n",
      "2025-05-13 13:46:08,686 - INFO - Running config > {'dataset': '../sample_data/binary', 'x_pipeline': [{'class': 'sklearn.preprocessing.RobustScaler', 'params': {'copy': True, 'quantile_range': [25.0, 75.0], 'unit_variance': False, 'with_centering': True, 'with_scaling': True}}, {'split': {'class': 'sklearn.model_selection.RepeatedKFold', 'params': {'cv': {'class': 'sklearn.model_selection.KFold', 'params': None}, 'n_repeats': 1, 'random_state': None, 'cvargs': {'n_splits': 3}}}}, {'class': 'sklearn.preprocessing.MinMaxScaler', 'params': {'clip': False, 'copy': True, 'feature_range': [0, 1]}}], 'y_pipeline': None, 'model': {'class': 'sklearn.ensemble.RandomForestClassifier', 'params': None}, 'experiment': {'action': 'finetune', 'task': 'classification', 'finetune_params': {'model_params': {'n_estimators': ['int', 5, 20]}, 'training_params': {'loss': 'sparse_categorical_crossentropy'}, 'tuner': 'sklearn'}, 'metrics': ['accuracy'], 'num_classes': 2}, 'seed': 246918912}\n",
      "2025-05-13 13:46:08,687 - INFO - Starting new experiment experiment_c49bf09a.\n",
      "2025-05-13 13:46:08,688 - INFO - Experiment prepared at results\\sample_databinary\\RandomForestClassifier\\experiment_c49bf09a\n",
      "2025-05-13 13:46:08,689 - INFO - Finetuning the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework: sklearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 13:46:09,356 - INFO - Evaluation Metrics fold_0: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:09,357 - INFO - Evaluation Metrics fold_1: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:09,358 - INFO - Evaluation Metrics fold_2: {'accuracy': 0.9457364341085271}\n",
      "2025-05-13 13:46:09,359 - INFO - Evaluation Metrics mean: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:09,359 - INFO - Evaluation Metrics best: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:09,360 - INFO - Evaluation Metrics weighted: {'accuracy': 0.9534883720930233}\n",
      "2025-05-13 13:46:09,362 - INFO - Metrics saved to results\\sample_databinary\\RandomForestClassifier\\experiment_c49bf09a\\metrics.json\n",
      "2025-05-13 13:46:09,363 - INFO - Best parameters {'n_estimators': 9, 'num_classes': 2} saved to results\\sample_databinary\\RandomForestClassifier\\experiment_c49bf09a\\best_params.json\n",
      "2025-05-13 13:46:09,365 - INFO - Predictions saved to results\\sample_databinary\\RandomForestClassifier\\experiment_c49bf09a\\predictions.csv\n",
      "2025-05-13 13:46:09,373 - INFO - Updated experiments at results\\sample_databinary\\RandomForestClassifier\\experiments.json\n",
      "2025-05-13 13:46:09,382 - INFO - Updated experiments at results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:46:09,384 - INFO - Updated experiments at results\\sample_databinary\\RandomForestClassifier\\experiments.json and results\\sample_databinary\\experiments.json\n",
      "2025-05-13 13:46:09,384 - INFO - All experiments completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: {'n_estimators': 9, 'num_classes': 2}\n",
      "Training fold 1, with shapes: (200, 1665) (200, 1) (100, 1665) (100, 1)\n",
      "Training fold 2, with shapes: (200, 1665) (200, 1) (100, 1665) (100, 1)\n",
      "Training fold 3, with shapes: (200, 1665) (200, 1) (100, 1665) (100, 1)\n",
      "Time elapsed: 1.683943271636963 seconds\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "import time\n",
    "from nirs4all.presets.ref_models import decon, nicon, customizable_nicon, nicon_classification\n",
    "from nirs4all.presets.preprocessings import decon_set, nicon_set\n",
    "from nirs4all.data_splitters import KennardStoneSplitter\n",
    "from nirs4all.transformations import StandardNormalVariate as SNV, SavitzkyGolay as SG, Gaussian as GS, Derivate as  Dv\n",
    "from nirs4all.transformations import Rotate_Translate as RT, Spline_X_Simplification as SXS, Random_X_Operation as RXO\n",
    "from nirs4all.transformations import CropTransformer\n",
    "from nirs4all.core.runner import ExperimentRunner\n",
    "from nirs4all.core.config import Config\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold, RepeatedStratifiedKFold, ShuffleSplit, GroupKFold, StratifiedShuffleSplit, BaseCrossValidator, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "model_sklearn = {\n",
    "    \"class\": \"sklearn.cross_decomposition.PLSRegression\",\n",
    "    \"model_params\": {\n",
    "        \"n_components\": 21,\n",
    "    }\n",
    "}\n",
    "    \n",
    "finetune_pls_experiment = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_components': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "bacon_train = {\"action\": \"train\", \"training_params\": {\"epochs\": 2000, \"batch_size\": 500, \"patience\": 200, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 400}}\n",
    "bacon_train_short = {\"action\": \"train\", \"training_params\": {\"epochs\": 10, \"batch_size\": 500, \"patience\": 20, \"cyclic_lr\": True, \"base_lr\": 1e-6, \"max_lr\": 1e-3, \"step_size\": 40}}\n",
    "bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 10,\n",
    "        \"verbose\":0\n",
    "    }\n",
    "}\n",
    "\n",
    "full_bacon_finetune = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 500,\n",
    "        \"patience\": 100,\n",
    "    },\n",
    "    \"finetune_params\": {\n",
    "        \"nb_trials\": 150,\n",
    "        \"model_params\": {\n",
    "            'spatial_dropout': (float, 0.01, 0.5),\n",
    "            'filters1': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'kernel_size1': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides1': [1, 2, 3, 4, 5],\n",
    "            # 'activation1': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'dropout_rate': (float, 0.01, 0.5),\n",
    "            'filters2': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size2': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides2': [1, 2, 3, 4, 5],\n",
    "            'activation2': ['relu', 'selu', 'elu', 'swish'],\n",
    "            'normalization_method1': ['BatchNormalization', 'LayerNormalization'],\n",
    "            'filters3': [4, 8, 16, 32, 64, 128, 256],\n",
    "            # 'kernel_size3': [3, 5, 7, 9, 11, 13, 15],\n",
    "            # 'strides3': [1, 2, 3, 4, 5],\n",
    "            'activation3': ['relu', 'selu', 'elu', 'swish'],\n",
    "            # 'normalization_method2': ['BatchNormalization', 'LayerNormalization'],\n",
    "            # 'dense_units': [4, 8, 16, 32, 64, 128, 256],\n",
    "            'dense_activation': ['relu', 'selu', 'elu', 'swish'],\n",
    "        },\n",
    "        # \"training_params\": {\n",
    "        #     \"batch_size\": [32, 64, 128, 256, 512],\n",
    "        #     \"cyclic_lr\": [True, False],\n",
    "        #     \"base_lr\": (float, 1e-6, 1e-2),\n",
    "        #     \"max_lr\": (float, 1e-3, 1e-1),\n",
    "        #     \"step_size\": (int, 500, 5000),\n",
    "        # },\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "x_pipeline_full = [\n",
    "    RobustScaler(quantile_range=(0.05, 0.95)),\n",
    "    {\"samples\": [None, None, None, None, SXS, RXO]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(3,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler(feature_range=(0, 0.9), clip=False)\n",
    "]\n",
    "\n",
    "\n",
    "bacon_finetune_classif = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        \"n_trials\": 5,\n",
    "        \"model_params\": {\n",
    "            \"filters_1\": [8, 16, 32, 64], \n",
    "            \"filters_2\": [8, 16, 32, 64], \n",
    "            \"filters_3\": [8, 16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"epochs\": 5,\n",
    "        \"verbose\":0\n",
    "    }\n",
    "}\n",
    "\n",
    "finetune_randomForestclassifier = {\n",
    "    \"action\": \"finetune\",\n",
    "    \"task\": \"classification\",\n",
    "    \"finetune_params\": {\n",
    "        'model_params': {\n",
    "            'n_estimators': ('int', 5, 20),\n",
    "        },\n",
    "        'training_params': {},\n",
    "        'tuner': 'sklearn'\n",
    "    }\n",
    "}\n",
    "\n",
    "x_pipeline_PLS = [\n",
    "    RobustScaler(),\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)},\n",
    "    {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "            \n",
    "            \n",
    "x_pipeline = [\n",
    "    RobustScaler(), \n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)}, \n",
    "    # bacon_set(),\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "x_pipelineb = [\n",
    "    RobustScaler(), \n",
    "    {\"samples\": [RT(6)], \"balance\": True},\n",
    "    # {\"samples\": [None, RT]},\n",
    "    {\"split\": RepeatedKFold(n_splits=3, n_repeats=1)}, \n",
    "    # {\"features\": [None, GS(2,1), SG, SNV, Dv, [GS, SNV], [GS, GS],[GS, SG],[SG, SNV], [GS, Dv], [SG, Dv]]},\n",
    "    MinMaxScaler()\n",
    "]\n",
    "\n",
    "\n",
    "y_pipeline = MinMaxScaler()\n",
    "\n",
    "seed = 123459456\n",
    "\n",
    "dataset1 = {\n",
    "    \"path\": \"../sample_data/regression\",\n",
    "    \"params\": {}\n",
    "}\n",
    "\n",
    "# processing only\n",
    "config1 = Config(\"../sample_data/regression\", x_pipeline_full, y_pipeline, None, None, seed)\n",
    "## TRAINING\n",
    "# regression\n",
    "config2 = Config(dataset1, x_pipeline, y_pipeline, nicon, bacon_train_short, seed)\n",
    "config3 = Config(dataset1, x_pipeline_PLS, y_pipeline, PLSRegression(n_components=10), None, seed)\n",
    "# classification\n",
    "config4 = Config(\"../sample_data/classification\", x_pipeline, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":10, \"patience\": 100, \"verbose\":0}}, seed*2)\n",
    "config4b = Config(\"../sample_data/binary\", x_pipelineb, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":10, \"patience\": 100, \"verbose\":0}}, seed*2)\n",
    "config5 = Config(\"../sample_data/binary\", x_pipeline, None, nicon_classification, {\"task\":\"classification\", \"training_params\":{\"epochs\":5}, \"verbose\":0}, seed*2)\n",
    "config6 = Config(\"../sample_data/classification\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "config7 = Config(\"../sample_data/binary\", x_pipeline, None, RandomForestClassifier, {\"task\":\"classification\"}, seed*2)\n",
    "## FINETUNING\n",
    "# regression\n",
    "config8 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, nicon, bacon_finetune, seed)\n",
    "config9 = Config(\"../sample_data/regression\", x_pipeline, y_pipeline, model_sklearn, finetune_pls_experiment, seed)\n",
    "# classification\n",
    "config10 = Config(\"../sample_data/classification\", x_pipeline, None, nicon_classification, bacon_finetune_classif, seed*2)\n",
    "config10b = Config(\"../sample_data/binary\", x_pipeline, None, nicon_classification, bacon_finetune_classif, seed*2)\n",
    "config11 = Config(\"../sample_data/classification\", x_pipelineb, None, RandomForestClassifier, finetune_randomForestclassifier, seed*2)\n",
    "config11b = Config(\"../sample_data/binary\", x_pipeline, None, RandomForestClassifier, finetune_randomForestclassifier, seed*2)\n",
    "\n",
    "\n",
    "configs = [config1, config2, config3, config4, config4b, config5, config6, config7, config8, config9, config10, config10b, config11, config11b]\n",
    "# configs = [config10b, config11, config11b]\n",
    "# configs = [config3]\n",
    "config_names = [\"config1\", \"config2\", \"config3\", \"config4\", \"config4b\", \"config5\", \"config6\", \"config7\", \"config8\", \"config9\", \"config10\", \"config10b\", \"config11\", \"config11b\"]\n",
    "for i, config in enumerate(configs):\n",
    "    print(\"#\" * 20)\n",
    "    print(f\"Config {i}: {config_names[i]}\")\n",
    "    print(\"#\" * 20)\n",
    "    start = time.time()\n",
    "    runner = ExperimentRunner([config], resume_mode=\"restart\")\n",
    "    datasets, predictions, scores, best_params = runner.run()\n",
    "    end = time.time()\n",
    "    print(f\"Time elapsed: {end-start} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
