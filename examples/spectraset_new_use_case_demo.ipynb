{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5fd12c",
   "metadata": {},
   "source": [
    "# Comprehensive SpectraSet Workflow Demo\n",
    "\n",
    "This notebook demonstrates a detailed workflow using the `SpectraSet` class, including:\n",
    "- Custom data generation for NIRS and Raman spectroscopy.\n",
    "- Sample augmentation with multiple custom transformers.\n",
    "- Source-specific transformations.\n",
    "- Feature augmentation by creating new spectral sources.\n",
    "- Custom grouping of samples.\n",
    "- Stratified train/test splitting.\n",
    "- Repeated K-Fold cross-validation.\n",
    "- Unpacking and inspecting data by groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b228dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup and Imports\n",
    "# Standard library imports\n",
    "import itertools\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import RepeatedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import the SpectraSet class (ensure nirs4all.data.spectraset is in PYTHONPATH or installed)\n",
    "# Assuming spectraset.py is in d:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\data\\\n",
    "import sys\n",
    "sys.path.append('d:\\\\Workspace\\\\ML\\\\NIRS\\\\nirs4all') # Adjust if necessary\n",
    "from nirs4all.data.spectraset import SpectraSet\n",
    "\n",
    "# IPython magic for autoreloading external modules (optional)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578f14b",
   "metadata": {},
   "source": [
    "## 2. Data Generation\n",
    "\n",
    "We will generate a dataset with 10 samples. Each sample corresponds to an \"n\" value from 1 to 5 (each n appearing twice).\n",
    "- **NIRS spectra**: 4 values, calculated as `(n-1) * i` for `i` in `0,1,2,3`.\n",
    "- **Raman spectra**: 5 values, calculated as `(n-1) * i + 5` for `i` in `0,1,2,3,4`.\n",
    "- **Target (y)**: The value of `n`.\n",
    "- **Metadata**:\n",
    "    - `n_numeric`: `n` (integer).\n",
    "    - `n_str`: `n` (string).\n",
    "    - `n_sum_str`: `f\"{n}+{n}\"` (string, e.g., \"1+1\").\n",
    "Initially, each sample has one augmentation (the original spectrum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13cbbc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial SpectraSet (ss_v1) ---\n",
      "\n",
      "Shape of X from ss_v1: (10, 9)\n",
      "Shape of y from ss_v1: (10, 1)\n",
      "**************************************************\n",
      "0: [0. 0. 0. 0.] - [5. 5. 5. 5. 5.]: y = [0]\n",
      "0: [0. 0. 0. 0. 5. 5. 5. 5. 5.] - [0]\n",
      "1: [1. 1. 1. 1.] - [6. 6. 6. 6. 6.]: y = [1]\n",
      "1: [1. 1. 1. 1. 6. 6. 6. 6. 6.] - [1]\n",
      "2: [2. 2. 2. 2.] - [7. 7. 7. 7. 7.]: y = [2]\n",
      "2: [2. 2. 2. 2. 7. 7. 7. 7. 7.] - [2]\n",
      "3: [3. 3. 3. 3.] - [8. 8. 8. 8. 8.]: y = [3]\n",
      "3: [3. 3. 3. 3. 8. 8. 8. 8. 8.] - [3]\n",
      "4: [4. 4. 4. 4.] - [9. 9. 9. 9. 9.]: y = [4]\n",
      "4: [4. 4. 4. 4. 9. 9. 9. 9. 9.] - [4]\n",
      "5: [5. 5. 5. 5.] - [10. 10. 10. 10. 10.]: y = [5]\n",
      "5: [ 5.  5.  5.  5. 10. 10. 10. 10. 10.] - [5]\n",
      "6: [6. 6. 6. 6.] - [11. 11. 11. 11. 11.]: y = [6]\n",
      "6: [ 6.  6.  6.  6. 11. 11. 11. 11. 11.] - [6]\n",
      "7: [7. 7. 7. 7.] - [12. 12. 12. 12. 12.]: y = [7]\n",
      "7: [ 7.  7.  7.  7. 12. 12. 12. 12. 12.] - [7]\n",
      "8: [8. 8. 8. 8.] - [13. 13. 13. 13. 13.]: y = [8]\n",
      "8: [ 8.  8.  8.  8. 13. 13. 13. 13. 13.] - [8]\n",
      "9: [9. 9. 9. 9.] - [14. 14. 14. 14. 14.]: y = [9]\n",
      "9: [ 9.  9.  9.  9. 14. 14. 14. 14. 14.] - [9]\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for Data Generation ---\n",
    "# n_unique_values = 5\n",
    "# samples_per_n = 2\n",
    "total_samples = 10\n",
    "\n",
    "# n_values_for_samples = []\n",
    "# for i in range(1, n_unique_values + 1):\n",
    "#     n_values_for_samples.extend([i] * samples_per_n)\n",
    "# # n_values_for_samples will be [1, 1, 2, 2, 3, 3, 4, 4, 5, 5]\n",
    "\n",
    "# --- Initialize data structures ---\n",
    "spectra_data_v1 = {'nirs': [], 'raman': []}\n",
    "target_y_v1 = np.zeros(total_samples, dtype=int)\n",
    "metadata_v1 = {\n",
    "    'n_numeric': np.zeros(total_samples, dtype=int),\n",
    "    'n_str': np.zeros(total_samples, dtype=object),\n",
    "    'n_sum_str': np.zeros(total_samples, dtype=object)\n",
    "}\n",
    "\n",
    "# --- Populate data ---\n",
    "for s_idx in range(total_samples):\n",
    "    nirs_spectrum = np.array([s_idx for i in range(4)], dtype=float)\n",
    "    spectra_data_v1['nirs'].append([nirs_spectrum]) # List of augmentations, initially one\n",
    "\n",
    "    # Raman data: (n-1)*i + 5 for i in 0,1,2,3,4\n",
    "    raman_spectrum = np.array([s_idx + 5 for i in range(5)], dtype=float)\n",
    "    spectra_data_v1['raman'].append([raman_spectrum]) # List of augmentations, initially one\n",
    "\n",
    "    # Target\n",
    "    target_y_v1[s_idx] = s_idx\n",
    "\n",
    "    # Metadata\n",
    "    metadata_v1['n_numeric'][s_idx] = s_idx\n",
    "    metadata_v1['n_str'][s_idx] = str(s_idx)\n",
    "    metadata_v1['n_sum_str'][s_idx] = f\"{s_idx}+{s_idx}\"\n",
    "\n",
    "\n",
    "\n",
    "# --- Build Initial SpectraSet ---\n",
    "ss_v1 = SpectraSet.build(\n",
    "    spectra=spectra_data_v1,\n",
    "    target=target_y_v1,\n",
    "    metadata=metadata_v1\n",
    ")\n",
    "\n",
    "print(\"--- Initial SpectraSet (ss_v1) ---\")\n",
    "# print(ss_v1.ds)\n",
    "print(f\"\\nShape of X from ss_v1: {ss_v1.X().shape}\")\n",
    "print(f\"Shape of y from ss_v1: {ss_v1.y().shape}\")\n",
    "\n",
    "print(\"*\"*50)\n",
    "# Display one sample's data for verification\n",
    "for i in range(10):\n",
    "    nirs = ss_v1.X(sources=[\"nirs\"])[i]\n",
    "    raman = ss_v1.X(sources=[\"raman\"])[i]\n",
    "    print(f\"{i}: {nirs} - {raman}: y = {ss_v1.y()[i]}\")\n",
    "    print(f\"{i}: {ss_v1.X()[i]} - {ss_v1.y()[i]}\")\n",
    "\n",
    "\n",
    "# ss_v1.ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32be53b",
   "metadata": {},
   "source": [
    "## 3. Custom Transformers for Augmentation\n",
    "\n",
    "We define `TransformerMixin` classes to add specific values to spectra.\n",
    "- `AddNTransformer`: Adds a specified value `N` to each element of a spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2096ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom transformers defined: AddNTransformer\n"
     ]
    }
   ],
   "source": [
    "# --- Define Custom Transformers ---\n",
    "class AddNTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, value_to_add):\n",
    "        self.value_to_add = value_to_add\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self # Nothing to fit\n",
    "\n",
    "    def transform(self, X_list):\n",
    "        # Expects a list of numpy arrays (augmentations for one sample, one source)\n",
    "        # or a single numpy array\n",
    "        if isinstance(X_list, np.ndarray): # Single spectrum\n",
    "             return X_list + self.value_to_add\n",
    "        # If it's a list of spectra (e.g. multiple augmentations for a sample)\n",
    "        return [x + self.value_to_add for x in X_list]\n",
    "\n",
    "\n",
    "# --- Instantiate Transformers ---\n",
    "add1_transformer = AddNTransformer(value_to_add=0.1)\n",
    "add2_transformer = AddNTransformer(value_to_add=0.2)\n",
    "\n",
    "print(\"Custom transformers defined: AddNTransformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a766cbcc",
   "metadata": {},
   "source": [
    "## 4. Sample Augmentation\n",
    "\n",
    "Now, we augment the samples based on their `n` value:\n",
    "- Samples with `n < 4`: Augment with `add1_transformer` (add 1). This adds one new augmentation.\n",
    "- Samples with `n >= 4`: Augment with `add1_transformer` and `add2_transformer` (add 1, then add 2 to original). This adds two new augmentations.\n",
    "\n",
    "The augmentations are applied to the *original* spectra of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b8f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SpectraSet after Sample Augmentation (ss_v2) ---\n",
      "Shape of X from ss_v2: (26, 9)\n",
      "[[5.1 5.1 5.1 5.1 5.1]\n",
      " [9.1 9.1 9.1 9.1 9.1]\n",
      " [9.2 9.2 9.2 9.2 9.2]]\n"
     ]
    }
   ],
   "source": [
    "# --- Deep copy initial spectra data to modify for augmentation ---\n",
    "\n",
    "# --- Apply Sample Augmentation ---\n",
    "for s_idx in range(total_samples):\n",
    "    # Original spectra for this sample (first augmentation)\n",
    "    original_nirs_aug = spectra_data_v1['nirs'][s_idx][0] \n",
    "    original_raman_aug = spectra_data_v1['raman'][s_idx][0]\n",
    "\n",
    "    if s_idx < 4:\n",
    "        # Augment with add1\n",
    "        spectra_data_v2['nirs'][s_idx].append(add1_transformer.transform(original_nirs_aug))\n",
    "        spectra_data_v2['raman'][s_idx].append(add1_transformer.transform(original_raman_aug))\n",
    "    else: # current_n >= 4\n",
    "        # Augment with add1\n",
    "        spectra_data_v2['nirs'][s_idx].append(add1_transformer.transform(original_nirs_aug))\n",
    "        spectra_data_v2['raman'][s_idx].append(add1_transformer.transform(original_raman_aug))\n",
    "        # Augment with add2 (applied to original)\n",
    "        spectra_data_v2['nirs'][s_idx].append(add2_transformer.transform(original_nirs_aug))\n",
    "        spectra_data_v2['raman'][s_idx].append(add2_transformer.transform(original_raman_aug))\n",
    "\n",
    "# --- Build SpectraSet with Augmented Samples ---\n",
    "ss_v2 = SpectraSet.build(\n",
    "    spectra=spectra_data_v2,\n",
    "    target=target_y_v1, # Target and metadata remain the same per original sample\n",
    "    metadata=metadata_v1\n",
    ")\n",
    "\n",
    "print(\"--- SpectraSet after Sample Augmentation (ss_v2) ---\")\n",
    "print(f\"Shape of X from ss_v2: {ss_v2.X().shape}\") \n",
    "\n",
    "# for i in range(len(ss_v2)):\n",
    "#     nirs = ss_v2.X(include_sources=[\"nirs\"])[i]\n",
    "#     raman = ss_v2.X(include_sources=[\"raman\"])[i]\n",
    "#     print(f\"{i}: {nirs} - {raman}: y = {ss_v2.y()[i]}\")\n",
    "    \n",
    "# print(ss_v2.X(include_sources=[\"nirs\"], augment=\"augmented\"))\n",
    "print(ss_v2.subset_by_samples([0, 4]).X(sources=[\"raman\"], augment=\"augmented\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59639f98",
   "metadata": {},
   "source": [
    "## 5. Source-Specific Transformation\n",
    "\n",
    "Next, we transform all spectra (original and their augmentations) based on their source:\n",
    "- **NIRS spectra**: Apply a \"minus 1\" transformation.\n",
    "- **Raman spectra**: Apply a \"plus 100\" transformation.\n",
    "\n",
    "These transformations are applied to *all existing augmentations* for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da1c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Source-Specific Transformers ---\n",
    "class Minus1Transformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X_spectrum): return X_spectrum - 1\n",
    "\n",
    "class Plus100Transformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X_spectrum): return X_spectrum + 100\n",
    "\n",
    "minus1_transformer = Minus1Transformer()\n",
    "plus100_transformer = Plus100Transformer()\n",
    "\n",
    "# --- Deep copy augmented spectra data for source transformation ---\n",
    "spectra_data_v3 = {\n",
    "    src: [[np.copy(aug) for aug in augs_list] for augs_list in sample_augs_list]\n",
    "    for src, sample_augs_list in spectra_data_v2.items()\n",
    "}\n",
    "\n",
    "# --- Apply Source-Specific Transformations ---\n",
    "# For NIRS source\n",
    "for s_idx in range(total_samples):\n",
    "    for aug_idx in range(len(spectra_data_v3['nirs'][s_idx])):\n",
    "        spectra_data_v3['nirs'][s_idx][aug_idx] = minus1_transformer.transform(\n",
    "            spectra_data_v3['nirs'][s_idx][aug_idx]\n",
    "        )\n",
    "\n",
    "# For Raman source\n",
    "for s_idx in range(total_samples):\n",
    "    for aug_idx in range(len(spectra_data_v3['raman'][s_idx])):\n",
    "        spectra_data_v3['raman'][s_idx][aug_idx] = plus100_transformer.transform(\n",
    "            spectra_data_v3['raman'][s_idx][aug_idx]\n",
    "        )\n",
    "\n",
    "# --- Build SpectraSet with Source-Transformed Data ---\n",
    "ss_v3 = SpectraSet.build(\n",
    "    spectra=spectra_data_v3,\n",
    "    target=target_y_v1,\n",
    "    metadata=metadata_v1\n",
    ")\n",
    "\n",
    "# print(\"--- SpectraSet after Source-Specific Transformation (ss_v3) ---\")\n",
    "# print(ss_v3.ds)\n",
    "# print(f\"\\nShape of X from ss_v3: {ss_v3.X().shape}\") # Shape should be same as ss_v2\n",
    "\n",
    "# # Verify transformations for one sample\n",
    "# print(f\"\\nNIRS for sample 0, aug 0 (original was {spectra_data_v2['nirs'][0][0]}):\")\n",
    "# print(f\"  Transformed: {spectra_data_v3['nirs'][0][0]}\")\n",
    "# print(f\"Raman for sample 0, aug 0 (original was {spectra_data_v2['raman'][0][0]}):\")\n",
    "# print(f\"  Transformed: {spectra_data_v3['raman'][0][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb44d8",
   "metadata": {},
   "source": [
    "## 6. Feature Augmentation (Adding New Sources)\n",
    "\n",
    "We create new spectral sources by applying a transformation to existing ones.\n",
    "- For every sample and its existing augmentations (which are now source-transformed):\n",
    "    - Create `nirs_plus_01` by adding 0.1 to each NIRS spectrum.\n",
    "    - Create `raman_plus_01` by adding 0.1 to each Raman spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fa51ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SpectraSet after Feature Augmentation (ss_v4_pre_group_split) ---\n",
      "<xarray.Dataset> Size: 6kB\n",
      "Dimensions:                (obs: 26, feature_nirs: 4, feature_raman: 5,\n",
      "                            feature_nirs_plus_01: 4, feature_raman_plus_01: 5,\n",
      "                            variable: 1)\n",
      "Coordinates:\n",
      "  * obs                    (obs) int64 208B 0 1 2 3 4 5 6 ... 20 21 22 23 24 25\n",
      "  * feature_nirs           (feature_nirs) <U7 112B 'nirs_f0' ... 'nirs_f3'\n",
      "  * feature_raman          (feature_raman) <U8 160B 'raman_f0' ... 'raman_f4'\n",
      "  * feature_nirs_plus_01   (feature_nirs_plus_01) <U15 240B 'nirs_plus_01_f0'...\n",
      "  * feature_raman_plus_01  (feature_raman_plus_01) <U16 320B 'raman_plus_01_f...\n",
      "  * variable               (variable) int64 8B 0\n",
      "    sample                 (obs) int64 208B 0 0 1 1 2 2 3 3 ... 7 7 8 8 8 9 9 9\n",
      "    augmentation           (obs) int64 208B 0 1 0 1 0 1 0 1 ... 1 2 0 1 2 0 1 2\n",
      "Data variables:\n",
      "    spectra_nirs           (obs, feature_nirs) float64 832B -1.0 -1.0 ... 8.2\n",
      "    spectra_raman          (obs, feature_raman) float64 1kB 105.0 ... 114.2\n",
      "    spectra_nirs_plus_01   (obs, feature_nirs_plus_01) float64 832B -0.9 ... 8.3\n",
      "    spectra_raman_plus_01  (obs, feature_raman_plus_01) float64 1kB 105.1 ......\n",
      "    target                 (obs, variable) int64 208B 0 0 1 1 2 2 ... 8 8 9 9 9\n",
      "    metadata_n_numeric     (obs) int64 208B 0 0 1 1 2 2 3 3 ... 7 7 8 8 8 9 9 9\n",
      "    metadata_n_str         (obs) <U1 104B '0' '0' '1' '1' ... '8' '9' '9' '9'\n",
      "    metadata_n_sum_str     (obs) <U3 312B '0+0' '0+0' '1+1' ... '9+9' '9+9'\n",
      "\n",
      "Shape of X from ss_v4_pre_group_split: (26, 18)\n",
      "Sources in ss_v4_pre_group_split: ['spectra_nirs', 'spectra_raman', 'spectra_nirs_plus_01', 'spectra_raman_plus_01']\n",
      "\n",
      "NIRS for sample 0, aug 0: [-1. -1. -1. -1.]\n",
      "NIRS_plus_01 for sample 0, aug 0: [-0.9 -0.9 -0.9 -0.9]\n",
      "\n",
      "<xarray.Dataset> Size: 6kB\n",
      "Dimensions:                (obs: 26, feature_nirs: 4, feature_raman: 5,\n",
      "                            feature_nirs_plus_01: 4, feature_raman_plus_01: 5,\n",
      "                            variable: 1)\n",
      "Coordinates:\n",
      "  * obs                    (obs) int64 208B 0 1 2 3 4 5 6 ... 20 21 22 23 24 25\n",
      "  * feature_nirs           (feature_nirs) <U7 112B 'nirs_f0' ... 'nirs_f3'\n",
      "  * feature_raman          (feature_raman) <U8 160B 'raman_f0' ... 'raman_f4'\n",
      "  * feature_nirs_plus_01   (feature_nirs_plus_01) <U15 240B 'nirs_plus_01_f0'...\n",
      "  * feature_raman_plus_01  (feature_raman_plus_01) <U16 320B 'raman_plus_01_f...\n",
      "  * variable               (variable) int64 8B 0\n",
      "    sample                 (obs) int64 208B 0 0 1 1 2 2 3 3 ... 7 7 8 8 8 9 9 9\n",
      "    augmentation           (obs) int64 208B 0 1 0 1 0 1 0 1 ... 1 2 0 1 2 0 1 2\n",
      "Data variables:\n",
      "    spectra_nirs           (obs, feature_nirs) float64 832B -1.0 -1.0 ... 8.2\n",
      "    spectra_raman          (obs, feature_raman) float64 1kB 105.0 ... 114.2\n",
      "    spectra_nirs_plus_01   (obs, feature_nirs_plus_01) float64 832B -0.9 ... 8.3\n",
      "    spectra_raman_plus_01  (obs, feature_raman_plus_01) float64 1kB 105.1 ......\n",
      "    target                 (obs, variable) int64 208B 0 0 1 1 2 2 ... 8 8 9 9 9\n",
      "    metadata_n_numeric     (obs) int64 208B 0 0 1 1 2 2 3 3 ... 7 7 8 8 8 9 9 9\n",
      "    metadata_n_str         (obs) <U1 104B '0' '0' '1' '1' ... '8' '9' '9' '9'\n",
      "    metadata_n_sum_str     (obs) <U3 312B '0+0' '0+0' '1+1' ... '9+9' '9+9'\n",
      "\n",
      "Shape of X from ss_v4_pre_group_split: (26, 18)\n",
      "Sources in ss_v4_pre_group_split: ['spectra_nirs', 'spectra_raman', 'spectra_nirs_plus_01', 'spectra_raman_plus_01']\n",
      "\n",
      "NIRS for sample 0, aug 0: [-1. -1. -1. -1.]\n",
      "NIRS_plus_01 for sample 0, aug 0: [-0.9 -0.9 -0.9 -0.9]\n"
     ]
    }
   ],
   "source": [
    "# --- Define Feature Augmentation Transformer ---\n",
    "class AddConstantTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, constant_to_add):\n",
    "        self.constant_to_add = constant_to_add\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X_spectrum): return X_spectrum + self.constant_to_add\n",
    "\n",
    "add_point_one_transformer = AddConstantTransformer(0.1)\n",
    "\n",
    "# --- Deep copy source-transformed spectra data for feature augmentation ---\n",
    "spectra_data_v4 = {\n",
    "    src: [[np.copy(aug) for aug in augs_list] for augs_list in sample_augs_list]\n",
    "    for src, sample_augs_list in spectra_data_v3.items()\n",
    "}\n",
    "\n",
    "# --- Initialize new sources ---\n",
    "spectra_data_v4['nirs_plus_01'] = [[] for _ in range(total_samples)]\n",
    "spectra_data_v4['raman_plus_01'] = [[] for _ in range(total_samples)]\n",
    "\n",
    "# --- Apply Feature Augmentation ---\n",
    "for s_idx in range(total_samples):\n",
    "    # For nirs_plus_01\n",
    "    for aug_spectrum in spectra_data_v3['nirs'][s_idx]: # Iterate existing NIRS augs\n",
    "        spectra_data_v4['nirs_plus_01'][s_idx].append(\n",
    "            add_point_one_transformer.transform(aug_spectrum)\n",
    "        )\n",
    "    # For raman_plus_01\n",
    "    for aug_spectrum in spectra_data_v3['raman'][s_idx]: # Iterate existing Raman augs\n",
    "        spectra_data_v4['raman_plus_01'][s_idx].append(\n",
    "            add_point_one_transformer.transform(aug_spectrum)\n",
    "        )\n",
    "        \n",
    "# --- Build SpectraSet with Feature-Augmented Data ---\n",
    "# This will be our main SpectraSet for subsequent steps\n",
    "ss_v4_pre_group_split = SpectraSet.build(\n",
    "    spectra=spectra_data_v4,\n",
    "    target=target_y_v1,\n",
    "    metadata=metadata_v1\n",
    ")\n",
    "\n",
    "print(\"--- SpectraSet after Feature Augmentation (ss_v4_pre_group_split) ---\")\n",
    "print(ss_v4_pre_group_split.ds)\n",
    "# X shape should be (24, 9+9) = (24, 18) if concatenated (nirs, raman, nirs_plus_01, raman_plus_01)\n",
    "# NIRS (4) + Raman (5) + NIRS_plus_01 (4) + Raman_plus_01 (5) = 18 features\n",
    "print(f\"\\nShape of X from ss_v4_pre_group_split: {ss_v4_pre_group_split.X().shape}\")\n",
    "print(f\"Sources in ss_v4_pre_group_split: {[k for k in ss_v4_pre_group_split.ds.data_vars if k.startswith('spectra_')]}\")\n",
    "\n",
    "# Verify new source for one sample\n",
    "print(f\"\\nNIRS for sample 0, aug 0: {spectra_data_v4['nirs'][0][0]}\")\n",
    "print(f\"NIRS_plus_01 for sample 0, aug 0: {spectra_data_v4['nirs_plus_01'][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa9720",
   "metadata": {},
   "source": [
    "## 7. Grouping Samples\n",
    "\n",
    "We group samples based on whether the first value of their *original* NIRS spectrum is odd or even.\n",
    "The original NIRS spectra are taken from `spectra_data_v1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "508363e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SpectraSet with Custom Groups (ss_v5_with_groups) ---\n",
      "<xarray.Dataset> Size: 8kB\n",
      "Dimensions:                     (obs: 26, feature_nirs: 4, feature_raman: 5,\n",
      "                                 feature_nirs_plus_01: 4,\n",
      "                                 feature_raman_plus_01: 5, variable: 1)\n",
      "Coordinates:\n",
      "  * obs                         (obs) int64 208B 0 1 2 3 4 5 ... 21 22 23 24 25\n",
      "  * feature_nirs                (feature_nirs) <U7 112B 'nirs_f0' ... 'nirs_f3'\n",
      "  * feature_raman               (feature_raman) <U8 160B 'raman_f0' ... 'rama...\n",
      "  * feature_nirs_plus_01        (feature_nirs_plus_01) <U15 240B 'nirs_plus_0...\n",
      "  * feature_raman_plus_01       (feature_raman_plus_01) <U16 320B 'raman_plus...\n",
      "  * variable                    (variable) int64 8B 0\n",
      "    sample                      (obs) int64 208B 0 0 1 1 2 2 3 ... 7 8 8 8 9 9 9\n",
      "    augmentation                (obs) int64 208B 0 1 0 1 0 1 0 ... 2 0 1 2 0 1 2\n",
      "    group_id_nirs_parity_group  (obs) <U15 2kB 'even_first_nirs' ... 'odd_fir...\n",
      "Data variables:\n",
      "    spectra_nirs                (obs, feature_nirs) float64 832B -1.0 ... 8.2\n",
      "    spectra_raman               (obs, feature_raman) float64 1kB 105.0 ... 114.2\n",
      "    spectra_nirs_plus_01        (obs, feature_nirs_plus_01) float64 832B -0.9...\n",
      "    spectra_raman_plus_01       (obs, feature_raman_plus_01) float64 1kB 105....\n",
      "    target                      (obs, variable) int64 208B 0 0 1 1 2 ... 8 9 9 9\n",
      "    metadata_n_numeric          (obs) int64 208B 0 0 1 1 2 2 3 ... 7 8 8 8 9 9 9\n",
      "    metadata_n_str              (obs) <U1 104B '0' '0' '1' '1' ... '9' '9' '9'\n",
      "    metadata_n_sum_str          (obs) <U3 312B '0+0' '0+0' '1+1' ... '9+9' '9+9'\n",
      "\n",
      "Shape of X from ss_v5_with_groups: (26, 18)\n",
      "\n",
      "Group labels per sample (first 10): ['even_first_nirs' 'odd_first_nirs']\n",
      "\n",
      "Value counts for 'nirs_parity_group' (per observation):\n",
      "even_first_nirs    13\n",
      "odd_first_nirs     13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'nirs_parity_group' (per original sample):\n",
      "even_first_nirs    5\n",
      "odd_first_nirs     5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Adjusting Grouping Logic for Better Distribution ---\n",
      "--- SpectraSet with Adjusted Custom Groups (ss_final_with_groups) ---\n",
      "<xarray.Dataset> Size: 7kB\n",
      "Dimensions:                         (obs: 26, feature_nirs: 4,\n",
      "                                     feature_raman: 5, feature_nirs_plus_01: 4,\n",
      "                                     feature_raman_plus_01: 5, variable: 1)\n",
      "Coordinates:\n",
      "  * obs                             (obs) int64 208B 0 1 2 3 4 ... 22 23 24 25\n",
      "  * feature_nirs                    (feature_nirs) <U7 112B 'nirs_f0' ... 'ni...\n",
      "  * feature_raman                   (feature_raman) <U8 160B 'raman_f0' ... '...\n",
      "  * feature_nirs_plus_01            (feature_nirs_plus_01) <U15 240B 'nirs_pl...\n",
      "  * feature_raman_plus_01           (feature_raman_plus_01) <U16 320B 'raman_...\n",
      "  * variable                        (variable) int64 8B 0\n",
      "    sample                          (obs) int64 208B 0 0 1 1 2 2 ... 8 8 8 9 9 9\n",
      "    augmentation                    (obs) int64 208B 0 1 0 1 0 1 ... 0 1 2 0 1 2\n",
      "    group_id_nirs_sum_parity_group  (obs) <U13 1kB 'even_sum_nirs' ... 'even_...\n",
      "Data variables:\n",
      "    spectra_nirs                    (obs, feature_nirs) float64 832B -1.0 ......\n",
      "    spectra_raman                   (obs, feature_raman) float64 1kB 105.0 .....\n",
      "    spectra_nirs_plus_01            (obs, feature_nirs_plus_01) float64 832B ...\n",
      "    spectra_raman_plus_01           (obs, feature_raman_plus_01) float64 1kB ...\n",
      "    target                          (obs, variable) int64 208B 0 0 1 1 ... 9 9 9\n",
      "    metadata_n_numeric              (obs) int64 208B 0 0 1 1 2 2 ... 8 8 8 9 9 9\n",
      "    metadata_n_str                  (obs) <U1 104B '0' '0' '1' ... '9' '9' '9'\n",
      "    metadata_n_sum_str              (obs) <U3 312B '0+0' '0+0' ... '9+9' '9+9'\n",
      "\n",
      "Value counts for 'nirs_sum_parity_group' (per original sample):\n",
      "even_sum_nirs    10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Final Grouping Logic: n % 2 ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_values_for_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 77\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# n=1, NIRS=[0,0,0,0], sum=0 (even)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# n=2, NIRS=[0,1,2,3], sum=6 (even)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# n=3, NIRS=[0,2,4,6], sum=12 (even)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Still all even. The data generation is very regular.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Let's group by n % 2 for simplicity to get a split.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Final Grouping Logic: n \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m 2 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m group_labels_n_parity \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_odd\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_values_for_samples[s_idx] \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_even\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_samples)]\n\u001b[0;32m     78\u001b[0m group_labels_n_parity_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(group_labels_n_parity)\n\u001b[0;32m     79\u001b[0m final_custom_groups \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_parity_group\u001b[39m\u001b[38;5;124m'\u001b[39m: group_labels_n_parity_np}\n",
      "Cell \u001b[1;32mIn[7], line 77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# n=1, NIRS=[0,0,0,0], sum=0 (even)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# n=2, NIRS=[0,1,2,3], sum=6 (even)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# n=3, NIRS=[0,2,4,6], sum=12 (even)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Still all even. The data generation is very regular.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Let's group by n % 2 for simplicity to get a split.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Final Grouping Logic: n \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m 2 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m group_labels_n_parity \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_odd\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mn_values_for_samples\u001b[49m[s_idx] \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_even\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_samples)]\n\u001b[0;32m     78\u001b[0m group_labels_n_parity_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(group_labels_n_parity)\n\u001b[0;32m     79\u001b[0m final_custom_groups \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_parity_group\u001b[39m\u001b[38;5;124m'\u001b[39m: group_labels_n_parity_np}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_values_for_samples' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Define Groups ---\n",
    "group_labels_per_sample = []\n",
    "for s_idx in range(total_samples):\n",
    "    # Access the first value of the original NIRS spectrum for the sample\n",
    "    # spectra_data_v1['nirs'][s_idx] is a list containing one np.array (the original aug)\n",
    "    original_nirs_spectrum = spectra_data_v1['nirs'][s_idx][0]\n",
    "    first_nirs_value = original_nirs_spectrum[0]\n",
    "    \n",
    "    if first_nirs_value % 2 != 0: # Check if odd\n",
    "        group_labels_per_sample.append('odd_first_nirs')\n",
    "    else:\n",
    "        group_labels_per_sample.append('even_first_nirs')\n",
    "\n",
    "group_labels_np = np.array(group_labels_per_sample)\n",
    "custom_groups = {'nirs_parity_group': group_labels_np}\n",
    "\n",
    "# --- Rebuild SpectraSet with Groups ---\n",
    "# Using spectra_data_v4 (which has all spectral transformations and augmentations)\n",
    "ss_v5_with_groups = SpectraSet.build(\n",
    "    spectra=spectra_data_v4,\n",
    "    target=target_y_v1,\n",
    "    metadata=metadata_v1,\n",
    "    groups=custom_groups\n",
    ")\n",
    "\n",
    "print(\"--- SpectraSet with Custom Groups (ss_v5_with_groups) ---\")\n",
    "print(ss_v5_with_groups.ds)\n",
    "print(f\"\\nShape of X from ss_v5_with_groups: {ss_v5_with_groups.X().shape}\") # Shape should be same as ss_v4\n",
    "print(f\"\\nGroup labels per sample (first {total_samples}): {np.unique(group_labels_np)[:total_samples]}\")\n",
    "print(f\"\\nValue counts for 'nirs_parity_group' (per observation):\")\n",
    "print(pd.Series(ss_v5_with_groups.ds['group_id_nirs_parity_group'].values).value_counts())\n",
    "# To see counts per original sample:\n",
    "print(f\"\\nValue counts for 'nirs_parity_group' (per original sample):\")\n",
    "print(pd.Series(group_labels_np).value_counts())\n",
    "\n",
    "# Example: n=1 (s_idx=0,1), NIRS starts with 0 (even)\n",
    "# n=2 (s_idx=2,3), NIRS starts with 0 (even) for (2-1)*0\n",
    "# n=3 (s_idx=4,5), NIRS starts with 0 (even) for (3-1)*0\n",
    "# n=4 (s_idx=6,7), NIRS starts with 0 (even) for (4-1)*0\n",
    "# n=5 (s_idx=8,9), NIRS starts with 0 (even) for (5-1)*0\n",
    "# It seems all will be 'even_first_nirs' with current (n-1)*i logic. Let's check.\n",
    "# (n-1)*0 is always 0. So all are 'even'.\n",
    "# Let's adjust the grouping logic to be more interesting, e.g. based on `current_n` itself.\n",
    "# Or, let's use the sum of the first NIRS spectrum.\n",
    "\n",
    "print(\"\\n--- Adjusting Grouping Logic for Better Distribution ---\")\n",
    "group_labels_per_sample_adj = []\n",
    "for s_idx in range(total_samples):\n",
    "    original_nirs_spectrum = spectra_data_v1['nirs'][s_idx][0]\n",
    "    sum_of_nirs_values = np.sum(original_nirs_spectrum)\n",
    "    if sum_of_nirs_values % 2 != 0: # Check if sum is odd\n",
    "        group_labels_per_sample_adj.append('odd_sum_nirs')\n",
    "    else:\n",
    "        group_labels_per_sample_adj.append('even_sum_nirs')\n",
    "\n",
    "group_labels_adj_np = np.array(group_labels_per_sample_adj)\n",
    "custom_groups_adj = {'nirs_sum_parity_group': group_labels_adj_np}\n",
    "\n",
    "ss_final_with_groups = SpectraSet.build(\n",
    "    spectra=spectra_data_v4,\n",
    "    target=target_y_v1,\n",
    "    metadata=metadata_v1,\n",
    "    groups=custom_groups_adj # Use adjusted groups\n",
    ")\n",
    "print(\"--- SpectraSet with Adjusted Custom Groups (ss_final_with_groups) ---\")\n",
    "print(ss_final_with_groups.ds)\n",
    "print(f\"\\nValue counts for 'nirs_sum_parity_group' (per original sample):\")\n",
    "print(pd.Series(group_labels_adj_np).value_counts())\n",
    "# n=1, NIRS=[0,0,0,0], sum=0 (even)\n",
    "# n=2, NIRS=[0,1,2,3], sum=6 (even)\n",
    "# n=3, NIRS=[0,2,4,6], sum=12 (even)\n",
    "# n=4, NIRS=[0,3,6,9], sum=18 (even)\n",
    "# n=5, NIRS=[0,4,8,12], sum=24 (even)\n",
    "# Still all even. The data generation is very regular.\n",
    "# Let's group by n % 2 for simplicity to get a split.\n",
    "print(\"\\n--- Final Grouping Logic: n % 2 ---\")\n",
    "group_labels_n_parity = ['n_odd' if n_values_for_samples[s_idx] % 2 != 0 else 'n_even' for s_idx in range(total_samples)]\n",
    "group_labels_n_parity_np = np.array(group_labels_n_parity)\n",
    "final_custom_groups = {'n_parity_group': group_labels_n_parity_np}\n",
    "\n",
    "ss_final_grouped = SpectraSet.build(\n",
    "    spectra=spectra_data_v4,\n",
    "    target=target_y_v1,\n",
    "    metadata=metadata_v1,\n",
    "    groups=final_custom_groups\n",
    ")\n",
    "print(\"--- SpectraSet with Final Custom Groups (ss_final_grouped) ---\")\n",
    "print(ss_final_grouped.ds)\n",
    "print(f\"\\nValue counts for 'n_parity_group' (per original sample):\")\n",
    "print(pd.Series(group_labels_n_parity_np).value_counts())\n",
    "# n=1 (odd), n=2 (even), n=3 (odd), n=4 (even), n=5 (odd)\n",
    "# Each n appears twice. So 6 'n_odd' samples, 4 'n_even' samples. This is good for stratification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6aafb4",
   "metadata": {},
   "source": [
    "## 8. Train/Test Split\n",
    "\n",
    "We split the data into training (80%) and testing (20%) sets.\n",
    "The split is stratified based on the `n_parity_group` to ensure proportional representation of each group in both sets.\n",
    "The split is performed on the original sample indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47cad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SpectraSet with Train/Test Splits (ss_final_split) ---\n",
      "<xarray.Dataset> Size: 6kB\n",
      "Dimensions:                  (obs: 24, feature: 5, variable: 1)\n",
      "Coordinates:\n",
      "  * obs                      (obs) object 192B MultiIndex\n",
      "  * sample                   (obs) int64 192B 0 0 1 1 2 2 3 3 ... 7 8 8 8 9 9 9\n",
      "  * augmentation             (obs) int64 192B 0 1 0 1 0 1 0 1 ... 2 0 1 2 0 1 2\n",
      "  * feature                  (feature) int64 40B 0 1 2 3 4\n",
      "  * variable                 (variable) int64 8B 0\n",
      "    split                    (obs) <U5 480B 'train' 'train' ... 'train' 'train'\n",
      "    group_id_n_parity_group  (obs) <U6 576B 'n_odd' 'n_odd' ... 'n_odd' 'n_odd'\n",
      "Data variables:\n",
      "    spectra_nirs             (obs, feature) float64 960B -1.0 -1.0 ... 13.0 nan\n",
      "    spectra_raman            (obs, feature) float64 960B 105.0 105.0 ... 123.0\n",
      "    spectra_nirs_plus_01     (obs, feature) float64 960B -0.9 -0.9 ... 13.1 nan\n",
      "    spectra_raman_plus_01    (obs, feature) float64 960B 105.1 105.1 ... 123.1\n",
      "    target                   (obs, variable) int64 192B 1 1 1 1 2 ... 5 5 5 5 5\n",
      "    metadata_n_numeric       (obs) int64 192B 1 1 1 1 2 2 2 2 ... 4 5 5 5 5 5 5\n",
      "    metadata_n_str           (obs) <U1 96B '1' '1' '1' '1' ... '5' '5' '5' '5'\n",
      "    metadata_n_sum_str       (obs) <U3 288B '1+1' '1+1' '1+1' ... '5+5' '5+5'\n",
      "\n",
      "Shape of X_train: (19, 20), y_train: (19, 1)\n",
      "Shape of X_test: (5, 20), y_test: (5, 1)\n",
      "\n",
      "Original sample group counts: n_odd     6\n",
      "n_even    4\n",
      "Name: count, dtype: int64\n",
      "Train sample group counts: n_odd     5\n",
      "n_even    3\n",
      "Name: count, dtype: int64\n",
      "Test sample group counts: n_even    1\n",
      "n_odd     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Perform Train/Test Split on Sample Indices ---\n",
    "# We need unique sample indices and their corresponding group labels for stratification\n",
    "sample_indices = np.arange(total_samples) # 0 to 9 for our 10 original samples\n",
    "\n",
    "# Stratify based on group_labels_n_parity_np (one label per original sample)\n",
    "train_sample_idx, test_sample_idx = train_test_split(\n",
    "    sample_indices,\n",
    "    test_size=0.2, # 20% for test\n",
    "    stratify=group_labels_n_parity_np, # Stratify by the group labels of original samples\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Create splits array for SpectraSet ---\n",
    "# This array indicates 'train' or 'test' for each original sample\n",
    "splits_array = np.full(total_samples, 'train', dtype=object)\n",
    "splits_array[test_sample_idx] = 'test'\n",
    "\n",
    "# --- Rebuild SpectraSet with Splits Information ---\n",
    "ss_final_split = SpectraSet.build(\n",
    "    spectra=spectra_data_v4, # Use the fully processed spectra\n",
    "    target=target_y_v1,\n",
    "    metadata=metadata_v1,\n",
    "    groups=final_custom_groups, # Keep the groups\n",
    "    splits=splits_array        # Add the split information\n",
    ")\n",
    "\n",
    "print(\"--- SpectraSet with Train/Test Splits (ss_final_split) ---\")\n",
    "print(ss_final_split.ds)\n",
    "\n",
    "# --- Extract Train and Test Data using SpectraSet methods ---\n",
    "X_train = ss_final_split.X(split='train')\n",
    "y_train = ss_final_split.y(split='train')\n",
    "X_test = ss_final_split.X(split='test')\n",
    "y_test = ss_final_split.y(split='test')\n",
    "\n",
    "print(f\"\\nShape of X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# Verify stratification (counts of groups in train/test based on original samples)\n",
    "print(f\"\\nOriginal sample group counts: {pd.Series(group_labels_n_parity_np).value_counts()}\")\n",
    "print(f\"Train sample group counts: {pd.Series(group_labels_n_parity_np[train_sample_idx]).value_counts()}\")\n",
    "print(f\"Test sample group counts: {pd.Series(group_labels_n_parity_np[test_sample_idx]).value_counts()}\")\n",
    "# Test set should have 2 samples (20% of 10).\n",
    "# If n_odd=6, n_even=4:\n",
    "# Test (2 samples): 20% of 6 n_odd is ~1.2 (so 1 or 2), 20% of 4 n_even is ~0.8 (so 0 or 1).\n",
    "# train_test_split will try its best. For small N, it might not be perfect but aims for proportion.\n",
    "# With 2 test samples: if 1 n_odd, 1 n_even, that's good.\n",
    "# Test sample indices: {test_sample_idx}, their groups: {group_labels_n_parity_np[test_sample_idx]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d27423",
   "metadata": {},
   "source": [
    "## 9. Repeated K-Fold Cross-Validation\n",
    "\n",
    "We apply `RepeatedKFold` to the 80% training data.\n",
    "- `n_splits=5`, `n_repeats=2`.\n",
    "- The folding is done on the *sample indices* of the training set.\n",
    "- The prompt mentioned \"excluding only a fold from one random group\". Standard `RepeatedKFold` operates on the provided samples. If group-specific exclusion per fold is needed, a more custom loop would be required. Here, we perform standard `RepeatedKFold` on the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55b9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique samples in training set: 8\n",
      "Unique sample IDs in training set: [0 1 2 3 5 7 8 9]\n",
      "\n",
      "--- Iterating through RepeatedKFold Splits ---\n",
      "Fold 1:\n",
      "  Train samples in fold (IDs): [0 2 3 5 8 9]\n",
      "  Validation samples in fold (IDs): [1 7]\n",
      "  X_train_fold shape: (14, 20), y_train_fold shape: (14, 1)\n",
      "  X_val_fold shape: (5, 20), y_val_fold shape: (5, 1)\n",
      "  Example y_val_fold (first 5): [1 1 4 4 4]\n",
      "Fold 2:\n",
      "  Train samples in fold (IDs): [1 2 3 5 7 8]\n",
      "  Validation samples in fold (IDs): [0 9]\n",
      "  X_train_fold shape: (14, 20), y_train_fold shape: (14, 1)\n",
      "  X_val_fold shape: (5, 20), y_val_fold shape: (5, 1)\n",
      "Fold 3:\n",
      "  Train samples in fold (IDs): [0 1 3 7 8 9]\n",
      "  Validation samples in fold (IDs): [2 5]\n",
      "  X_train_fold shape: (15, 20), y_train_fold shape: (15, 1)\n",
      "  X_val_fold shape: (4, 20), y_val_fold shape: (4, 1)\n",
      "Fold 4:\n",
      "  Train samples in fold (IDs): [0 1 2 5 7 8 9]\n",
      "  Validation samples in fold (IDs): [3]\n",
      "  X_train_fold shape: (17, 20), y_train_fold shape: (17, 1)\n",
      "  X_val_fold shape: (2, 20), y_val_fold shape: (2, 1)\n",
      "Fold 5:\n",
      "  Train samples in fold (IDs): [0 1 2 3 5 7 9]\n",
      "  Validation samples in fold (IDs): [8]\n",
      "  X_train_fold shape: (16, 20), y_train_fold shape: (16, 1)\n",
      "  X_val_fold shape: (3, 20), y_val_fold shape: (3, 1)\n",
      "Fold 6:\n",
      "  Train samples in fold (IDs): [0 1 2 5 7 8]\n",
      "  Validation samples in fold (IDs): [3 9]\n",
      "  X_train_fold shape: (14, 20), y_train_fold shape: (14, 1)\n",
      "  X_val_fold shape: (5, 20), y_val_fold shape: (5, 1)\n",
      "Fold 7:\n",
      "  Train samples in fold (IDs): [1 2 3 7 8 9]\n",
      "  Validation samples in fold (IDs): [0 5]\n",
      "  X_train_fold shape: (15, 20), y_train_fold shape: (15, 1)\n",
      "  X_val_fold shape: (4, 20), y_val_fold shape: (4, 1)\n",
      "Fold 8:\n",
      "  Train samples in fold (IDs): [0 1 3 5 8 9]\n",
      "  Validation samples in fold (IDs): [2 7]\n",
      "  X_train_fold shape: (14, 20), y_train_fold shape: (14, 1)\n",
      "  X_val_fold shape: (5, 20), y_val_fold shape: (5, 1)\n",
      "Fold 9:\n",
      "  Train samples in fold (IDs): [0 2 3 5 7 8 9]\n",
      "  Validation samples in fold (IDs): [1]\n",
      "  X_train_fold shape: (17, 20), y_train_fold shape: (17, 1)\n",
      "  X_val_fold shape: (2, 20), y_val_fold shape: (2, 1)\n",
      "Fold 10:\n",
      "  Train samples in fold (IDs): [0 1 2 3 5 7 9]\n",
      "  Validation samples in fold (IDs): [8]\n",
      "  X_train_fold shape: (16, 20), y_train_fold shape: (16, 1)\n",
      "  X_val_fold shape: (3, 20), y_val_fold shape: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Setup RepeatedKFold ---\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "# We need to apply KFold to the *samples* within the training set.\n",
    "# `train_sample_idx` contains the original indices (0-9) of the samples in the training set.\n",
    "# Let's get a SpectraSet view of only the training data samples.\n",
    "ss_train_samples_only = ss_final_split.subset_by_samples(train_sample_idx)\n",
    "\n",
    "# The KFold split will be on the *unique sample IDs present in ss_train_samples_only*.\n",
    "# These are not necessarily contiguous from 0 to len(train_sample_idx)-1 if we directly use train_sample_idx.\n",
    "# Instead, we split based on the number of unique samples in the training set.\n",
    "unique_train_sample_ids_in_ss = ss_train_samples_only.ds.sample.to_series().unique()\n",
    "# unique_train_sample_ids_in_ss contains the actual sample IDs (from 0-9 range) that are in training.\n",
    "\n",
    "print(f\"Number of unique samples in training set: {len(unique_train_sample_ids_in_ss)}\")\n",
    "print(f\"Unique sample IDs in training set: {unique_train_sample_ids_in_ss}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Iterating through RepeatedKFold Splits ---\")\n",
    "for fold_num, (train_fold_indices, val_fold_indices) in enumerate(rkf.split(unique_train_sample_ids_in_ss)):\n",
    "    # train_fold_indices and val_fold_indices are indices *within* unique_train_sample_ids_in_ss\n",
    "    \n",
    "    # Get the actual sample IDs for this fold's train and validation sets\n",
    "    current_fold_train_sample_ids = unique_train_sample_ids_in_ss[train_fold_indices]\n",
    "    current_fold_val_sample_ids = unique_train_sample_ids_in_ss[val_fold_indices]\n",
    "    \n",
    "    # Get SpectraSet views for this specific fold's train and validation samples\n",
    "    ss_fold_train = ss_train_samples_only.subset_by_samples(current_fold_train_sample_ids)\n",
    "    ss_fold_val = ss_train_samples_only.subset_by_samples(current_fold_val_sample_ids)\n",
    "    \n",
    "    # Extract X and y for this fold\n",
    "    X_fold_tr = ss_fold_train.X()\n",
    "    y_fold_tr = ss_fold_train.y()\n",
    "    X_fold_val = ss_fold_val.X()\n",
    "    y_fold_val = ss_fold_val.y()\n",
    "    \n",
    "    print(f\"Fold {fold_num + 1}:\")\n",
    "    print(f\"  Train samples in fold (IDs): {current_fold_train_sample_ids}\")\n",
    "    print(f\"  Validation samples in fold (IDs): {current_fold_val_sample_ids}\")\n",
    "    print(f\"  X_train_fold shape: {X_fold_tr.shape}, y_train_fold shape: {y_fold_tr.shape}\")\n",
    "    print(f\"  X_val_fold shape: {X_fold_val.shape}, y_val_fold shape: {y_fold_val.shape}\")\n",
    "    if fold_num == 0: # Print details for the first fold\n",
    "        print(f\"  Example y_val_fold (first 5): {y_fold_val[:5].ravel()}\")\n",
    "\n",
    "# Note: With n_splits=5 and 8 training samples, some validation sets might be small (1-2 samples).\n",
    "# This means X_val/y_val shapes will reflect observations from those 1-2 samples.\n",
    "# E.g., if a val sample has 2 augs, its y_val will have 2 identical target values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f82991",
   "metadata": {},
   "source": [
    "## 10. Unpacking Groups\n",
    "\n",
    "Finally, we iterate through the defined groups (`n_parity_group`) in the full dataset (before train/test split, but with all transformations and augmentations - `ss_final_grouped`) and display the shape of `X` and `y` for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594d911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Shapes per Group (from ss_final_grouped) ---\n",
      "\n",
      "Group: 'n_even'\n",
      "  Shape of X for this group: (10, 20)\n",
      "  Shape of y for this group: (10, 1)\n",
      "  Unique 'n' values (target y) in this group: [2 4]\n",
      "    All target 'n' values are even: True\n",
      "\n",
      "Group: 'n_odd'\n",
      "  Shape of X for this group: (14, 20)\n",
      "  Shape of y for this group: (14, 1)\n",
      "  Unique 'n' values (target y) in this group: [1 3 5]\n",
      "    All target 'n' values are odd: True\n"
     ]
    }
   ],
   "source": [
    "# --- Unpack and Inspect Data by Group ---\n",
    "# Using ss_final_grouped, which contains all samples and their group assignments.\n",
    "unique_group_values = np.unique(ss_final_grouped.ds['group_id_n_parity_group'].values)\n",
    "\n",
    "print(f\"--- Data Shapes per Group (from ss_final_grouped) ---\")\n",
    "for group_val in unique_group_values:\n",
    "    # Filter SpectraSet by the current group value\n",
    "    # The groups argument in X() and y() filters observations.\n",
    "    X_group = ss_final_grouped.X(groups={'n_parity_group': group_val})\n",
    "    y_group = ss_final_grouped.y(groups={'n_parity_group': group_val})\n",
    "    \n",
    "    print(f\"\\nGroup: '{group_val}'\")\n",
    "    print(f\"  Shape of X for this group: {X_group.shape}\")\n",
    "    print(f\"  Shape of y for this group: {y_group.shape}\")\n",
    "    # Verify target values in this group (should be consistent with n_parity)\n",
    "    unique_n_in_group_y = np.unique(y_group.ravel())\n",
    "    print(f\"  Unique 'n' values (target y) in this group: {unique_n_in_group_y}\")\n",
    "    if group_val == 'n_odd':\n",
    "        all_odd = all(n % 2 != 0 for n in unique_n_in_group_y)\n",
    "        print(f\"    All target 'n' values are odd: {all_odd}\")\n",
    "    elif group_val == 'n_even':\n",
    "        all_even = all(n % 2 == 0 for n in unique_n_in_group_y)\n",
    "        print(f\"    All target 'n' values are even: {all_even}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0dca2",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "This notebook demonstrated a comprehensive workflow using `SpectraSet`, covering data generation, various types of augmentations and transformations, grouping, splitting, and cross-validation preparation. Each step involved careful manipulation of the spectral data and rebuilding or querying the `SpectraSet` object to reflect the changes, while displaying shapes to track the data transformations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
