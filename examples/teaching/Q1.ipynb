{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f89073",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f7d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded pipeline(s) with 2 configuration(s).\n",
      "========================================================================================================================================================================================================\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_68891f28 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 64 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 1_0_MinMaxScaler_1.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': ['nirs4all.operators.transformations.nirs.Haar', ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'nirs4all.operators.transformations.nirs.Haar'], ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Gaussian']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "💾 Saved file: 2_1_0_Haar_2.pkl\n",
      "\u001b[96m   ▶ Sub-step 2.2: ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'nirs4all.operators.transformations.nirs.Haar']\u001b[0m\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.3: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "\u001b[96m   ▶ Sub-step 2.4: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Gaussian']\u001b[0m\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved file: 3_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 4_MinMaxScaler_numeric_MinMaxScaler3.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}, '_runtime_instance': PLSRegression(n_components=1)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 6: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', '_runtime_instance': PLSRegression()}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 7: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 3}, '_runtime_instance': PLSRegression(n_components=3)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 8: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 4}, '_runtime_instance': PLSRegression(n_components=4)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 9: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 5}, '_runtime_instance': PLSRegression(n_components=5)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 10: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 6}, '_runtime_instance': PLSRegression(n_components=6)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 11: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 7}, '_runtime_instance': PLSRegression(n_components=7)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 12: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 8}, '_runtime_instance': PLSRegression(n_components=8)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 13: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 9}, '_runtime_instance': PLSRegression(n_components=9)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 14: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 15: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 11}, '_runtime_instance': PLSRegression(n_components=11)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 16: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 12}, '_runtime_instance': PLSRegression(n_components=12)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 17: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 13}, '_runtime_instance': PLSRegression(n_components=13)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 18: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 14}, '_runtime_instance': PLSRegression(n_components=14)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 19: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 15}, '_runtime_instance': PLSRegression(n_components=15)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 20: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 16}, '_runtime_instance': PLSRegression(n_components=16)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 21: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 17}, '_runtime_instance': PLSRegression(n_components=17)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 22: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 18}, '_runtime_instance': PLSRegression(n_components=18)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 23: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 19}, '_runtime_instance': PLSRegression(n_components=19)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 24: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 20}, '_runtime_instance': PLSRegression(n_components=20)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 25: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 21}, '_runtime_instance': PLSRegression(n_components=21)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 26: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 22}, '_runtime_instance': PLSRegression(n_components=22)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 27: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 23}, '_runtime_instance': PLSRegression(n_components=23)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 28: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 24}, '_runtime_instance': PLSRegression(n_components=24)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 29: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 25}, '_runtime_instance': PLSRegression(n_components=25)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 30: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 26}, '_runtime_instance': PLSRegression(n_components=26)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 31: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 27}, '_runtime_instance': PLSRegression(n_components=27)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 32: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 28}, '_runtime_instance': PLSRegression(n_components=28)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 33: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 29}, '_runtime_instance': PLSRegression(n_components=29)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 34: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 30}, '_runtime_instance': PLSRegression(n_components=30)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 35: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 31}, '_runtime_instance': PLSRegression(n_components=31)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 36: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 32}, '_runtime_instance': PLSRegression(n_components=32)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 37: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 33}, '_runtime_instance': PLSRegression(n_components=33)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 38: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 34}, '_runtime_instance': PLSRegression(n_components=34)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 39: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 35}, '_runtime_instance': PLSRegression(n_components=35)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 40: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 36}, '_runtime_instance': PLSRegression(n_components=36)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 41: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 37}, '_runtime_instance': PLSRegression(n_components=37)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 42: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 38}, '_runtime_instance': PLSRegression(n_components=38)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 43: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 39}, '_runtime_instance': PLSRegression(n_components=39)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 44: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 40}, '_runtime_instance': PLSRegression(n_components=40)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 45: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 41}, '_runtime_instance': PLSRegression(n_components=41)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 46: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 42}, '_runtime_instance': PLSRegression(n_components=42)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 47: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 43}, '_runtime_instance': PLSRegression(n_components=43)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 48: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 44}, '_runtime_instance': PLSRegression(n_components=44)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 49: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 45}, '_runtime_instance': PLSRegression(n_components=45)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 50: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 46}, '_runtime_instance': PLSRegression(n_components=46)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 51: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 47}, '_runtime_instance': PLSRegression(n_components=47)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 52: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 48}, '_runtime_instance': PLSRegression(n_components=48)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 53: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 49}, '_runtime_instance': PLSRegression(n_components=49)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 54: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 50}, '_runtime_instance': PLSRegression(n_components=50)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 55: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 51}, '_runtime_instance': PLSRegression(n_components=51)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 56: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 52}, '_runtime_instance': PLSRegression(n_components=52)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 57: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 53}, '_runtime_instance': PLSRegression(n_components=53)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 58: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 54}, '_runtime_instance': PLSRegression(n_components=54)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 59: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 55}, '_runtime_instance': PLSRegression(n_components=55)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 60: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 56}, '_runtime_instance': PLSRegression(n_components=56)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 61: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 57}, '_runtime_instance': PLSRegression(n_components=57)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 62: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 58}, '_runtime_instance': PLSRegression(n_components=58)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 63: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 59}, '_runtime_instance': PLSRegression(n_components=59)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 64: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 60}, '_runtime_instance': PLSRegression(n_components=60)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_68891f28 completed successfully on dataset regression\u001b[0m\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_563e869e on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 64 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 1_0_MinMaxScaler_1.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': ['nirs4all.operators.transformations.nirs.SavitzkyGolay', ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'sklearn.preprocessing._data.StandardScaler'], ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'nirs4all.operators.transformations.nirs.Haar']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "💾 Saved file: 2_1_0_SavitzkyGolay_2.pkl\n",
      "\u001b[96m   ▶ Sub-step 2.2: ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.3: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "\u001b[96m   ▶ Sub-step 2.4: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'nirs4all.operators.transformations.nirs.Haar']\u001b[0m\n",
      "\u001b[94m🔄 Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "💾 Saved file: 3_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 4_MinMaxScaler_numeric_MinMaxScaler3.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}, '_runtime_instance': PLSRegression(n_components=1)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 6: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', '_runtime_instance': PLSRegression()}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 7: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 3}, '_runtime_instance': PLSRegression(n_components=3)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 8: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 4}, '_runtime_instance': PLSRegression(n_components=4)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 9: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 5}, '_runtime_instance': PLSRegression(n_components=5)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 10: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 6}, '_runtime_instance': PLSRegression(n_components=6)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 11: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 7}, '_runtime_instance': PLSRegression(n_components=7)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 12: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 8}, '_runtime_instance': PLSRegression(n_components=8)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 13: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 9}, '_runtime_instance': PLSRegression(n_components=9)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 14: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 15: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 11}, '_runtime_instance': PLSRegression(n_components=11)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 16: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 12}, '_runtime_instance': PLSRegression(n_components=12)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 17: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 13}, '_runtime_instance': PLSRegression(n_components=13)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 18: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 14}, '_runtime_instance': PLSRegression(n_components=14)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 19: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 15}, '_runtime_instance': PLSRegression(n_components=15)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 20: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 16}, '_runtime_instance': PLSRegression(n_components=16)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 21: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 17}, '_runtime_instance': PLSRegression(n_components=17)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 22: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 18}, '_runtime_instance': PLSRegression(n_components=18)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 23: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 19}, '_runtime_instance': PLSRegression(n_components=19)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 24: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 20}, '_runtime_instance': PLSRegression(n_components=20)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 25: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 21}, '_runtime_instance': PLSRegression(n_components=21)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 26: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 22}, '_runtime_instance': PLSRegression(n_components=22)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 27: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 23}, '_runtime_instance': PLSRegression(n_components=23)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 28: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 24}, '_runtime_instance': PLSRegression(n_components=24)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 29: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 25}, '_runtime_instance': PLSRegression(n_components=25)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 30: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 26}, '_runtime_instance': PLSRegression(n_components=26)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 31: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 27}, '_runtime_instance': PLSRegression(n_components=27)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 32: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 28}, '_runtime_instance': PLSRegression(n_components=28)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 33: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 29}, '_runtime_instance': PLSRegression(n_components=29)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 34: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 30}, '_runtime_instance': PLSRegression(n_components=30)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 35: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 31}, '_runtime_instance': PLSRegression(n_components=31)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 36: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 32}, '_runtime_instance': PLSRegression(n_components=32)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 37: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 33}, '_runtime_instance': PLSRegression(n_components=33)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 38: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 34}, '_runtime_instance': PLSRegression(n_components=34)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 39: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 35}, '_runtime_instance': PLSRegression(n_components=35)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 40: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 36}, '_runtime_instance': PLSRegression(n_components=36)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 41: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 37}, '_runtime_instance': PLSRegression(n_components=37)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 42: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 38}, '_runtime_instance': PLSRegression(n_components=38)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 43: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 39}, '_runtime_instance': PLSRegression(n_components=39)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 44: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 40}, '_runtime_instance': PLSRegression(n_components=40)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 45: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 41}, '_runtime_instance': PLSRegression(n_components=41)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 46: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 42}, '_runtime_instance': PLSRegression(n_components=42)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 47: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 43}, '_runtime_instance': PLSRegression(n_components=43)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 48: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 44}, '_runtime_instance': PLSRegression(n_components=44)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 49: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 45}, '_runtime_instance': PLSRegression(n_components=45)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 50: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 46}, '_runtime_instance': PLSRegression(n_components=46)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 51: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 47}, '_runtime_instance': PLSRegression(n_components=47)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 52: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 48}, '_runtime_instance': PLSRegression(n_components=48)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 53: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 49}, '_runtime_instance': PLSRegression(n_components=49)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 54: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 50}, '_runtime_instance': PLSRegression(n_components=50)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 55: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 51}, '_runtime_instance': PLSRegression(n_components=51)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 56: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 52}, '_runtime_instance': PLSRegression(n_components=52)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 57: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 53}, '_runtime_instance': PLSRegression(n_components=53)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 58: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 54}, '_runtime_instance': PLSRegression(n_components=54)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 59: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 55}, '_runtime_instance': PLSRegression(n_components=55)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 60: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 56}, '_runtime_instance': PLSRegression(n_components=56)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 61: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 57}, '_runtime_instance': PLSRegression(n_components=57)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 62: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 58}, '_runtime_instance': PLSRegression(n_components=58)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 63: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 59}, '_runtime_instance': PLSRegression(n_components=59)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 64: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 60}, '_runtime_instance': PLSRegression(n_components=60)}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "💾 Saved 6 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_563e869e completed successfully on dataset regression\u001b[0m\n",
      "[(<nirs4all.dataset.dataset.SpectroDataset object at 0x0000023BA50919C0>, <nirs4all.pipeline.history.PipelineHistory object at 0x0000023BA5091A20>, None), (<nirs4all.dataset.dataset.SpectroDataset object at 0x0000023BA3EEDFF0>, <nirs4all.pipeline.history.PipelineHistory object at 0x0000023BFC09BE50>, None)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from nirs4all.operators.transformations import Gaussian, SavitzkyGolay, StandardNormalVariate, Haar\n",
    "from nirs4all.pipeline.config import PipelineConfigs\n",
    "from nirs4all.dataset.dataset_config import DatasetConfigs\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "import json\n",
    "\n",
    "pipeline_separated = [\n",
    "    # Normalize the spectra reflectance\n",
    "    MinMaxScaler(feature_range=(0.1, 0.8)),\n",
    "\n",
    "    # Generate 10 version of feature augmentation combinations (3 elements with size 1 to 2, ie. [SG, [SNV, GS], Haar])\n",
    "    {\n",
    "        \"feature_augmentation\": {\n",
    "            \"_or_\": [\n",
    "                Gaussian, StandardNormalVariate, SavitzkyGolay, Haar,\n",
    "            ],\n",
    "            \"size\": [3, (1,2)],\n",
    "            \"count\": 2,\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Split the dataset in train and validation\n",
    "    ShuffleSplit(n_splits=3, test_size=.25),\n",
    "\n",
    "    # Normalize the y values\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "\n",
    "    # PLS regression with 1 to 60 components\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\n",
    "            \"n_components\": {\n",
    "                \"_range_\": [1, 4],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pipeline_commons = [\n",
    "    # Normalize the spectra reflectance\n",
    "    MinMaxScaler(),\n",
    "\n",
    "    # Generate 10 version of feature augmentation combinations (3 elements with size 1 to 2, ie. [SG, [SNV, GS], Haar])\n",
    "    {\n",
    "        \"feature_augmentation\": {\n",
    "            \"_or_\": [\n",
    "                Gaussian, StandardNormalVariate, SavitzkyGolay, Haar,\n",
    "            ],\n",
    "            \"size\": [3, (1,2)],\n",
    "            \"count\": 2,\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Split the dataset in train and validation\n",
    "    ShuffleSplit(n_splits=3, test_size=.25),\n",
    "\n",
    "    # Normalize the y values\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "]\n",
    "\n",
    "for i in range(1, 61):\n",
    "    pipeline_commons.append(PLSRegression(n_components=i))\n",
    "\n",
    "# create pipeline config\n",
    "config = PipelineConfigs(pipeline_commons)\n",
    "\n",
    "\n",
    "# path = ['../../sample_data/regression', '../../sample_data/classification', '../../sample_data/binary']\n",
    "path = '../../sample_data/regression'\n",
    "dataset_config_obj = DatasetConfigs(path)\n",
    "\n",
    "runner = PipelineRunner()\n",
    "results = runner.run(config, dataset_config_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf9b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_commons = [\n",
    "    MinMaxScaler(feature_range=(0.1, 0.8)),\n",
    "    {\n",
    "        \"y_processing\": {\n",
    "            \"class\": \"sklearn.preprocessing._data.MinMaxScaler\",\n",
    "            \"params\": {\n",
    "                \"feature_range\": (0.1, 0.8)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\n",
    "            \"n_components\": {\n",
    "                \"_range_\": [1, 4],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca8501ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing serialization ===\n",
      "Original: {'y_processing': <class 'sklearn.preprocessing._data.MinMaxScaler'>}\n",
      "Serialized: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\n",
      "JSON: {\n",
      "  \"y_processing\": {\n",
      "    \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "  }\n",
      "}\n",
      "Deserialized y_processing: MinMaxScaler() (type: <class 'sklearn.preprocessing._data.MinMaxScaler'>)\n",
      "\n",
      "==================================================\n",
      "Original: {'model': {'class': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'params': {'n_components': 1}}}\n",
      "Preprocessed: {'model': {'class': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'params': {'n_components': 1}}}\n",
      "Serialized: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}}}\n",
      "JSON: {\n",
      "  \"model\": {\n",
      "    \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "    \"params\": {\n",
      "      \"n_components\": 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "Deserialized model: PLSRegression(n_components=1) (type: <class 'sklearn.cross_decomposition._pls.PLSRegression'>)\n",
      "\n",
      "==================================================\n",
      "Original pipeline: [<class 'sklearn.preprocessing._data.MinMaxScaler'>, {'y_processing': <class 'sklearn.preprocessing._data.MinMaxScaler'>}, {'model': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'model_params': {'n_components': 1}}]\n",
      "Preprocessed pipeline: [<class 'sklearn.preprocessing._data.MinMaxScaler'>, {'y_processing': <class 'sklearn.preprocessing._data.MinMaxScaler'>}, {'model': {'class': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'params': {'n_components': 1}}}]\n",
      "Serialized pipeline: [\n",
      "  \"sklearn.preprocessing._data.MinMaxScaler\",\n",
      "  {\n",
      "    \"y_processing\": {\n",
      "      \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"model\": {\n",
      "      \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "      \"params\": {\n",
      "        \"n_components\": 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Let's debug the serialization process\n",
    "import json\n",
    "from nirs4all.pipeline.serialization import serialize_component, deserialize_component\n",
    "\n",
    "print(\"=== Testing serialization ===\")\n",
    "\n",
    "# Test case 1: Bare class\n",
    "test_step_1 = {\"y_processing\": MinMaxScaler}\n",
    "serialized_1 = serialize_component(test_step_1)\n",
    "print(f\"Original: {test_step_1}\")\n",
    "print(f\"Serialized: {serialized_1}\")\n",
    "print(f\"JSON: {json.dumps(serialized_1, indent=2)}\")\n",
    "\n",
    "# Test deserialization\n",
    "deserialized_1 = deserialize_component(serialized_1[\"y_processing\"])\n",
    "print(f\"Deserialized y_processing: {deserialized_1} (type: {type(deserialized_1)})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Test case 2: With params\n",
    "test_step_2 = {\n",
    "    \"model\": PLSRegression,\n",
    "    \"model_params\": {\"n_components\": 1}\n",
    "}\n",
    "\n",
    "from nirs4all.pipeline.config import PipelineConfigs\n",
    "preprocessed_2 = PipelineConfigs._preprocess_steps(test_step_2)\n",
    "serialized_2 = serialize_component(preprocessed_2)\n",
    "print(f\"Original: {test_step_2}\")\n",
    "print(f\"Preprocessed: {preprocessed_2}\")\n",
    "print(f\"Serialized: {serialized_2}\")\n",
    "print(f\"JSON: {json.dumps(serialized_2, indent=2)}\")\n",
    "\n",
    "# Test deserialization\n",
    "deserialized_2 = deserialize_component(serialized_2[\"model\"])\n",
    "print(f\"Deserialized model: {deserialized_2} (type: {type(deserialized_2)})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Test the full pipeline config\n",
    "test_pipeline = [\n",
    "    MinMaxScaler,\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\n",
    "            \"n_components\": 1,\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Original pipeline: {test_pipeline}\")\n",
    "preprocessed = PipelineConfigs._preprocess_steps(test_pipeline)\n",
    "print(f\"Preprocessed pipeline: {preprocessed}\")\n",
    "serialized = serialize_component(preprocessed)\n",
    "print(f\"Serialized pipeline: {json.dumps(serialized, indent=2, default=str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac4fc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking actual config steps ===\n",
      "Config steps type: <class 'list'>\n",
      "Number of pipeline configurations: 1\n",
      "\n",
      "Pipeline config 0:\n",
      "  Type: <class 'list'>\n",
      "  Length: 3\n",
      "  Step 0: sklearn.preprocessing._data.MinMaxScaler (type: <class 'str'>)\n",
      "  Step 1: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}} (type: <class 'dict'>)\n",
      "    y_processing: {'class': 'sklearn.preprocessing._data.MinMaxScaler'} (type: <class 'dict'>)\n",
      "      class: sklearn.preprocessing._data.MinMaxScaler (type: <class 'str'>)\n",
      "  Step 2: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}}} (type: <class 'dict'>)\n",
      "    model: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}} (type: <class 'dict'>)\n",
      "      class: sklearn.cross_decomposition._pls.PLSRegression (type: <class 'str'>)\n",
      "      params: {'n_components': 1} (type: <class 'dict'>)\n"
     ]
    }
   ],
   "source": [
    "# Test the actual config object and examine its steps\n",
    "print(\"=== Checking actual config steps ===\")\n",
    "print(f\"Config steps type: {type(config.steps)}\")\n",
    "print(f\"Number of pipeline configurations: {len(config.steps)}\")\n",
    "\n",
    "for i, steps in enumerate(config.steps):\n",
    "    print(f\"\\nPipeline config {i}:\")\n",
    "    print(f\"  Type: {type(steps)}\")\n",
    "    print(f\"  Length: {len(steps) if hasattr(steps, '__len__') else 'N/A'}\")\n",
    "\n",
    "    if isinstance(steps, list):\n",
    "        for j, step in enumerate(steps):\n",
    "            print(f\"  Step {j}: {step} (type: {type(step)})\")\n",
    "            if isinstance(step, dict):\n",
    "                for key, value in step.items():\n",
    "                    print(f\"    {key}: {value} (type: {type(value)})\")\n",
    "                    if isinstance(value, dict) and 'class' in value:\n",
    "                        print(f\"      class: {value['class']} (type: {type(value['class'])})\")\n",
    "                        if 'params' in value:\n",
    "                            print(f\"      params: {value['params']} (type: {type(value['params'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2ce3f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing runner logic simulation ===\n",
      "Step: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}}}\n",
      "Found key: model\n",
      "step[key]: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}}\n",
      "'class' in step[key]: True\n",
      "Deserializing step[key]...\n",
      "Operator after deserialization: PLSRegression(n_components=1)\n",
      "Operator type: <class 'sklearn.cross_decomposition._pls.PLSRegression'>\n",
      "Has fit method: True\n",
      "✅ Operator correctly deserialized!\n"
     ]
    }
   ],
   "source": [
    "# Let's test the exact deserialization that should happen in the runner\n",
    "print(\"=== Testing runner logic simulation ===\")\n",
    "\n",
    "# Simulate step 3 processing\n",
    "step = {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}}}\n",
    "print(f\"Step: {step}\")\n",
    "\n",
    "# Check what key is found\n",
    "WORKFLOW_OPERATORS = [\"sample_augmentation\", \"feature_augmentation\", \"branch\", \"dispatch\", \"model\", \"stack\",\n",
    "                      \"scope\", \"cluster\", \"merge\", \"uncluster\", \"unscope\", \"chart_2d\", \"chart_3d\", \"fold_chart\",\n",
    "                      \"model\", \"y_processing\", \"y_chart\"]\n",
    "\n",
    "key = next((k for k in step if k in WORKFLOW_OPERATORS), None)\n",
    "print(f\"Found key: {key}\")\n",
    "\n",
    "if key:\n",
    "    print(f\"step[key]: {step[key]}\")\n",
    "    print(f\"'class' in step[key]: {'class' in step[key]}\")\n",
    "\n",
    "    if 'class' in step[key]:\n",
    "        print(\"Deserializing step[key]...\")\n",
    "        operator = deserialize_component(step[key])\n",
    "        print(f\"Operator after deserialization: {operator}\")\n",
    "        print(f\"Operator type: {type(operator)}\")\n",
    "        print(f\"Has fit method: {hasattr(operator, 'fit')}\")\n",
    "\n",
    "        if hasattr(operator, 'fit'):\n",
    "            print(\"✅ Operator correctly deserialized!\")\n",
    "        else:\n",
    "            print(\"❌ Operator missing fit method!\")\n",
    "            print(f\"Operator attributes: {dir(operator)}\")\n",
    "    else:\n",
    "        print(\"No 'class' key found in step[key]\")\n",
    "else:\n",
    "    print(\"No workflow operator key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9006f5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing both requested pipeline syntaxes ===\n",
      "Pipeline 1 (without model_params):\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "✅ Configuration created with 1 step(s)\n",
      "Steps: [\n",
      "  \"sklearn.preprocessing._data.MinMaxScaler\",\n",
      "  {\n",
      "    \"y_processing\": {\n",
      "      \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"model\": {\n",
      "      \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "======================================================================\n",
      "Pipeline 2 (with model_params):\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "✅ Configuration created with 1 step(s)\n",
      "Steps: [\n",
      "  \"sklearn.preprocessing._data.MinMaxScaler\",\n",
      "  {\n",
      "    \"y_processing\": {\n",
      "      \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"model\": {\n",
      "      \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "      \"params\": {\n",
      "        \"n_components\": 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "✅ Both syntaxes now work and produce the expected serialization format!\n"
     ]
    }
   ],
   "source": [
    "# Test both syntax examples from the user's request\n",
    "print(\"=== Testing both requested pipeline syntaxes ===\")\n",
    "\n",
    "# Test syntax 1: Without model_params\n",
    "pipeline_1 = [\n",
    "    MinMaxScaler,\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Pipeline 1 (without model_params):\")\n",
    "config_1 = PipelineConfigs(pipeline_1)\n",
    "print(f\"✅ Configuration created with {len(config_1.steps)} step(s)\")\n",
    "print(f\"Steps: {json.dumps(config_1.steps[0], indent=2, default=str)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Test syntax 2: With model_params (already tested above)\n",
    "pipeline_2 = [\n",
    "    MinMaxScaler,\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\n",
    "            \"n_components\":1,\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Pipeline 2 (with model_params):\")\n",
    "config_2 = PipelineConfigs(pipeline_2)\n",
    "print(f\"✅ Configuration created with {len(config_2.steps)} step(s)\")\n",
    "print(f\"Steps: {json.dumps(config_2.steps[0], indent=2, default=str)}\")\n",
    "\n",
    "# Verify the expected serialization format\n",
    "expected_format = [\n",
    "  {\n",
    "    \"class\": \"sklearn.preprocessing._data.MinMaxScaler\",\n",
    "  },\n",
    "  {\n",
    "    \"y_processing\": {\n",
    "        \"class\": \"sklearn.preprocessing._data.MinMaxScaler\",\n",
    "      }\n",
    "  },\n",
    "  {\n",
    "    \"model\": {\n",
    "        \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
    "        \"params\": {\n",
    "          \"n_components\": 1,\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "]\n",
    "\n",
    "print(f\"\\n✅ Both syntaxes now work and produce the expected serialization format!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "317a1103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Agnostic XX/XX_params Pattern Detection ===\n",
      "\n",
      "Test Case 1:\n",
      "Original: {'model': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'model_params': {'n_components': 2}}\n",
      "Preprocessed: {'model': {'class': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'params': {'n_components': 2}}}\n",
      "Serialized: {\n",
      "  \"model\": {\n",
      "    \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "    \"params\": {\n",
      "      \"n_components\": 2\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Test Case 2:\n",
      "Original: {'y_processing': <class 'sklearn.preprocessing._data.MinMaxScaler'>, 'y_processing_params': {'feature_range': (0, 1)}}\n",
      "Preprocessed: {'y_processing': {'class': <class 'sklearn.preprocessing._data.MinMaxScaler'>, 'params': {'feature_range': (0, 1)}}}\n",
      "Serialized: {\n",
      "  \"y_processing\": {\n",
      "    \"class\": \"sklearn.preprocessing._data.MinMaxScaler\",\n",
      "    \"params\": {\n",
      "      \"feature_range\": [\n",
      "        0,\n",
      "        1\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Test Case 3:\n",
      "Original: {'splitter': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'splitter_params': {'n_splits': 5, 'test_size': 0.3}}\n",
      "Preprocessed: {'splitter': {'class': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'params': {'n_splits': 5, 'test_size': 0.3}}}\n",
      "Serialized: {\n",
      "  \"splitter\": {\n",
      "    \"class\": \"sklearn.model_selection._split.ShuffleSplit\",\n",
      "    \"params\": {\n",
      "      \"n_splits\": 5,\n",
      "      \"test_size\": 0.3\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Test Case 4:\n",
      "Original: {'class': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'params': {'n_splits': 3, 'test_size': 0.25}}\n",
      "Preprocessed: {'class': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'params': {'n_splits': 3, 'test_size': 0.25}}\n",
      "Serialized: {\n",
      "  \"class\": \"sklearn.model_selection._split.ShuffleSplit\",\n",
      "  \"params\": {\n",
      "    \"n_splits\": 3,\n",
      "    \"test_size\": 0.25\n",
      "  }\n",
      "}\n",
      "\n",
      "Test Case 5:\n",
      "Original: {'model': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'model_params': {'n_components': 1}, 'y_processing': <class 'sklearn.preprocessing._data.MinMaxScaler'>, 'other_key': 'some_value'}\n",
      "Preprocessed: {'model': {'class': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'params': {'n_components': 1}}, 'y_processing': <class 'sklearn.preprocessing._data.MinMaxScaler'>, 'other_key': 'some_value'}\n",
      "Serialized: {\n",
      "  \"model\": {\n",
      "    \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "    \"params\": {\n",
      "      \"n_components\": 1\n",
      "    }\n",
      "  },\n",
      "  \"y_processing\": \"sklearn.preprocessing._data.MinMaxScaler\",\n",
      "  \"other_key\": \"some_value\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test the improved agnostic preprocessing logic\n",
    "print(\"=== Testing Agnostic XX/XX_params Pattern Detection ===\")\n",
    "\n",
    "# Test case 1: Multiple different component types with params\n",
    "test_cases = [\n",
    "    # Case 1: model/model_params\n",
    "    {\"model\": PLSRegression, \"model_params\": {\"n_components\": 2}},\n",
    "\n",
    "    # Case 2: y_processing/y_processing_params\n",
    "    {\"y_processing\": MinMaxScaler, \"y_processing_params\": {\"feature_range\": (0, 1)}},\n",
    "\n",
    "    # Case 3: splitter/splitter_params\n",
    "    {\"splitter\": ShuffleSplit, \"splitter_params\": {\"n_splits\": 5, \"test_size\": 0.3}},\n",
    "\n",
    "    # Case 4: Direct class/params format\n",
    "    {\"class\": ShuffleSplit, \"params\": {\"n_splits\": 3, \"test_size\": 0.25}},\n",
    "\n",
    "    # Case 5: Mixed components in one dict\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\"n_components\": 1},\n",
    "        \"y_processing\": MinMaxScaler,\n",
    "        \"other_key\": \"some_value\"\n",
    "    }\n",
    "]\n",
    "\n",
    "from nirs4all.pipeline.config import PipelineConfigs\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nTest Case {i}:\")\n",
    "    print(f\"Original: {test_case}\")\n",
    "\n",
    "    preprocessed = PipelineConfigs._preprocess_steps(test_case)\n",
    "    print(f\"Preprocessed: {preprocessed}\")\n",
    "\n",
    "    serialized = serialize_component(preprocessed)\n",
    "    print(f\"Serialized: {json.dumps(serialized, indent=2, default=str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a055091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Serialization Consistency ===\n",
      "Testing equivalent configurations...\n",
      "\n",
      "Variation 1: {'model': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'model_params': {'n_components': 2}}\n",
      "Serialized: {\n",
      "  \"model\": {\n",
      "    \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "    \"params\": {\n",
      "      \"n_components\": 2\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Variation 2: {'model': {'class': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'params': {'n_components': 2}}}\n",
      "Serialized: {\n",
      "  \"model\": {\n",
      "    \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "    \"params\": {\n",
      "      \"n_components\": 2\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Variation 3: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 2}}}\n",
      "Serialized: {\n",
      "  \"model\": {\n",
      "    \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "    \"params\": {\n",
      "      \"n_components\": 2\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Consistency Check ===\n",
      "All variations produce identical serialized output: True\n",
      "✅ Serialization is consistent across different syntax variations!\n",
      "Hash 1: f66d7f62\n",
      "Hash 2: f66d7f62\n",
      "Hash 3: f66d7f62\n",
      "All hashes equal: True\n"
     ]
    }
   ],
   "source": [
    "# Test consistency: different syntax variations should produce identical serialized output\n",
    "print(\"\\n=== Testing Serialization Consistency ===\")\n",
    "\n",
    "# Define equivalent configurations using different syntax\n",
    "equivalent_configs = [\n",
    "    # Variation 1: XX/XX_params pattern\n",
    "    {\"model\": PLSRegression, \"model_params\": {\"n_components\": 2}},\n",
    "\n",
    "    # Variation 2: Direct class/params pattern\n",
    "    {\"model\": {\"class\": PLSRegression, \"params\": {\"n_components\": 2}}},\n",
    "\n",
    "    # Variation 3: Already preprocessed format\n",
    "    {\"model\": {\"class\": \"sklearn.cross_decomposition._pls.PLSRegression\", \"params\": {\"n_components\": 2}}},\n",
    "]\n",
    "\n",
    "print(\"Testing equivalent configurations...\")\n",
    "serialized_results = []\n",
    "\n",
    "for i, config in enumerate(equivalent_configs, 1):\n",
    "    print(f\"\\nVariation {i}: {config}\")\n",
    "\n",
    "    # Apply full pipeline processing\n",
    "    preprocessed = PipelineConfigs._preprocess_steps(config)\n",
    "    serialized = serialize_component(preprocessed)\n",
    "    serialized_results.append(serialized)\n",
    "\n",
    "    print(f\"Serialized: {json.dumps(serialized, indent=2, default=str)}\")\n",
    "\n",
    "# Check if all serialized results are identical\n",
    "print(f\"\\n=== Consistency Check ===\")\n",
    "all_equal = all(serialized_results[0] == result for result in serialized_results[1:])\n",
    "print(f\"All variations produce identical serialized output: {all_equal}\")\n",
    "\n",
    "if all_equal:\n",
    "    print(\"✅ Serialization is consistent across different syntax variations!\")\n",
    "\n",
    "    # Test hash consistency\n",
    "    hash1 = PipelineConfigs.get_hash([serialized_results[0]])\n",
    "    hash2 = PipelineConfigs.get_hash([serialized_results[1]])\n",
    "    hash3 = PipelineConfigs.get_hash([serialized_results[2]])\n",
    "\n",
    "    print(f\"Hash 1: {hash1}\")\n",
    "    print(f\"Hash 2: {hash2}\")\n",
    "    print(f\"Hash 3: {hash3}\")\n",
    "    print(f\"All hashes equal: {hash1 == hash2 == hash3}\")\n",
    "else:\n",
    "    print(\"❌ Serialization is not consistent!\")\n",
    "    for i, result in enumerate(serialized_results):\n",
    "        print(f\"Result {i+1}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e025e37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Enhanced Preprocessing for Bare Classes ===\n",
      "\n",
      "Test Case 1:\n",
      "Original: {'y_processing': <class 'sklearn.preprocessing._data.MinMaxScaler'>}\n",
      "Preprocessed: {'y_processing': {'class': <class 'sklearn.preprocessing._data.MinMaxScaler'>}}\n",
      "Serialized: {\n",
      "  \"y_processing\": {\n",
      "    \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Test Case 2:\n",
      "Original: {'model': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'model_params': {'n_components': 1}, 'y_processing': <class 'sklearn.preprocessing._data.MinMaxScaler'>}\n",
      "Preprocessed: {'model': {'class': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'params': {'n_components': 1}}, 'y_processing': {'class': <class 'sklearn.preprocessing._data.MinMaxScaler'>}}\n",
      "Serialized: {\n",
      "  \"model\": {\n",
      "    \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "    \"params\": {\n",
      "      \"n_components\": 1\n",
      "    }\n",
      "  },\n",
      "  \"y_processing\": {\n",
      "    \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Test Case 3:\n",
      "Original: {'class': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'params': {'n_splits': 3}}\n",
      "Preprocessed: {'class': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'params': {'n_splits': 3}}\n",
      "Serialized: {\n",
      "  \"class\": \"sklearn.model_selection._split.ShuffleSplit\",\n",
      "  \"params\": {\n",
      "    \"n_splits\": 3\n",
      "  }\n",
      "}\n",
      "\n",
      "Test Case 4:\n",
      "Original: {'splitter': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'validator': <class 'sklearn.preprocessing._data.MinMaxScaler'>, 'other_key': 'some_value'}\n",
      "Preprocessed: {'splitter': {'class': <class 'sklearn.model_selection._split.ShuffleSplit'>}, 'validator': {'class': <class 'sklearn.preprocessing._data.MinMaxScaler'>}, 'other_key': 'some_value'}\n",
      "Serialized: {\n",
      "  \"splitter\": {\n",
      "    \"class\": \"sklearn.model_selection._split.ShuffleSplit\"\n",
      "  },\n",
      "  \"validator\": {\n",
      "    \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "  },\n",
      "  \"other_key\": \"some_value\"\n",
      "}\n",
      "\n",
      "=== Testing Original Pipeline Case ===\n",
      "Original pipeline: [<class 'sklearn.preprocessing._data.MinMaxScaler'>, {'y_processing': <class 'sklearn.preprocessing._data.MinMaxScaler'>}, {'model': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'model_params': {'n_components': 1}}]\n",
      "Preprocessed pipeline: [<class 'sklearn.preprocessing._data.MinMaxScaler'>, {'y_processing': {'class': <class 'sklearn.preprocessing._data.MinMaxScaler'>}}, {'model': {'class': <class 'sklearn.cross_decomposition._pls.PLSRegression'>, 'params': {'n_components': 1}}}]\n",
      "Serialized pipeline: [\n",
      "  \"sklearn.preprocessing._data.MinMaxScaler\",\n",
      "  {\n",
      "    \"y_processing\": {\n",
      "      \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"model\": {\n",
      "      \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "      \"params\": {\n",
      "        \"n_components\": 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Test the enhanced preprocessing that handles bare classes in component keys\n",
    "print(\"=== Testing Enhanced Preprocessing for Bare Classes ===\")\n",
    "\n",
    "test_cases = [\n",
    "    # Case 1: Bare class in component key (like y_processing)\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "\n",
    "    # Case 2: Combination of bare class and XX/XX_params\n",
    "    {\"model\": PLSRegression, \"model_params\": {\"n_components\": 1}, \"y_processing\": MinMaxScaler},\n",
    "\n",
    "    # Case 3: Direct class/params format\n",
    "    {\"class\": ShuffleSplit, \"params\": {\"n_splits\": 3}},\n",
    "\n",
    "    # Case 4: Mixed scenarios\n",
    "    {\"splitter\": ShuffleSplit, \"validator\": MinMaxScaler, \"other_key\": \"some_value\"}\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nTest Case {i}:\")\n",
    "    print(f\"Original: {test_case}\")\n",
    "\n",
    "    preprocessed = PipelineConfigs._preprocess_steps(test_case)\n",
    "    print(f\"Preprocessed: {preprocessed}\")\n",
    "\n",
    "    serialized = serialize_component(preprocessed)\n",
    "    print(f\"Serialized: {json.dumps(serialized, indent=2, default=str)}\")\n",
    "\n",
    "# Test our original pipeline case\n",
    "print(\"\\n=== Testing Original Pipeline Case ===\")\n",
    "original_pipeline = [\n",
    "    MinMaxScaler,\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\n",
    "            \"n_components\": 1,\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Original pipeline: {original_pipeline}\")\n",
    "preprocessed_pipeline = PipelineConfigs._preprocess_steps(original_pipeline)\n",
    "print(f\"Preprocessed pipeline: {preprocessed_pipeline}\")\n",
    "serialized_pipeline = serialize_component(preprocessed_pipeline)\n",
    "print(f\"Serialized pipeline: {json.dumps(serialized_pipeline, indent=2, default=str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e209b77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Consistency Check for Requested Syntaxes ===\n",
      "Syntax 1 (without model_params):\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "Hash: 4380155b\n",
      "Serialized: [\n",
      "  \"sklearn.preprocessing._data.MinMaxScaler\",\n",
      "  {\n",
      "    \"y_processing\": {\n",
      "      \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"model\": {\n",
      "      \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "Syntax 2 (with model_params):\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "Hash: 7b748deb\n",
      "Serialized: [\n",
      "  \"sklearn.preprocessing._data.MinMaxScaler\",\n",
      "  {\n",
      "    \"y_processing\": {\n",
      "      \"class\": \"sklearn.preprocessing._data.MinMaxScaler\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"model\": {\n",
      "      \"class\": \"sklearn.cross_decomposition._pls.PLSRegression\",\n",
      "      \"params\": {\n",
      "        \"n_components\": 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "Same hash (as expected, different params): False\n",
      "\n",
      "=== Testing Equivalent Configurations ===\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "Format 1 hash: 7b748deb\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "Format 2 hash: 7b748deb\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "Format 3 hash: 7b748deb\n",
      "\n",
      "All equivalent configurations have same hash: True\n",
      "✅ Perfect! All equivalent syntax variations produce identical hashes!\n"
     ]
    }
   ],
   "source": [
    "# Test the final consistency check for the two requested syntaxes\n",
    "print(\"=== Final Consistency Check for Requested Syntaxes ===\")\n",
    "\n",
    "# The two syntaxes from the user's request\n",
    "syntax_1 = [\n",
    "    MinMaxScaler,\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "    {\"model\": PLSRegression}\n",
    "]\n",
    "\n",
    "syntax_2 = [\n",
    "    MinMaxScaler,\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\"n_components\": 1}\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Syntax 1 (without model_params):\")\n",
    "config_1 = PipelineConfigs(syntax_1)\n",
    "hash_1 = config_1.get_hash(config_1.steps[0])\n",
    "print(f\"Hash: {hash_1}\")\n",
    "print(f\"Serialized: {json.dumps(config_1.steps[0], indent=2, default=str)}\")\n",
    "\n",
    "print(\"\\nSyntax 2 (with model_params):\")\n",
    "config_2 = PipelineConfigs(syntax_2)\n",
    "hash_2 = config_2.get_hash(config_2.steps[0])\n",
    "print(f\"Hash: {hash_2}\")\n",
    "print(f\"Serialized: {json.dumps(config_2.steps[0], indent=2, default=str)}\")\n",
    "\n",
    "print(f\"\\nSame hash (as expected, different params): {hash_1 == hash_2}\")\n",
    "\n",
    "# Test equivalent configurations with same params\n",
    "syntax_2_alt_formats = [\n",
    "    # Format 1: XX/XX_params\n",
    "    [MinMaxScaler, {\"y_processing\": MinMaxScaler}, {\"model\": PLSRegression, \"model_params\": {\"n_components\": 1}}],\n",
    "\n",
    "    # Format 2: nested class/params\n",
    "    [MinMaxScaler, {\"y_processing\": MinMaxScaler}, {\"model\": {\"class\": PLSRegression, \"params\": {\"n_components\": 1}}}],\n",
    "\n",
    "    # Format 3: string class name\n",
    "    [MinMaxScaler, {\"y_processing\": MinMaxScaler}, {\"model\": {\"class\": \"sklearn.cross_decomposition._pls.PLSRegression\", \"params\": {\"n_components\": 1}}}]\n",
    "]\n",
    "\n",
    "print(f\"\\n=== Testing Equivalent Configurations ===\")\n",
    "hashes = []\n",
    "\n",
    "for i, config_def in enumerate(syntax_2_alt_formats, 1):\n",
    "    config = PipelineConfigs(config_def)\n",
    "    hash_val = config.get_hash(config.steps[0])\n",
    "    hashes.append(hash_val)\n",
    "    print(f\"Format {i} hash: {hash_val}\")\n",
    "\n",
    "all_same = all(h == hashes[0] for h in hashes[1:])\n",
    "print(f\"\\nAll equivalent configurations have same hash: {all_same}\")\n",
    "\n",
    "if all_same:\n",
    "    print(\"✅ Perfect! All equivalent syntax variations produce identical hashes!\")\n",
    "else:\n",
    "    print(\"❌ Issue: Equivalent configurations produce different hashes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a528db9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Investigating Pipeline Configuration Generation ===\n",
      "Number of configurations generated: 4\n",
      "Configuration names: ['config_408030b0', 'config_d0a3f61e', 'config_bc2891fd', 'config_5b9b41c8']\n",
      "\n",
      "--- Configuration 1: config_408030b0 ---\n",
      "  Step 0: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.1, 0.8))}\n",
      "  Step 1: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}}}\n",
      "  Step 2: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}}}\n",
      "\n",
      "--- Configuration 2: config_d0a3f61e ---\n",
      "  Step 0: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.1, 0.8))}\n",
      "  Step 1: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}}}\n",
      "  Step 2: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 2}}}\n",
      "\n",
      "--- Configuration 3: config_bc2891fd ---\n",
      "  Step 0: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.1, 0.8))}\n",
      "  Step 1: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}}}\n",
      "  Step 2: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 3}}}\n",
      "\n",
      "--- Configuration 4: config_5b9b41c8 ---\n",
      "  Step 0: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.1, 0.8))}\n",
      "  Step 1: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}}}\n",
      "  Step 2: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 4}}}\n",
      "\n",
      "=== Y-Processing Steps in Each Configuration ===\n",
      "Config 1: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}}}\n",
      "Config 2: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}}}\n",
      "Config 3: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}}}\n",
      "Config 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}}}\n",
      "\n",
      "=== Analysis ===\n",
      "The issue: All configurations share identical y_processing steps.\n",
      "When the pipeline runner executes them sequentially on the same dataset,\n",
      "they try to create the same processing name 'numeric_MinMaxScaler1',\n",
      "causing a collision after the first configuration completes.\n"
     ]
    }
   ],
   "source": [
    "# Investigate the naming collision issue\n",
    "print(\"=== Investigating Pipeline Configuration Generation ===\")\n",
    "\n",
    "# Check how many configurations are generated\n",
    "print(f\"Number of configurations generated: {len(config.steps)}\")\n",
    "print(f\"Configuration names: {config.names}\")\n",
    "\n",
    "# Check each configuration\n",
    "for i, (steps, name) in enumerate(zip(config.steps, config.names)):\n",
    "    print(f\"\\n--- Configuration {i+1}: {name} ---\")\n",
    "    for j, step in enumerate(steps):\n",
    "        if isinstance(step, dict):\n",
    "            print(f\"  Step {j}: {step}\")\n",
    "        else:\n",
    "            print(f\"  Step {j}: {step}\")\n",
    "\n",
    "# The issue is that all configurations have identical y_processing steps\n",
    "# Let's see what the y_processing step looks like in each config\n",
    "print(f\"\\n=== Y-Processing Steps in Each Configuration ===\")\n",
    "for i, steps in enumerate(config.steps):\n",
    "    y_processing_step = steps[1]  # Should be the y_processing step\n",
    "    print(f\"Config {i+1}: {y_processing_step}\")\n",
    "\n",
    "print(f\"\\n=== Analysis ===\")\n",
    "print(\"The issue: All configurations share identical y_processing steps.\")\n",
    "print(\"When the pipeline runner executes them sequentially on the same dataset,\")\n",
    "print(\"they try to create the same processing name 'numeric_MinMaxScaler1',\")\n",
    "print(\"causing a collision after the first configuration completes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5fd6e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Current Pipeline Analysis ===\n",
      "Configuration has 2 pipeline(s)\n",
      "Each pipeline has 63 steps\n",
      "Number of PLS regression models: 59\n",
      "n_components range: 1 to 60\n",
      "Dataset sizes:\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SpectroDataset' object has no attribute 'X_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d_config \u001b[38;5;129;01min\u001b[39;00m dataset_config_obj\u001b[38;5;241m.\u001b[39mdata_configs:\n\u001b[0;32m     19\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset_config_obj\u001b[38;5;241m.\u001b[39mget_dataset(d_config)\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m training samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Issue Analysis ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe problem: PLS regression n_components cannot exceed the number of training samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SpectroDataset' object has no attribute 'X_train'"
     ]
    }
   ],
   "source": [
    "# Analyze the current pipeline issue\n",
    "print(\"=== Current Pipeline Analysis ===\")\n",
    "print(f\"Configuration has {len(config.steps)} pipeline(s)\")\n",
    "print(f\"Each pipeline has {len(config.steps[0])} steps\")\n",
    "\n",
    "# Check how many PLS regression models are created\n",
    "pls_models = [step for step in config.steps[0] if isinstance(step, dict) and 'n_components' in str(step)]\n",
    "print(f\"Number of PLS regression models: {len(pls_models)}\")\n",
    "\n",
    "# Check the n_components range\n",
    "n_components_values = []\n",
    "for step in config.steps[0]:\n",
    "    if isinstance(step, dict) and step.get('params', {}).get('n_components'):\n",
    "        n_components_values.append(step['params']['n_components'])\n",
    "\n",
    "print(f\"n_components range: {min(n_components_values) if n_components_values else 'N/A'} to {max(n_components_values) if n_components_values else 'N/A'}\")\n",
    "print(f\"Dataset sizes:\")\n",
    "for d_config in dataset_config_obj.data_configs:\n",
    "    dataset = dataset_config_obj.get_dataset(d_config)\n",
    "    print(f\"  - {dataset.name}: {len(dataset.X_train)} training samples\")\n",
    "\n",
    "print(f\"\\n=== Issue Analysis ===\")\n",
    "print(\"The problem: PLS regression n_components cannot exceed the number of training samples.\")\n",
    "print(\"Classification dataset has 48 training samples, but the pipeline tries n_components up to 60.\")\n",
    "print(\"Solution: Limit n_components to be <= min(training samples across all datasets)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating simple test configuration...\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "Configuration created with 1 step(s)\n",
      "Running test with new score management...\n",
      "========================================================================================================================================================================================================\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_5138d6a7 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 3 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 1_0_MinMaxScaler_1.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 2_MinMaxScaler_numeric_MinMaxScaler2.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 2}}, 'train_params': {'verbose': 1}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🎯 PLSRegression - train scores: mse: 0.0335, mae: 0.1347\n",
      "🏆 Best score (mse): 0.0335 ↓\n",
      "🎯 PLSRegression_3 - test scores: mse: 0.0260, mae: 0.1303\n",
      "🏆 Best score (mse): 0.0260 ↓\n",
      "✅ Model PLSRegression_3 completed. Best mse: 0.0260 ↓\n",
      "💾 Saved 2 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_5138d6a7 completed successfully on dataset regression\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test the new score management functionality with simpler pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "# Simpler pipeline configuration to test score functionality\n",
    "simple_pipeline = [\n",
    "    MinMaxScaler(),\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\"n_components\": 2},\n",
    "        \"train_params\": {\"verbose\": 1}  # Enable verbose output to see scores\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Creating simple test configuration...\")\n",
    "config_test = PipelineConfigs(simple_pipeline)\n",
    "print(f\"Configuration created with {len(config_test.steps)} step(s)\")\n",
    "\n",
    "# Use existing dataset config from previous cell\n",
    "print(\"Running test with new score management...\")\n",
    "runner_test = PipelineRunner()\n",
    "\n",
    "# Select only regression dataset for testing\n",
    "path_test = '../../sample_data/regression'\n",
    "dataset_config_test = DatasetConfigs(path_test)\n",
    "\n",
    "# Run just the first dataset config\n",
    "results_test = runner_test.run(config_test, dataset_config_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55255738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testing enhanced Predictions functionality...\n",
      "\n",
      "📊 Dataset Predictions Summary:\n",
      "📈 Predictions: 1 entries\n",
      "   Datasets: ['regression']\n",
      "   Pipelines: ['config_5138d6a7']\n",
      "   Models: ['PLSRegression_3']\n",
      "\n",
      "🏆 Best Scores Summary:\n",
      "🏆 Best Scores Summary (mse):\n",
      "📊 Task Type: regression\n",
      "📈 Optimization: Lower is better\n",
      "--------------------------------------------------------------------------------\n",
      " 1. PLSRegression_3           | test            | mse: 413.8856 ↓\n",
      "\n",
      "📈 All Scores in DataFrame:\n",
      "                                    prediction_key     dataset  \\\n",
      "0  regression_config_5138d6a7_PLSRegression_3_test  regression   \n",
      "\n",
      "          pipeline            model partition fold_idx  n_samples         mse  \\\n",
      "0  config_5138d6a7  PLSRegression_3      test     None         59  413.885571   \n",
      "\n",
      "         mae  \n",
      "0  16.455721  \n",
      "\n",
      "🥇 Top Rankings by MSE:\n",
      "1. regression_config_5138d6a7_PLSRegression_3_test: MSE = 413.8856\n",
      "\n",
      "🥈 Best Score:\n",
      "Best model: regression_config_5138d6a7_PLSRegression_3_test with MSE: 413.8856\n",
      "\n",
      "💾 Saving predictions to CSV...\n",
      "💾 Saved 59 prediction records to ../../results/test_predictions.csv\n",
      "\n",
      "✅ Enhanced Predictions functionality test complete!\n"
     ]
    }
   ],
   "source": [
    "# Test the new enhanced Predictions functionality\n",
    "print(\"🔍 Testing enhanced Predictions functionality...\")\n",
    "\n",
    "# Access the dataset that was used in the pipeline run\n",
    "# The dataset object gets modified during the pipeline run\n",
    "dataset_result, history_result, pipeline_result = results_test[0]\n",
    "\n",
    "print(\"\\n📊 Dataset Predictions Summary:\")\n",
    "print(dataset_result._predictions)\n",
    "\n",
    "if len(dataset_result._predictions) > 0:\n",
    "    print(\"\\n🏆 Best Scores Summary:\")\n",
    "    dataset_result._predictions.print_best_scores_summary()\n",
    "\n",
    "    print(\"\\n📈 All Scores in DataFrame:\")\n",
    "    scores_df = dataset_result._predictions.get_all_scores_summary()\n",
    "    print(scores_df)\n",
    "\n",
    "    print(\"\\n🥇 Top Rankings by MSE:\")\n",
    "    mse_rankings = dataset_result._predictions.get_scores_ranking('mse', ascending=True)\n",
    "    for i, (key, score) in enumerate(mse_rankings[:5], 1):\n",
    "        print(f\"{i}. {key}: MSE = {score:.4f}\")\n",
    "\n",
    "    print(\"\\n🥈 Best Score:\")\n",
    "    best_result = dataset_result._predictions.get_best_score('mse')\n",
    "    if best_result:\n",
    "        key, score = best_result\n",
    "        print(f\"Best model: {key} with MSE: {score:.4f}\")\n",
    "\n",
    "    print(\"\\n💾 Saving predictions to CSV...\")\n",
    "    dataset_result._predictions.save_predictions_to_csv(\n",
    "        '../../results/test_predictions.csv',\n",
    "        include_scores=True\n",
    "    )\n",
    "\n",
    "    print(\"\\n✅ Enhanced Predictions functionality test complete!\")\n",
    "else:\n",
    "    print(\"⚠️ No predictions found in dataset object\")\n",
    "\n",
    "    # Let's check what keys are available in the dataset\n",
    "    print(\"Available prediction keys:\", dataset_result._predictions.list_keys())\n",
    "    print(\"Available datasets:\", dataset_result._predictions.list_datasets())\n",
    "    print(\"Available pipelines:\", dataset_result._predictions.list_pipelines())\n",
    "    print(\"Available models:\", dataset_result._predictions.list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d2b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Testing multiple models for comprehensive ranking...\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "🏃 Running multiple models...\n",
      "\n",
      "=== Running Model 1: PLS ===\n",
      "========================================================================================================================================================================================================\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_1990306e on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 3 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 1_0_MinMaxScaler_1.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 2_MinMaxScaler_numeric_MinMaxScaler2.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 3}}, 'train_params': {'verbose': 1}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🎯 PLSRegression - train scores: mse: 0.0318, mae: 0.1351\n",
      "🏆 Best score (mse): 0.0318 ↓\n",
      "🎯 PLSRegression_3 - test scores: mse: 0.0296, mae: 0.1418\n",
      "🏆 Best score (mse): 0.0296 ↓\n",
      "✅ Model PLSRegression_3 completed. Best mse: 0.0296 ↓\n",
      "💾 Saved 2 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_1990306e completed successfully on dataset regression\u001b[0m\n",
      "\n",
      "=== Running Model 2: RandomForest ===\n",
      "========================================================================================================================================================================================================\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_f5b108c6 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 3 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 1_0_MinMaxScaler_1.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 2_MinMaxScaler_numeric_MinMaxScaler2.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'model': {'class': 'sklearn.ensemble._forest.RandomForestRegressor', 'params': {'n_estimators': 50, 'random_state': 42}}, 'train_params': {'verbose': 1}}\u001b[0m\n",
      "Type mismatch: <class 'int'> != <class 'NoneType'>\n",
      "🔹 Executing controller SklearnModelController with operator RandomForestRegressor\n",
      "🎯 RandomForestRegressor - train scores: mse: 0.0050, mae: 0.0531\n",
      "🏆 Best score (mse): 0.0050 ↓\n",
      "🎯 RandomForestRegressor_3 - test scores: mse: 0.0345, mae: 0.1504\n",
      "🏆 Best score (mse): 0.0345 ↓\n",
      "✅ Model RandomForestRegressor_3 completed. Best mse: 0.0345 ↓\n",
      "💾 Saved 2 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_f5b108c6 completed successfully on dataset regression\u001b[0m\n",
      "\n",
      "=== Running Model 3: Ridge ===\n",
      "========================================================================================================================================================================================================\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_f38842da on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m🔄 Running 3 steps in sequential mode\u001b[0m\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 1_0_MinMaxScaler_1.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "💾 Saved file: 2_MinMaxScaler_numeric_MinMaxScaler2.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'model': {'class': 'sklearn.linear_model._ridge.Ridge', 'params': {'alpha': 1.0}}, 'train_params': {'verbose': 1}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator Ridge\n",
      "🎯 Ridge - train scores: mse: 0.0197, mae: 0.1048\n",
      "🏆 Best score (mse): 0.0197 ↓\n",
      "🎯 Ridge_3 - test scores: mse: 0.0140, mae: 0.0949\n",
      "🏆 Best score (mse): 0.0140 ↓\n",
      "✅ Model Ridge_3 completed. Best mse: 0.0140 ↓\n",
      "💾 Saved 2 files.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94m✅ Pipeline config_f38842da completed successfully on dataset regression\u001b[0m\n",
      "\n",
      "🏆 Final Multi-Model Comparison:\n",
      "=====================================\n",
      "🏆 Best Scores Summary (mse):\n",
      "📊 Task Type: regression\n",
      "📈 Optimization: Lower is better\n",
      "--------------------------------------------------------------------------------\n",
      " 1. Ridge_3                   | test            | mse: 223.8662 ↓\n",
      " 2. PLSRegression_3           | test            | mse: 471.7702 ↓\n",
      " 3. RandomForestRegressor_3   | test            | mse: 549.6191 ↓\n",
      "\n",
      "📊 Detailed Scores DataFrame:\n",
      "                     model         mse        mae\n",
      "2                  Ridge_3  223.866165  11.976521\n",
      "0          PLSRegression_3  471.770215  17.905627\n",
      "1  RandomForestRegressor_3  549.619096  18.994356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple models to show ranking functionality\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"🚀 Testing multiple models for comprehensive ranking...\")\n",
    "\n",
    "# Create pipeline with multiple models\n",
    "multi_model_pipeline = [\n",
    "    MinMaxScaler(),\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\"n_components\": 3},\n",
    "        \"train_params\": {\"verbose\": 1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Add another configuration with RandomForest\n",
    "multi_model_pipeline_2 = [\n",
    "    MinMaxScaler(),\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "    {\n",
    "        \"model\": RandomForestRegressor,\n",
    "        \"model_params\": {\"n_estimators\": 50, \"random_state\": 42},\n",
    "        \"train_params\": {\"verbose\": 1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Add Ridge regression\n",
    "multi_model_pipeline_3 = [\n",
    "    MinMaxScaler(),\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "    {\n",
    "        \"model\": Ridge,\n",
    "        \"model_params\": {\"alpha\": 1.0},\n",
    "        \"train_params\": {\"verbose\": 1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create configs for all three models\n",
    "config_pls = PipelineConfigs(multi_model_pipeline)\n",
    "config_rf = PipelineConfigs(multi_model_pipeline_2)\n",
    "config_ridge = PipelineConfigs(multi_model_pipeline_3)\n",
    "\n",
    "print(\"🏃 Running multiple models...\")\n",
    "for i, (config, name) in enumerate([(config_pls, \"PLS\"), (config_rf, \"RandomForest\"), (config_ridge, \"Ridge\")], 1):\n",
    "    print(f\"\\n=== Running Model {i}: {name} ===\")\n",
    "    runner = PipelineRunner()\n",
    "    results = runner.run(config, dataset_config_test)\n",
    "\n",
    "    if i == 1:\n",
    "        # Store the first result for comparison\n",
    "        first_dataset = results[0][0]\n",
    "    else:\n",
    "        # Merge predictions from other models into first dataset for comparison\n",
    "        current_dataset = results[0][0]\n",
    "        for key, pred_data in current_dataset._predictions._predictions.items():\n",
    "            first_dataset._predictions._predictions[key] = pred_data\n",
    "\n",
    "print(\"\\n🏆 Final Multi-Model Comparison:\")\n",
    "print(\"=====================================\")\n",
    "first_dataset._predictions.print_best_scores_summary()\n",
    "\n",
    "print(\"\\n📊 Detailed Scores DataFrame:\")\n",
    "detailed_scores = first_dataset._predictions.get_all_scores_summary()\n",
    "print(detailed_scores[['model', 'mse', 'mae']].sort_values('mse'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
