{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f89073",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f7d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded pipeline(s) with 8 configuration(s).\n",
      "========================================================================================================================================================================================================\n",
      "‚úÖ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94müöÄ Starting pipeline config_4edac1e9 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[94müîÑ Running 5 steps in sequential mode\u001b[0m\n",
      "\u001b[92müî∑ Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', 'params': {'feature_range': [0.1, 0.8]}, '_runtime_instance': MinMaxScaler(feature_range=(0.1, 0.8))}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "üíæ Saved file: 1_0_MinMaxScaler_1.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 2: {'feature_augmentation': ['sklearn.preprocessing._data.StandardScaler', ['nirs4all.operators.transformations.signal.Gaussian', 'sklearn.preprocessing._data.StandardScaler'], ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']]}\u001b[0m\n",
      "üîπ Executing controller FeatureAugmentationController without operator\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator StandardScaler\n",
      "üíæ Saved file: 2_1_0_StandardScaler_2.pkl\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: ['nirs4all.operators.transformations.signal.Gaussian', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[94müîÑ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.3: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Gaussian\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.4: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[94müîÑ Running 2 steps in sequential mode\u001b[0m\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   ‚ñ∂ Sub-step 2.2: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator StandardScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "üîπ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "üíæ Saved file: 3_folds_ShuffleSplit.csv\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}}\u001b[0m\n",
      "üîπ Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "üíæ Saved file: 4_MinMaxScaler_numeric_MinMaxScaler3.pkl\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 1}}}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator PLSRegression\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[91m‚ùå Pipeline config_4edac1e9 on dataset regression failed: \n",
      "Pipeline step failed: 'dict' object has no attribute 'fit'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 240, in run_step\n",
      "    return self._execute_controller(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 292, in _execute_controller\n",
      "    context, binaries = controller.execute(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_model.py\", line 204, in execute\n",
      "    return super().execute(step, operator, dataset, context, runner, source, mode, loaded_binaries)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py\", line 211, in execute\n",
      "    return self._execute_training_mode(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py\", line 259, in _execute_training_mode\n",
      "    return self._execute_cross_validation(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py\", line 1357, in _execute_cross_validation\n",
      "    fold_context, fold_binaries = self._execute_train(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py\", line 1409, in _execute_train\n",
      "    trained_model = self._train_model(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_model.py\", line 112, in _train_model\n",
      "    trained_model.fit(X_train, y_train.ravel())  # Ensure y is 1D for sklearn\n",
      "AttributeError: 'dict' object has no attribute 'fit'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 240, in run_step\n",
      "    return self._execute_controller(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 292, in _execute_controller\n",
      "    context, binaries = controller.execute(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_model.py\", line 204, in execute\n",
      "    return super().execute(step, operator, dataset, context, runner, source, mode, loaded_binaries)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py\", line 211, in execute\n",
      "    return self._execute_training_mode(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py\", line 259, in _execute_training_mode\n",
      "    return self._execute_cross_validation(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py\", line 1357, in _execute_cross_validation\n",
      "    fold_context, fold_binaries = self._execute_train(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py\", line 1409, in _execute_train\n",
      "    trained_model = self._train_model(\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_model.py\", line 112, in _train_model\n",
      "    trained_model.fit(X_train, y_train.ravel())  # Ensure y is 1D for sklearn\n",
      "AttributeError: 'dict' object has no attribute 'fit'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 106, in _run_single\n",
      "    self.run_steps(steps, dataset, context, execution=\"sequential\")\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 146, in run_steps\n",
      "    context = self.run_step(step, dataset, context, is_substep=is_substep)\n",
      "  File \"D:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py\", line 255, in run_step\n",
      "    raise RuntimeError(f\"Pipeline step failed: {str(e)}\") from e\n",
      "RuntimeError: Pipeline step failed: 'dict' object has no attribute 'fit'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Pipeline step failed: 'dict' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:240\u001b[0m, in \u001b[0;36mPipelineRunner.run_step\u001b[1;34m(self, step, dataset, context, is_substep)\u001b[0m\n\u001b[0;32m    239\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_controller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_binaries\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# self.history.complete_step(step_execution.step_id)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:292\u001b[0m, in \u001b[0;36mPipelineRunner._execute_controller\u001b[1;34m(self, controller, step, operator, dataset, context, source, loaded_binaries)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîπ Executing controller \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontroller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m without operator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 292\u001b[0m context, binaries \u001b[38;5;241m=\u001b[39m \u001b[43mcontroller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloaded_binaries\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# Save binaries if in training mode and saving is enabled\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_model.py:204\u001b[0m, in \u001b[0;36mSklearnModelController.execute\u001b[1;34m(self, step, operator, dataset, context, runner, source, mode, loaded_binaries)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# print(f\"üî¨ Executing sklearn model controller\")\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Call parent execute method\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_binaries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py:211\u001b[0m, in \u001b[0;36mBaseModelController.execute\u001b[1;34m(self, step, operator, dataset, context, runner, source, mode, loaded_binaries)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Training/finetuning mode - original logic\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_training_mode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py:259\u001b[0m, in \u001b[0;36mBaseModelController._execute_training_mode\u001b[1;34m(self, step, operator, dataset, context, runner)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;66;03m# Standard cross-validation without finetuning\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_cross_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinetune_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# Single training mode: no folds\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py:1357\u001b[0m, in \u001b[0;36mBaseModelController._execute_cross_validation\u001b[1;34m(self, model_config, data_splits, train_params, finetune_params, mode, context, runner, dataset)\u001b[0m\n\u001b[0;32m   1355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1356\u001b[0m     \u001b[38;5;66;03m# Train for this fold\u001b[39;00m\n\u001b[1;32m-> 1357\u001b[0m     fold_context, fold_binaries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_idx\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;66;03m# Add fold suffix to binary names\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\models\\base_model_controller.py:1409\u001b[0m, in \u001b[0;36mBaseModelController._execute_train\u001b[1;34m(self, model_config, X_train, y_train, X_test, y_test, train_params, context, runner, dataset, fold_idx)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;66;03m# print(X_train_prep.shape, y_train_prep.shape, X_test_prep.shape, y_test.shape)\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \n\u001b[0;32m   1408\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m-> 1409\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_prep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_prep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_params\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\controllers\\sklearn\\op_model.py:112\u001b[0m, in \u001b[0;36mSklearnModelController._train_model\u001b[1;34m(self, model, X_train, y_train, X_val, y_val, train_params)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[43mtrained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m(X_train, y_train\u001b[38;5;241m.\u001b[39mravel())  \u001b[38;5;66;03m# Ensure y is 1D for sklearn\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_model\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'fit'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m dataset_config_obj \u001b[38;5;241m=\u001b[39m DatasetConfigs(path)\n\u001b[0;32m     54\u001b[0m runner \u001b[38;5;241m=\u001b[39m PipelineRunner()\n\u001b[1;32m---> 55\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_config_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# print(f\"Pipeline execution completed! Got {len(results)} results\")\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# for i, (ds, hist, _) in enumerate(results):\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# print(f\"Result {i+1}: {ds.name}\")\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:80\u001b[0m, in \u001b[0;36mPipelineRunner.run\u001b[1;34m(self, pipeline_configs, dataset_configs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset_configs\u001b[38;5;241m.\u001b[39mget_dataset(d_config)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m steps, config_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pipeline_configs\u001b[38;5;241m.\u001b[39msteps, pipeline_configs\u001b[38;5;241m.\u001b[39mnames):\n\u001b[1;32m---> 80\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:106\u001b[0m, in \u001b[0;36mPipelineRunner._run_single\u001b[1;34m(self, steps, config_name, dataset)\u001b[0m\n\u001b[0;32m    103\u001b[0m context \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m: [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m*\u001b[39m dataset\u001b[38;5;241m.\u001b[39mfeatures_sources(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequential\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# Save enhanced configuration with metadata if saving binaries\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_binaries:\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:146\u001b[0m, in \u001b[0;36mPipelineRunner.run_steps\u001b[1;34m(self, steps, dataset, context, execution, is_substep)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(context, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# print(\"üîÑ Running steps sequentially with shared context\")\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m--> 146\u001b[0m         context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_substep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_substep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;66;03m# print(f\"üîπ Updated context after step: {context}\")\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubstep_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Reset sub-step number after sequential execution\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:255\u001b[0m, in \u001b[0;36mPipelineRunner.run_step\u001b[1;34m(self, step, dataset, context, is_substep)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è Step failed but continuing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline step failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_substep:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Pipeline step failed: 'dict' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from nirs4all.operators.transformations import Gaussian, SavitzkyGolay, StandardNormalVariate, Haar\n",
    "from nirs4all.pipeline.config import PipelineConfigs\n",
    "from nirs4all.dataset.dataset_config import DatasetConfigs\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "import json\n",
    "\n",
    "pipeline = [\n",
    "    # Normalize the spectra reflectance\n",
    "    MinMaxScaler(feature_range=(0.1, 0.8)),\n",
    "\n",
    "    # Generate 10 version of feature augmentation combinations (3 elements with size 1 to 2, ie. [SG, [SNV, GS], Haar])\n",
    "    # {\n",
    "    #     \"feature_augmentation\": {\n",
    "    #         \"_or_\": [\n",
    "    #             Gaussian, StandardNormalVariate, SavitzkyGolay, Haar,\n",
    "    #         ],\n",
    "    #         \"size\": [3, (1,2)],\n",
    "    #         \"count\": 2,\n",
    "    #     }\n",
    "    # },\n",
    "\n",
    "    # Split the dataset in train and validation\n",
    "    # ShuffleSplit(n_splits=3, test_size=.25),\n",
    "\n",
    "    # Normalize the y values\n",
    "    {\"y_processing\": MinMaxScaler()},\n",
    "\n",
    "    # PLS regression with 1 to 60 components\n",
    "    {\n",
    "        \"model\": PLSRegression,\n",
    "        \"model_params\": {\n",
    "            \"n_components\": {\n",
    "                \"_range_\": [1, 4],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# create pipeline config\n",
    "config = PipelineConfigs(pipeline)\n",
    "\n",
    "# print(config.has_configurations)\n",
    "# print(config)\n",
    "# print(PipelineConfigs.value_of_str(config.steps, \"n_components\"))\n",
    "\n",
    "path = ['../../sample_data/regression', '../../sample_data/classification', '../../sample_data/binary']\n",
    "# # path = '../../sample_data/regression'\n",
    "dataset_config_obj = DatasetConfigs(path)\n",
    "\n",
    "runner = PipelineRunner()\n",
    "results = runner.run(config, dataset_config_obj)\n",
    "\n",
    "# print(f\"Pipeline execution completed! Got {len(results)} results\")\n",
    "# for i, (ds, hist, _) in enumerate(results):\n",
    "    # print(f\"Result {i+1}: {ds.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe592e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Dataset does not have data for train_group.\n",
      "‚ö†Ô∏è Dataset does not have data for test_group.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mLoading dataset:\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "‚ö†Ô∏è Dataset does not have data for train_group.\n",
      "‚ö†Ô∏è Dataset does not have data for test_group.\n",
      "\u001b[97müìä Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw'], min=-0.265, max=1.436, mean=0.466, var=0.149)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw']: 130 samples\n",
      "- \"test\", ['raw']: 59 samples\u001b[0m\n",
      "regression\n",
      "Pipeline execution completed! Got 0 results\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
