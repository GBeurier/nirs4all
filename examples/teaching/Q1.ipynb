{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f7d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting pipeline run with 1 pipeline configuration(s) on 1 dataset configuration(s) (1 total runs).\n",
      "========================================================================================================================================================================================================\n",
      "‚úÖ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "üì• Loaded 2075 predictions from results\\regression\\regression_predictions.json\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94müöÄ Starting pipeline config_pipeline_Q1_803cf8 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "üîπ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "üîÑ TransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 2: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}}\u001b[0m\n",
      "üîπ Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "üîÑ YTransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 3: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}\u001b[0m\n",
      "üîπ Executing controller SklearnModelController with operator PLSRegression\n",
      "üîÑ SklearnModel (test: (59, 1)) (PLSRegression)\n",
      "[DEBUG] Model config: {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10), 'model_instance': PLSRegression(n_components=10)}\n",
      "[DEBUG] CV config: CVConfig(mode=<CVMode.SIMPLE: 'simple'>, param_strategy=<ParamStrategy.PER_FOLD_BEST: 'per_fold_best'>, inner_cv=None, outer_cv=None, use_full_train_for_final=False, n_folds=5)\n",
      "‚úÖ PLSRegression - test: mse=0.0109‚Üì (mae: 0.0838) (train:59)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92müî∑ Step 4: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "üîπ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "üèÜ Best for config: UnknownModel_3 - mse=173.8910‚Üì\n",
      "\u001b[94m‚úÖ Pipeline config_pipeline_Q1_803cf8 completed successfully on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "üèÜ Best from this run: UnknownModel_3 (pipeline_Q1_803cf8) - mse=173.8910‚Üì\n",
      "ü•á Best overall: UnknownModel_17_fold2 (pipeline_Q1_37a0d0) - mse=0.0073‚Üì\n",
      "üìä Tab report saved: best_score_report_UnknownModel_fold2.csv\n",
      "|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|-----------------|\n",
      "|          | Nsample  | Nfeature | Mean     | Median   | Min      | Max      | SD       | CV       | R¬≤       | RMSE     | MSE      | SEP      | MAE      | RPD      | Bias     | Q-Value  | Consistency (%) |\n",
      "|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|-----------------|\n",
      "| Cros Val |          | 2151     |          |          |          |          |          |          |          |          |          |          |          |          |          |          |                 |\n",
      "| Train    |          |          |          |          |          |          |          |          |          |          |          |          |          |          |          |          |                 |\n",
      "| Test     | 708      |          | 31.762   | 27.110   | 1.330    | 84.570   | 19.805   | 0.624    | -0.221   | 21.882   | 478.839  | 21.018   | 16.828   | 0.94     | -6.088   |          | 67.7            |\n",
      "|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|-----------------|\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "from nirs4all.operators.transformations import *\n",
    "from nirs4all.pipeline import PipelineConfigs, PipelineRunner\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from nirs4all.operators.models.cirad_tf import nicon\n",
    "\n",
    "x_scaler = MinMaxScaler() # StandardScaler(), RobustScaler(), QuantileTransformer(), PowerTransformer(), LogTransform()\n",
    "y_scaler = MinMaxScaler()\n",
    "list_of_preprocessors = [ Detrend, FirstDerivative, SecondDerivative, Gaussian, StandardNormalVariate, SavitzkyGolay, Haar, MultiplicativeScatterCorrection]\n",
    "splitting_strategy = ShuffleSplit(n_splits=3, test_size=.25)\n",
    "dataset_folder = '../../sample_data/regression'\n",
    "\n",
    "pipeline = [\n",
    "    # \"chart_2d\",\n",
    "    x_scaler,\n",
    "    # \"chart_3d\",\n",
    "    {\"y_processing\": y_scaler},\n",
    "    # {\"feature_augmentation\": { \"_or_\": list_of_preprocessors, \"size\":[1,(1,2)], \"count\":5 }}, # Generate all elements of size 1 and of order 1 or 2 (ie. \"Gaussian\", [\"SavitzkyGolay\", \"Log\"], etc.)\n",
    "    # {\"model\": nicon}, # Initial model to compare with\n",
    "    PLSRegression(n_components=10),\n",
    "    splitting_strategy,\n",
    "    # PLSRegression(n_components=10)\n",
    "]\n",
    "\n",
    "for i in range(10, 30, 10):\n",
    "    model = {\n",
    "        \"name\": f\"PLS-{i}_cp\",\n",
    "        \"model\": PLSRegression(n_components=i)\n",
    "    }\n",
    "    pipeline.append(model)\n",
    "\n",
    "pipeline_config = PipelineConfigs(pipeline, \"pipeline_Q1\")\n",
    "dataset_config = DatasetConfigs(dataset_folder)\n",
    "\n",
    "# Create pipeline with verbose=1 to see debug output\n",
    "runner = PipelineRunner(save_files=True, verbose=0)\n",
    "run_predictions, other_predictions = runner.run(pipeline_config, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "from nirs4all.operators.transformations import *\n",
    "from nirs4all.pipeline import PipelineConfigs, PipelineRunner\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from nirs4all.operators.models.cirad_tf import nicon\n",
    "\n",
    "x_scaler = MinMaxScaler() # StandardScaler(), RobustScaler(), QuantileTransformer(), PowerTransformer(), LogTransform()\n",
    "y_scaler = MinMaxScaler()\n",
    "list_of_preprocessors = [ Detrend, FirstDerivative, SecondDerivative, Gaussian, StandardNormalVariate, SavitzkyGolay, Haar, MultiplicativeScatterCorrection]\n",
    "splitting_strategy = ShuffleSplit(n_splits=3, test_size=.25)\n",
    "dataset_folder = '../../sample_data/regression'\n",
    "\n",
    "pipeline = [\n",
    "    # \"chart_2d\",\n",
    "    x_scaler,\n",
    "    # \"chart_3d\",\n",
    "    {\"y_processing\": y_scaler},\n",
    "    {\"feature_augmentation\": { \"_or_\": list_of_preprocessors, \"size\":[1,(1,2)], \"count\":5 }}, # Generate all elements of size 1 and of order 1 or 2 (ie. \"Gaussian\", [\"SavitzkyGolay\", \"Log\"], etc.)\n",
    "    # {\"model\": nicon}, # Initial model to compare with\n",
    "    splitting_strategy,\n",
    "]\n",
    "\n",
    "for i in range(10, 30, 10):\n",
    "    model = {\n",
    "        \"name\": f\"PLS-{i}_cp\",\n",
    "        \"model\": PLSRegression(n_components=i)\n",
    "    }\n",
    "    pipeline.append(model)\n",
    "\n",
    "pipeline_config = PipelineConfigs(pipeline, \"pipeline_Q1\")\n",
    "dataset_config = DatasetConfigs(dataset_folder)\n",
    "\n",
    "# Create pipeline with verbose=1 to see debug output\n",
    "runner = PipelineRunner(save_files=True, verbose=1)\n",
    "run_predictions, other_predictions = runner.run(pipeline_config, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nirs4all.dataset.prediction_analyzer import PredictionAnalyzer\n",
    "\n",
    "analyzer = PredictionAnalyzer(run_predictions)\n",
    "\n",
    "# Get top models to verify the real model names are displayed correctly\n",
    "top_10 = analyzer.get_top_k(10, 'mse')\n",
    "print(f\"Top 10 models by MSE:\")\n",
    "for i, model in enumerate(top_10, 1):\n",
    "    real_model = model.get('real_model', 'unknown')\n",
    "    enhanced_name = model.get('enhanced_model_name', 'unknown')\n",
    "    pipeline_path = model.get('path', '')\n",
    "\n",
    "    # Extract config ID from pipeline path\n",
    "    config_id = \"unknown\"\n",
    "    if 'config_' in pipeline_path:\n",
    "        config_part = pipeline_path.split('config_')[1].split('/')[0] if '/' in pipeline_path else pipeline_path.split('config_')[1]\n",
    "        config_id = f\"config_{config_part}\"\n",
    "\n",
    "    print(f\"{i}. Real: {real_model} | Config: {config_id} | RMSE: {model['metrics']['rmse']:.6f} | MSE: {model['metrics']['mse']:.6f} | R¬≤: {model['metrics']['r2']:.6f} | Enhanced: {enhanced_name}\")\n",
    "\n",
    "# Plot comparison with enhanced names (for readability in plots)\n",
    "# fig = analyzer.plot_top_k_comparison(k=3, metric='rmse', partition_type='test')\n",
    "# plt.show()\n",
    "\n",
    "# PLS-20_cp_step6_w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "from nirs4all.operators.transformations import *\n",
    "from nirs4all.pipeline import PipelineConfigs, PipelineRunner\n",
    "\n",
    "x_scaler = MinMaxScaler() # StandardScaler(), RobustScaler(), QuantileTransformer(), PowerTransformer(), LogTransform()\n",
    "list_of_preprocessors = [ Detrend, FirstDerivative, SecondDerivative, Gaussian, StandardNormalVariate, SavitzkyGolay, Haar, MultiplicativeScatterCorrection]\n",
    "splitting_strategy = ShuffleSplit(n_splits=3, test_size=.25)\n",
    "dataset_folder = '../../sample_data/classification'\n",
    "\n",
    "pipeline = [\n",
    "    \"chart_2d\",\n",
    "    x_scaler,\n",
    "    \"chart_3d\",\n",
    "    {\"feature_augmentation\": { \"_or_\": list_of_preprocessors, \"size\":[1,(1,2)], \"count\":5 }}, # Generate all elements of size 1 and of order 1 or 2 (ie. \"Gaussian\", [\"SavitzkyGolay\", \"Log\"], etc.)\n",
    "    splitting_strategy,\n",
    "]\n",
    "\n",
    "for i in range(5, 20, 5):\n",
    "    model = {\n",
    "        \"name\": f\"RF-depth-{i}\",\n",
    "        \"model\": RandomForestClassifier(max_depth=i)\n",
    "    }\n",
    "    pipeline.append(model)\n",
    "\n",
    "pipeline_config = PipelineConfigs(pipeline, \"pipeline_Q1\")\n",
    "dataset_config = DatasetConfigs(dataset_folder)\n",
    "\n",
    "# Create pipeline\n",
    "runner = PipelineRunner(save_files=False)\n",
    "run_predictions, other_predictions = runner.run(pipeline_config, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nirs4all.dataset.prediction_analyzer import PredictionAnalyzer\n",
    "\n",
    "analyzer = PredictionAnalyzer(run_predictions)\n",
    "\n",
    "top_5 = analyzer.get_top_k(5, 'accuracy')\n",
    "for i, model in enumerate(top_5, 1):\n",
    "    # Use enhanced_model_name which includes custom names when available\n",
    "    enhanced_name = model.get('enhanced_model_name', model.get('real_model', 'unknown'))\n",
    "    # canonical_name = model.get('canonical_model', 'unknown')\n",
    "    pipeline_path = model.get('path', '')\n",
    "\n",
    "    # Extract config ID from pipeline path or key\n",
    "    config_id = \"unknown\"\n",
    "    if 'config_' in pipeline_path:\n",
    "        config_part = pipeline_path.split('config_')[1].split('/')[0] if '/' in pipeline_path else pipeline_path.split('config_')[1]\n",
    "        config_id = f\"config_{config_part}\"\n",
    "\n",
    "    print(f\"{i}. {enhanced_name} - {config_id} - Accuracy: {model['metrics']['accuracy']:.6f}, F1: {model['metrics']['f1']:.6f}, Precision: {model['metrics']['precision']:.6f}, Recall: {model['metrics']['recall']:.6f}\")\n",
    "\n",
    "# Plot top_k comparison with enhanced names in titles\n",
    "fig = analyzer.plot_top_k_confusionMatrix(k=3, metric='accuracy', partition_type='test')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
