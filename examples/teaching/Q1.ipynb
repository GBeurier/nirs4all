{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "from nirs4all.operators.transformations import *\n",
    "from nirs4all.pipeline import PipelineConfigs, PipelineRunner\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "x_scaler = MinMaxScaler() # StandardScaler(), RobustScaler(), QuantileTransformer(), PowerTransformer(), LogTransform()\n",
    "y_scaler = MinMaxScaler()\n",
    "list_of_preprocessors = [ Detrend, FirstDerivative, SecondDerivative, Gaussian, StandardNormalVariate, SavitzkyGolay, Haar, MultiplicativeScatterCorrection]\n",
    "splitting_strategy = ShuffleSplit(n_splits=3, test_size=.25)\n",
    "dataset_folder = '../../sample_data/regression'\n",
    "\n",
    "pipeline = [\n",
    "    # \"chart_2d\",\n",
    "    x_scaler,\n",
    "    # \"chart_3d\",\n",
    "    {\"y_processing\": y_scaler},\n",
    "    {\"feature_augmentation\": { \"_or_\": list_of_preprocessors, \"size\":[1,(1,2)], \"count\":5 }}, # Generate all elements of size 1 and of order 1 or 2 (ie. \"Gaussian\", [\"SavitzkyGolay\", \"Log\"], etc.)\n",
    "    splitting_strategy,\n",
    "]\n",
    "\n",
    "for i in range(10, 30, 10):\n",
    "    model = {\n",
    "        \"name\": f\"PLS-{i}_cp\",\n",
    "        \"model\": PLSRegression(n_components=i)\n",
    "    }\n",
    "    pipeline.append(model)\n",
    "\n",
    "pipeline_config = PipelineConfigs(pipeline, \"pipeline_Q1\")\n",
    "dataset_config = DatasetConfigs(dataset_folder)\n",
    "\n",
    "# Create pipeline\n",
    "runner = PipelineRunner(save_files=True)\n",
    "run_predictions, other_predictions = runner.run(pipeline_config, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nirs4all.dataset.prediction_analyzer import PredictionAnalyzer\n",
    "\n",
    "analyzer = PredictionAnalyzer(run_predictions)\n",
    "\n",
    "top_5 = analyzer.get_top_k(5, 'mse')\n",
    "for i, model in enumerate(top_5, 1):\n",
    "    # Use enhanced_model_name which includes custom names when available\n",
    "    enhanced_name = model.get('enhanced_model_name', model.get('real_model', 'unknown'))\n",
    "    pipeline_path = model.get('path', '')\n",
    "\n",
    "    # Extract config ID from pipeline path or key\n",
    "    config_id = \"unknown\"\n",
    "    if 'config_' in pipeline_path:\n",
    "        config_part = pipeline_path.split('config_')[1].split('/')[0] if '/' in pipeline_path else pipeline_path.split('config_')[1]\n",
    "        config_id = f\"config_{config_part}\"\n",
    "\n",
    "    print(f\"{i}. {enhanced_name} - {config_id} - RMSE: {model['metrics']['rmse']:.6f}, RÂ²: {model['metrics']['r2']:.6f}, MAE: {model['metrics']['mae']:.6f}, MSE: {model['metrics']['mse']:.6f}\")\n",
    "\n",
    "# Plot top_k comparison with enhanced names in titles\n",
    "fig = analyzer.plot_top_k_comparison(k=3, metric='rmse', partition_type='test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7229fa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting pipeline run with 5 pipeline configuration(s) on 1 dataset configuration(s) (5 total runs).\n",
      "========================================================================================================================================================================================================\n",
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "ğŸ“¥ Loaded 135 predictions from results\\classification\\classification_predictions.json\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_pipeline_Q1_c96199 on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 1: chart_2d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 2: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 3: chart_3d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 4: {'feature_augmentation': ['nirs4all.operators.transformations.nirs.Haar']}\u001b[0m\n",
      "ğŸ”¹ Executing controller FeatureAugmentationController without operator\n",
      "ğŸ”„ FeatureAugmentation â ‹\u001b[96m   â–¶ Sub-step 4.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator Haar\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 5: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 6: {'name': 'RF-depth-5', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 5}, '_runtime_instance': RandomForestClassifier(max_depth=5)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-5_3 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-5_6 - test: accuracy=0.3333â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-5_9 - test: accuracy=0.1667â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 7: {'name': 'RF-depth-10', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 10}, '_runtime_instance': RandomForestClassifier(max_depth=10)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-10_12 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-10_15 - test: accuracy=0.3333â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-10_18 - test: accuracy=0.1667â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 8: {'name': 'RF-depth-15', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 15}, '_runtime_instance': RandomForestClassifier(max_depth=15)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-15_21 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-15_24 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-15_27 - test: accuracy=0.1667â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best for config: RF-depth-5_6 - accuracy=0.3333â†‘\n",
      "\u001b[94mâœ… Pipeline config_pipeline_Q1_c96199 completed successfully on dataset classification\u001b[0m\n",
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_pipeline_Q1_3a3e47 on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 1: chart_2d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 2: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 3: chart_3d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 4: {'feature_augmentation': [['nirs4all.operators.transformations.nirs.SecondDerivative', 'nirs4all.operators.transformations.signal.Detrend']]}\u001b[0m\n",
      "ğŸ”¹ Executing controller FeatureAugmentationController without operator\n",
      "ğŸ”„ FeatureAugmentation â ‹\u001b[96m   â–¶ Sub-step 4.1: ['nirs4all.operators.transformations.nirs.SecondDerivative', 'nirs4all.operators.transformations.signal.Detrend']\u001b[0m\n",
      "\u001b[96m   â–¶ Sub-step 4.2: nirs4all.operators.transformations.nirs.SecondDerivative\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator SecondDerivative\n",
      "\u001b[96m   â–¶ Sub-step 4.3: nirs4all.operators.transformations.signal.Detrend\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator Detrend\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 5: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 6: {'name': 'RF-depth-5', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 5}, '_runtime_instance': RandomForestClassifier(max_depth=5)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-5_4 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-5_7 - test: accuracy=0.0833â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-5_10 - test: accuracy=0.1667â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 7: {'name': 'RF-depth-10', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 10}, '_runtime_instance': RandomForestClassifier(max_depth=10)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-10_13 - test: accuracy=0.1667â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-10_16 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-10_19 - test: accuracy=0.2500â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 8: {'name': 'RF-depth-15', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 15}, '_runtime_instance': RandomForestClassifier(max_depth=15)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¹âœ… RF-depth-15_22 - test: accuracy=0.3333â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-15_25 - test: accuracy=0.1667â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ´âœ… RF-depth-15_28 - test: accuracy=0.0833â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best for config: RF-depth-15_22 - accuracy=0.3333â†‘\n",
      "\u001b[94mâœ… Pipeline config_pipeline_Q1_3a3e47 completed successfully on dataset classification\u001b[0m\n",
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_pipeline_Q1_27170e on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 1: chart_2d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 2: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 3: chart_3d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 4: {'feature_augmentation': [['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Detrend']]}\u001b[0m\n",
      "ğŸ”¹ Executing controller FeatureAugmentationController without operator\n",
      "ğŸ”„ FeatureAugmentation â ‹\u001b[96m   â–¶ Sub-step 4.1: ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Detrend']\u001b[0m\n",
      "\u001b[96m   â–¶ Sub-step 4.2: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   â–¶ Sub-step 4.3: nirs4all.operators.transformations.signal.Detrend\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator Detrend\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 5: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 6: {'name': 'RF-depth-5', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 5}, '_runtime_instance': RandomForestClassifier(max_depth=5)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-5_4 - test: accuracy=0.4167â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-5_7 - test: accuracy=0.0833â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-5_10 - test: accuracy=0.2500â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 7: {'name': 'RF-depth-10', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 10}, '_runtime_instance': RandomForestClassifier(max_depth=10)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-10_13 - test: accuracy=0.3333â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-10_16 - test: accuracy=0.0833â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-10_19 - test: accuracy=0.2500â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 8: {'name': 'RF-depth-15', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 15}, '_runtime_instance': RandomForestClassifier(max_depth=15)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-15_22 - test: accuracy=0.3333â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-15_25 - test: accuracy=0.1667â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-15_28 - test: accuracy=0.2500â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best for config: RF-depth-5_4 - accuracy=0.4167â†‘\n",
      "\u001b[94mâœ… Pipeline config_pipeline_Q1_27170e completed successfully on dataset classification\u001b[0m\n",
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_pipeline_Q1_d88df0 on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 1: chart_2d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 2: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 3: chart_3d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 4: {'feature_augmentation': [['nirs4all.operators.transformations.nirs.FirstDerivative', 'nirs4all.operators.transformations.nirs.SecondDerivative']]}\u001b[0m\n",
      "ğŸ”¹ Executing controller FeatureAugmentationController without operator\n",
      "ğŸ”„ FeatureAugmentation â ‹\u001b[96m   â–¶ Sub-step 4.1: ['nirs4all.operators.transformations.nirs.FirstDerivative', 'nirs4all.operators.transformations.nirs.SecondDerivative']\u001b[0m\n",
      "\u001b[96m   â–¶ Sub-step 4.2: nirs4all.operators.transformations.nirs.FirstDerivative\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator FirstDerivative\n",
      "\u001b[96m   â–¶ Sub-step 4.3: nirs4all.operators.transformations.nirs.SecondDerivative\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator SecondDerivative\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 5: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 6: {'name': 'RF-depth-5', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 5}, '_runtime_instance': RandomForestClassifier(max_depth=5)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-5_4 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-5_7 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-5_10 - test: accuracy=0.4167â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 7: {'name': 'RF-depth-10', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 10}, '_runtime_instance': RandomForestClassifier(max_depth=10)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-10_13 - test: accuracy=0.1667â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-10_16 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-10_19 - test: accuracy=0.2500â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 8: {'name': 'RF-depth-15', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 15}, '_runtime_instance': RandomForestClassifier(max_depth=15)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-15_22 - test: accuracy=0.3333â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-15_25 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-15_28 - test: accuracy=0.3333â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best for config: RF-depth-5_10 - accuracy=0.4167â†‘\n",
      "\u001b[94mâœ… Pipeline config_pipeline_Q1_d88df0 completed successfully on dataset classification\u001b[0m\n",
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_pipeline_Q1_d13ea9 on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 1: chart_2d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 2: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 3: chart_3d\u001b[0m\n",
      "ğŸ”¹ Executing controller SpectraChartController without operator\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 4: {'feature_augmentation': [['nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', 'sklearn.preprocessing._data.StandardScaler']]}\u001b[0m\n",
      "ğŸ”¹ Executing controller FeatureAugmentationController without operator\n",
      "ğŸ”„ FeatureAugmentation â ‹\u001b[96m   â–¶ Sub-step 4.1: ['nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[96m   â–¶ Sub-step 4.2: nirs4all.operators.transformations.nirs.MultiplicativeScatterCorrection\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator MultiplicativeScatterCorrection\n",
      "\u001b[96m   â–¶ Sub-step 4.3: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator StandardScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 5: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 6: {'name': 'RF-depth-5', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 5}, '_runtime_instance': RandomForestClassifier(max_depth=5)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-5_4 - test: accuracy=0.1667â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-5_7 - test: accuracy=0.1667â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ´âœ… RF-depth-5_10 - test: accuracy=0.1667â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 7: {'name': 'RF-depth-10', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 10}, '_runtime_instance': RandomForestClassifier(max_depth=10)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-10_13 - test: accuracy=0.2500â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-10_16 - test: accuracy=0.1667â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-10_19 - test: accuracy=0.1667â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 8: {'name': 'RF-depth-15', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'max_depth': 15}, '_runtime_instance': RandomForestClassifier(max_depth=15)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ™âœ… RF-depth-15_22 - test: accuracy=0.1667â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¸âœ… RF-depth-15_25 - test: accuracy=0.1667â†‘\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ¼âœ… RF-depth-15_28 - test: accuracy=0.0833â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best for config: RF-depth-10_13 - accuracy=0.2500â†‘\n",
      "\u001b[94mâœ… Pipeline config_pipeline_Q1_d13ea9 completed successfully on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best from this run: RF-depth-5 (pipeline_Q1_27170e) - accuracy=0.4167â†‘\n",
      "ğŸ¥‡ Best overall: RF-depth-15 (pipeline_Q1_2ba45f) - accuracy=0.5833â†‘\n",
      "ğŸ“Š Tab report saved: best_score_report_RF-depth-15_28.csv\n",
      "|----------|----------|-----------|----------|-----------|----------|----------|-------------|----------|\n",
      "|          | Nsample  | Nfeatures | Accuracy | Precision | Recall   | F1-score | Specificity | AUC      |\n",
      "|----------|----------|-----------|----------|-----------|----------|----------|-------------|----------|\n",
      "| Cros Val | 360      |           | 0.225    | 0.165     | 0.225    | 0.183    |             |          |\n",
      "| Train    | 1080     |           | 1.000    | 1.000     | 1.000    | 1.000    |             |          |\n",
      "| Test     | 360      |           | 0.225    | 0.165     | 0.225    | 0.183    |             |          |\n",
      "|----------|----------|-----------|----------|-----------|----------|----------|-------------|----------|\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "from nirs4all.operators.transformations import *\n",
    "from nirs4all.pipeline import PipelineConfigs, PipelineRunner\n",
    "\n",
    "x_scaler = MinMaxScaler() # StandardScaler(), RobustScaler(), QuantileTransformer(), PowerTransformer(), LogTransform()\n",
    "list_of_preprocessors = [ Detrend, FirstDerivative, SecondDerivative, Gaussian, StandardNormalVariate, SavitzkyGolay, Haar, MultiplicativeScatterCorrection]\n",
    "splitting_strategy = ShuffleSplit(n_splits=3, test_size=.25)\n",
    "dataset_folder = '../../sample_data/classification'\n",
    "\n",
    "pipeline = [\n",
    "    \"chart_2d\",\n",
    "    x_scaler,\n",
    "    \"chart_3d\",\n",
    "    {\"feature_augmentation\": { \"_or_\": list_of_preprocessors, \"size\":[1,(1,2)], \"count\":5 }}, # Generate all elements of size 1 and of order 1 or 2 (ie. \"Gaussian\", [\"SavitzkyGolay\", \"Log\"], etc.)\n",
    "    splitting_strategy,\n",
    "]\n",
    "\n",
    "for i in range(5, 20, 5):\n",
    "    model = {\n",
    "        \"name\": f\"RF-depth-{i}\",\n",
    "        \"model\": RandomForestClassifier(max_depth=i)\n",
    "    }\n",
    "    pipeline.append(model)\n",
    "\n",
    "pipeline_config = PipelineConfigs(pipeline, \"pipeline_Q1\")\n",
    "dataset_config = DatasetConfigs(dataset_folder)\n",
    "\n",
    "# Create pipeline\n",
    "runner = PipelineRunner(save_files=False)\n",
    "run_predictions, other_predictions = runner.run(pipeline_config, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nirs4all.dataset.prediction_analyzer import PredictionAnalyzer\n",
    "\n",
    "analyzer = PredictionAnalyzer(run_predictions)\n",
    "\n",
    "top_5 = analyzer.get_top_k(5, 'accuracy')\n",
    "for i, model in enumerate(top_5, 1):\n",
    "    # Use enhanced_model_name which includes custom names when available\n",
    "    enhanced_name = model.get('enhanced_model_name', model.get('real_model', 'unknown'))\n",
    "    # canonical_name = model.get('canonical_model', 'unknown')\n",
    "    pipeline_path = model.get('path', '')\n",
    "\n",
    "    # Extract config ID from pipeline path or key\n",
    "    config_id = \"unknown\"\n",
    "    if 'config_' in pipeline_path:\n",
    "        config_part = pipeline_path.split('config_')[1].split('/')[0] if '/' in pipeline_path else pipeline_path.split('config_')[1]\n",
    "        config_id = f\"config_{config_part}\"\n",
    "\n",
    "    print(f\"{i}. {enhanced_name} - {config_id} - Accuracy: {model['metrics']['accuracy']:.6f}, F1: {model['metrics']['f1']:.6f}, Precision: {model['metrics']['precision']:.6f}, Recall: {model['metrics']['recall']:.6f}\")\n",
    "\n",
    "# Plot top_k comparison with enhanced names in titles\n",
    "fig = analyzer.plot_top_k_confusionMatrix(k=3, metric='accuracy', partition_type='test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2514ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing tab report generation with dataset information...\n",
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "Test dataset name: classification\n",
      "Error with selector 'all': 'str' object has no attribute 'items'\n",
      "Error with selector 'train': 'str' object has no attribute 'items'\n",
      "Error with selector 'test': 'str' object has no attribute 'items'\n",
      "Dataset x('0') type: <class 'numpy.ndarray'>\n",
      "Dataset x('0') shape: (66, 2152)\n",
      "With selector '0' - N_samples: 66, N_features: 2152\n",
      "Extracted n_features: 2152\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed tab report generation\n",
    "print(\"ğŸ§ª Testing tab report generation with dataset information...\")\n",
    "\n",
    "# Let's reload the module to get the updated code\n",
    "import importlib\n",
    "import nirs4all.utils.tab_report_generator\n",
    "importlib.reload(nirs4all.utils.tab_report_generator)\n",
    "\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "\n",
    "# Get dataset config\n",
    "dataset_config = DatasetConfigs('../../sample_data/classification')\n",
    "config, name = list(dataset_config.configs)[0]\n",
    "test_dataset = dataset_config.get_dataset(config, name)\n",
    "\n",
    "print(f\"Test dataset name: {test_dataset.name}\")\n",
    "\n",
    "# Test different selectors to see what works\n",
    "for selector in ['all', 'train', 'test', 0]:\n",
    "    try:\n",
    "        x_data = test_dataset.x(selector)\n",
    "        print(f\"Dataset x('{selector}') type: {type(x_data)}\")\n",
    "        print(f\"Dataset x('{selector}') shape: {getattr(x_data, 'shape', 'no shape')}\")\n",
    "        if hasattr(x_data, 'shape'):\n",
    "            print(f\"With selector '{selector}' - N_samples: {x_data.shape[0]}, N_features: {x_data.shape[1] if len(x_data.shape) > 1 else x_data.shape[0]}\")\n",
    "            break  # Found working selector\n",
    "    except Exception as e:\n",
    "        print(f\"Error with selector '{selector}': {e}\")\n",
    "\n",
    "# Test our extraction function\n",
    "from nirs4all.utils.tab_report_generator import TabReportGenerator\n",
    "generator = TabReportGenerator()\n",
    "nfeatures = generator._extract_nfeatures_from_dataset(test_dataset)\n",
    "print(f\"Extracted n_features: {nfeatures}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c72baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Running complete tab report test...\n",
      "Running pipeline with tab reports enabled...\n",
      "ğŸš€ Starting pipeline run with 1 pipeline configuration(s) on 1 dataset configuration(s) (1 total runs).\n",
      "========================================================================================================================================================================================================\n",
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "ğŸ“¥ Loaded 270 predictions from results\\classification\\classification_predictions.json\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_test_pipeline_e371bb on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 2: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 2, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=2, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 2 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 3: {'name': 'RF-test', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'n_estimators': 10, 'max_depth': 5}, '_runtime_instance': RandomForestClassifier(max_depth=5, n_estimators=10)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ‹âœ… RF-test_2 - test: accuracy=0.1667â†‘\n",
      "âœ… RF-test_5 - test: accuracy=0.1667â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best for config: RF-test_2 - accuracy=0.1667â†‘\n",
      "\u001b[94mâœ… Pipeline config_test_pipeline_e371bb completed successfully on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best from this run: RF-test (test_pipeline_e371bb) - accuracy=0.1667â†‘\n",
      "ğŸ¥‡ Best overall: RF-depth-15 (pipeline_Q1_2ba45f) - accuracy=0.5833â†‘\n",
      "ğŸ“Š Tab report saved: best_score_report_RF-depth-15_28.csv\n",
      "|----------|----------|-----------|----------|-----------|----------|----------|-------------|----------|\n",
      "|          | Nsample  | Nfeatures | Accuracy | Precision | Recall   | F1-score | Specificity | AUC      |\n",
      "|----------|----------|-----------|----------|-----------|----------|----------|-------------|----------|\n",
      "| Cros Val | 360      |           | 0.225    | 0.165     | 0.225    | 0.183    | 0.909       |          |\n",
      "| Train    | 1080     |           | 1.000    | 1.000     | 1.000    | 1.000    | 1.000       |          |\n",
      "| Test     | 360      |           | 0.225    | 0.165     | 0.225    | 0.183    | 0.909       |          |\n",
      "|----------|----------|-----------|----------|-----------|----------|----------|-------------|----------|\n",
      "========================================================================================================================\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test a complete tab report generation with the fixes\n",
    "print(\"ğŸ§ª Running complete tab report test...\")\n",
    "\n",
    "# Reload all relevant modules\n",
    "import importlib\n",
    "import nirs4all.pipeline.runner\n",
    "import nirs4all.utils.tab_report_generator\n",
    "importlib.reload(nirs4all.utils.tab_report_generator)\n",
    "importlib.reload(nirs4all.pipeline.runner)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "from nirs4all.operators.transformations import *\n",
    "from nirs4all.pipeline import PipelineConfigs, PipelineRunner\n",
    "\n",
    "# Create a minimal test configuration\n",
    "x_scaler = MinMaxScaler()\n",
    "splitting_strategy = ShuffleSplit(n_splits=2, test_size=.25)  # Reduced splits for faster test\n",
    "dataset_folder = '../../sample_data/classification'\n",
    "\n",
    "pipeline = [\n",
    "    x_scaler,\n",
    "    splitting_strategy,\n",
    "    {\n",
    "        \"name\": \"RF-test\",\n",
    "        \"model\": RandomForestClassifier(max_depth=5, n_estimators=10)  # Small model for speed\n",
    "    }\n",
    "]\n",
    "\n",
    "pipeline_config = PipelineConfigs(pipeline, \"test_pipeline\")\n",
    "dataset_config = DatasetConfigs(dataset_folder)\n",
    "\n",
    "# Create pipeline with tab reports enabled\n",
    "print(\"Running pipeline with tab reports enabled...\")\n",
    "runner = PipelineRunner(save_files=False, enable_tab_reports=True)\n",
    "test_predictions, test_results = runner.run(pipeline_config, dataset_config)\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Best model details:\n",
      "  Model name: RF-test_2\n",
      "  Canonical model: RF-test\n",
      "  Real model: RF-test_2\n",
      "  Path: results\\classification\\config_test_pipeline_e371bb\n",
      "\n",
      "ğŸ” Current test dataset info:\n",
      "  Dataset name: classification\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check what the best model selection is finding\n",
    "from nirs4all.dataset.prediction_analyzer import PredictionAnalyzer\n",
    "\n",
    "# Get the current predictions and see what the best model analysis produces\n",
    "analyzer = PredictionAnalyzer(test_predictions)\n",
    "top_1 = analyzer.get_top_k(1, 'accuracy', partition_type='test')\n",
    "\n",
    "if top_1:\n",
    "    best_model = top_1[0]\n",
    "    print(\"ğŸ” Best model details:\")\n",
    "    print(f\"  Model name: {best_model.get('enhanced_model_name', 'unknown')}\")\n",
    "    print(f\"  Canonical model: {best_model.get('canonical_model', 'unknown')}\")\n",
    "    print(f\"  Real model: {best_model.get('real_model', 'unknown')}\")\n",
    "    print(f\"  Path: {best_model.get('path', 'unknown')}\")\n",
    "\n",
    "    # Check the most recent dataset we used\n",
    "    print(f\"\\nğŸ” Current test dataset info:\")\n",
    "    print(f\"  Dataset name: {test_dataset.name if 'test_dataset' in locals() else 'not available'}\")\n",
    "\n",
    "    # Check if the dataset passed to the tab generator would be the correct one\n",
    "    # The issue might be that the best model is from a previous run,\n",
    "    # but we're passing the current dataset which might not match\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b16128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "Testing feature extraction with dataset: classification\n",
      "Extracted n_features: 2152\n",
      "Testing with runner's dataset approach...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the updated feature extraction with fresh dataset approach\n",
    "import importlib\n",
    "import nirs4all.utils.tab_report_generator\n",
    "importlib.reload(nirs4all.utils.tab_report_generator)\n",
    "\n",
    "from nirs4all.utils.tab_report_generator import TabReportGenerator\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "\n",
    "# Test with the classification dataset\n",
    "dataset_config = DatasetConfigs('../../sample_data/classification')\n",
    "config, name = list(dataset_config.configs)[0]\n",
    "test_dataset = dataset_config.get_dataset(config, name)\n",
    "\n",
    "print(f\"Testing feature extraction with dataset: {test_dataset.name}\")\n",
    "\n",
    "generator = TabReportGenerator()\n",
    "nfeatures = generator._extract_nfeatures_from_dataset(test_dataset)\n",
    "print(f\"Extracted n_features: {nfeatures}\")\n",
    "\n",
    "# Now test with a potentially modified dataset (simulating the runner scenario)\n",
    "# Get the current runner's last dataset if available\n",
    "if 'runner' in locals():\n",
    "    print(\"Testing with runner's dataset approach...\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4eb9ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing tab report with updated feature extraction...\n",
      "Running final test with updated tab report generation...\n",
      "ğŸš€ Starting pipeline run with 1 pipeline configuration(s) on 1 dataset configuration(s) (1 total runs).\n",
      "========================================================================================================================================================================================================\n",
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "ğŸ“¥ Loaded 276 predictions from results\\classification\\classification_predictions.json\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_final_test_pipeline_b16c6b on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 2: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 1, 'test_size': 0.3}, '_runtime_instance': ShuffleSplit(n_splits=1, random_state=None, test_size=0.3, train_size=None)}\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 1 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 3: {'name': 'RF-final-test', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'n_estimators': 5, 'max_depth': 3}, '_runtime_instance': RandomForestClassifier(max_depth=3, n_estimators=5)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ‹âœ… RF-final-test_2 - test: accuracy=0.3333â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best for config: RF-final-test_2 - accuracy=0.3333â†‘\n",
      "\u001b[94mâœ… Pipeline config_final_test_pipeline_b16c6b completed successfully on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best from this run: RF-final-test (final_test_pipeline) - accuracy=0.3333â†‘\n",
      "ğŸ¥‡ Best overall: RF-depth-15 (pipeline_Q1_2ba45f) - accuracy=0.5833â†‘\n",
      "ğŸ“Š Tab report saved: best_score_report_RF-depth-15_28.csv\n",
      "|----------|----------|-----------|----------|-----------|----------|----------|-------------|----------|\n",
      "|          | Nsample  | Nfeatures | Accuracy | Precision | Recall   | F1-score | Specificity | AUC      |\n",
      "|----------|----------|-----------|----------|-----------|----------|----------|-------------|----------|\n",
      "| Cros Val | 360      |           | 0.225    | 0.165     | 0.225    | 0.183    | 0.909       |          |\n",
      "| Train    | 1080     |           | 1.000    | 1.000     | 1.000    | 1.000    | 1.000       |          |\n",
      "| Test     | 360      |           | 0.225    | 0.165     | 0.225    | 0.183    | 0.909       |          |\n",
      "|----------|----------|-----------|----------|-----------|----------|----------|-------------|----------|\n",
      "========================================================================================================================\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run another test to see if nfeatures now appears in the tab report\n",
    "print(\"ğŸ§ª Testing tab report with updated feature extraction...\")\n",
    "\n",
    "# Reload the pipeline runner to get the latest changes\n",
    "import importlib\n",
    "import nirs4all.pipeline.runner\n",
    "importlib.reload(nirs4all.pipeline.runner)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from nirs4all.dataset import DatasetConfigs\n",
    "from nirs4all.operators.transformations import *\n",
    "from nirs4all.pipeline import PipelineConfigs, PipelineRunner\n",
    "\n",
    "# Create another small test\n",
    "x_scaler = MinMaxScaler()\n",
    "splitting_strategy = ShuffleSplit(n_splits=1, test_size=.3)  # Single split\n",
    "dataset_folder = '../../sample_data/classification'\n",
    "\n",
    "pipeline = [\n",
    "    x_scaler,\n",
    "    splitting_strategy,\n",
    "    {\n",
    "        \"name\": \"RF-final-test\",\n",
    "        \"model\": RandomForestClassifier(max_depth=3, n_estimators=5)  # Very small for speed\n",
    "    }\n",
    "]\n",
    "\n",
    "pipeline_config = PipelineConfigs(pipeline, \"final_test_pipeline\")\n",
    "dataset_config = DatasetConfigs(dataset_folder)\n",
    "\n",
    "# Run with tab reports\n",
    "print(\"Running final test with updated tab report generation...\")\n",
    "runner = PipelineRunner(save_files=False, enable_tab_reports=True)\n",
    "final_predictions, final_results = runner.run(pipeline_config, dataset_config)\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2733dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing with clean predictions (no cached results)...\n",
      "Moved existing predictions to backup\n",
      "Running clean pipeline...\n",
      "ğŸš€ Starting pipeline run with 1 pipeline configuration(s) on 1 dataset configuration(s) (1 total runs).\n",
      "========================================================================================================================================================================================================\n",
      "âœ… Loaded dataset 'classification' with 48 training and 18 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94mğŸš€ Starting pipeline config_clean_test_ef1549 on dataset classification\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "ğŸ”¹ Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 2: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 1, 'test_size': 0.3}, '_runtime_instance': ShuffleSplit(n_splits=1, random_state=None, test_size=0.3, train_size=None)}\u001b[0m\n",
      "ğŸ”¹ Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 1 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92mğŸ”· Step 3: {'name': 'RF-clean-test', 'model': {'class': 'sklearn.ensemble._forest.RandomForestClassifier', 'params': {'n_estimators': 10, 'max_depth': 5}, '_runtime_instance': RandomForestClassifier(max_depth=5, n_estimators=10)}}\u001b[0m\n",
      "ğŸ”¹ Executing controller SklearnModelController with operator RandomForestClassifier\n",
      "ğŸ”„ SklearnModel (RandomForestClassifier) â ‹âœ… RF-clean-test_2 - test: accuracy=0.2667â†‘\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best for config: RF-clean-test_2 - accuracy=0.2667â†‘\n",
      "\u001b[94mâœ… Pipeline config_clean_test_ef1549 completed successfully on dataset classification\u001b[0m\n",
      "Restored predictions from backup\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'merge_predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning clean pipeline...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PipelineRunner(save_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, enable_tab_reports\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, load_existing_predictions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 49\u001b[0m     clean_predictions, clean_results \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Restore backup\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(backup_path):\n",
      "File \u001b[1;32mD:\\Workspace\\ML\\NIRS\\nirs4all\\nirs4all\\pipeline\\runner.py:103\u001b[0m, in \u001b[0;36mPipelineRunner.run\u001b[1;34m(self, pipeline_configs, dataset_configs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_single(steps, config_name, dataset)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# results.append(result)\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m dataset_pred_db\u001b[38;5;241m.\u001b[39mmerge_predictions(dataset\u001b[38;5;241m.\u001b[39m_predictions)\n\u001b[0;32m    104\u001b[0m run_dataset_pred_db\u001b[38;5;241m.\u001b[39mmerge_predictions(dataset\u001b[38;5;241m.\u001b[39m_predictions)\n\u001b[0;32m    105\u001b[0m global_pred_db\u001b[38;5;241m.\u001b[39mmerge_predictions(dataset\u001b[38;5;241m.\u001b[39m_predictions)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'merge_predictions'"
     ]
    }
   ],
   "source": [
    "# Let's try a clean run without loading existing predictions\n",
    "print(\"ğŸ§ª Testing with clean predictions (no cached results)...\")\n",
    "\n",
    "# Reload runner with the fix\n",
    "import importlib\n",
    "import nirs4all.pipeline.runner\n",
    "importlib.reload(nirs4all.pipeline.runner)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Backup and temporarily remove existing predictions\n",
    "predictions_path = 'results/classification/classification_predictions.json'\n",
    "backup_path = 'results/classification/classification_predictions_backup.json'\n",
    "\n",
    "if os.path.exists(predictions_path):\n",
    "    shutil.move(predictions_path, backup_path)\n",
    "    print(f\"Moved existing predictions to backup\")\n",
    "\n",
    "try:\n",
    "    # Now run without existing predictions\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "    from nirs4all.dataset import DatasetConfigs\n",
    "    from nirs4all.operators.transformations import *\n",
    "    from nirs4all.pipeline import PipelineConfigs, PipelineRunner\n",
    "\n",
    "    x_scaler = MinMaxScaler()\n",
    "    splitting_strategy = ShuffleSplit(n_splits=1, test_size=.3)\n",
    "    dataset_folder = '../../sample_data/classification'\n",
    "\n",
    "    pipeline = [\n",
    "        x_scaler,\n",
    "        splitting_strategy,\n",
    "        {\n",
    "            \"name\": \"RF-clean-test\",\n",
    "            \"model\": RandomForestClassifier(max_depth=5, n_estimators=10)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    pipeline_config = PipelineConfigs(pipeline, \"clean_test\")\n",
    "    dataset_config = DatasetConfigs(dataset_folder)\n",
    "\n",
    "    # Run fresh\n",
    "    print(\"Running clean pipeline...\")\n",
    "    runner = PipelineRunner(save_files=False, enable_tab_reports=True, load_existing_predictions=False)\n",
    "    clean_predictions, clean_results = runner.run(pipeline_config, dataset_config)\n",
    "\n",
    "finally:\n",
    "    # Restore backup\n",
    "    if os.path.exists(backup_path):\n",
    "        shutil.move(backup_path, predictions_path)\n",
    "        print(f\"Restored predictions from backup\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
