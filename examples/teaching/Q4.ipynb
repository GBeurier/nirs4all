{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed6e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Cleared old results to ensure fresh training\n",
      "✅ Loaded pipeline(s) with 5 configuration(s).\n",
      "========================================================================================================================================================================================================\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_7145413d on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1'], min=0.0, max=1.128, mean=0.801, var=0.033)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': ['nirs4all.operators.transformations.signal.Gaussian', ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.Haar'], ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation ⠋\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "\u001b[96m   ▶ Sub-step 2.2: ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.Haar']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.3: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.4: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   ▶ Sub-step 2.2: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_Gaussian_2'], min=-0.033, max=0.034, mean=-0.0, var=0.0)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_Gaussian_2']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_Gaussian_2']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_Gaussian_2'], min=-0.033, max=0.034, mean=-0.0, var=0.0)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_Gaussian_2']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_Gaussian_2']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_Gaussian_2'], min=-0.033, max=0.034, mean=-0.0, var=0.0)\n",
      "Targets: (samples=189, targets=1, processings=['numeric', 'numeric_MinMaxScaler3'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "- numeric_MinMaxScaler3: min=-0.006, max=1.0, mean=0.228\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_Gaussian_2']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_Gaussian_2']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (PLSRegression) ⠋✅ PLSRegression_4 - test: mse=0.0219↓ (mae: 0.1249)\n",
      "✅ PLSRegression_7 - test: mse=0.0400↓ (mae: 0.1468)\n",
      "✅ PLSRegression_10 - test: mse=0.0181↓ (mae: 0.1146)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: fold (config_7145413d) - mse=287.9639↓\n",
      "\u001b[94m✅ Pipeline config_7145413d completed successfully on dataset regression\u001b[0m\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_a08494a0 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1'], min=0.0, max=1.128, mean=0.801, var=0.033)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': ['sklearn.preprocessing._data.StandardScaler', ['nirs4all.operators.transformations.signal.Gaussian', 'sklearn.preprocessing._data.StandardScaler'], ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Gaussian']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation ⠋\u001b[96m   ▶ Sub-step 2.1: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.2: ['nirs4all.operators.transformations.signal.Gaussian', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.3: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "\u001b[96m   ▶ Sub-step 2.4: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Gaussian']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_StandardScaler_2'], min=-6.489, max=2.151, mean=0.064, var=0.793)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_StandardScaler_2']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_StandardScaler_2']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_StandardScaler_2'], min=-6.489, max=2.151, mean=0.064, var=0.793)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_StandardScaler_2']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_StandardScaler_2']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_StandardScaler_2'], min=-6.489, max=2.151, mean=0.064, var=0.793)\n",
      "Targets: (samples=189, targets=1, processings=['numeric', 'numeric_MinMaxScaler3'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "- numeric_MinMaxScaler3: min=-0.006, max=1.0, mean=0.228\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_StandardScaler_2']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_StandardScaler_2']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (PLSRegression) ⠋✅ PLSRegression_4 - test: mse=0.0199↓ (mae: 0.1079)\n",
      "✅ PLSRegression_7 - test: mse=0.0149↓ (mae: 0.0991)\n",
      "✅ PLSRegression_10 - test: mse=0.0169↓ (mae: 0.1090)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: fold (config_a08494a0) - mse=236.9133↓\n",
      "\u001b[94m✅ Pipeline config_a08494a0 completed successfully on dataset regression\u001b[0m\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_c59b49ed on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1'], min=0.0, max=1.128, mean=0.801, var=0.033)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': [['nirs4all.operators.transformations.signal.Gaussian', 'sklearn.preprocessing._data.StandardScaler'], ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.SavitzkyGolay'], ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation ⠋\u001b[96m   ▶ Sub-step 2.1: ['nirs4all.operators.transformations.signal.Gaussian', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "\u001b[96m   ▶ Sub-step 2.3: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.SavitzkyGolay']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   ▶ Sub-step 2.2: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_Gaussian_2_StandardScaler_3'], min=-6.24, max=5.967, mean=-0.019, var=0.947)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_Gaussian_2_StandardScaler_3']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_Gaussian_2_StandardScaler_3']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_Gaussian_2_StandardScaler_3'], min=-6.24, max=5.967, mean=-0.019, var=0.947)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_Gaussian_2_StandardScaler_3']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_Gaussian_2_StandardScaler_3']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_Gaussian_2_StandardScaler_3'], min=-6.24, max=5.967, mean=-0.019, var=0.947)\n",
      "Targets: (samples=189, targets=1, processings=['numeric', 'numeric_MinMaxScaler4'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "- numeric_MinMaxScaler4: min=-0.006, max=1.0, mean=0.228\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_Gaussian_2_StandardScaler_3']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_Gaussian_2_StandardScaler_3']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (PLSRegression) ⠋✅ PLSRegression_5 - test: mse=0.0200↓ (mae: 0.1135)\n",
      "✅ PLSRegression_8 - test: mse=0.0276↓ (mae: 0.1208)\n",
      "✅ PLSRegression_11 - test: mse=0.0203↓ (mae: 0.1103)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: fold (config_c59b49ed) - mse=319.3122↓\n",
      "\u001b[94m✅ Pipeline config_c59b49ed completed successfully on dataset regression\u001b[0m\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_533c9c31 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1'], min=0.0, max=1.128, mean=0.801, var=0.033)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': [['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.SavitzkyGolay'], ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'nirs4all.operators.transformations.nirs.Haar'], ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Gaussian']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation ⠋\u001b[96m   ▶ Sub-step 2.1: ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.SavitzkyGolay']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.2: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.3: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'nirs4all.operators.transformations.nirs.Haar']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Gaussian']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_StandardScaler_2_SavitzkyGolay_3'], min=-6.489, max=2.151, mean=0.064, var=0.793)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_StandardScaler_2_SavitzkyGolay_3']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_StandardScaler_2_SavitzkyGolay_3']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_StandardScaler_2_SavitzkyGolay_3'], min=-6.489, max=2.151, mean=0.064, var=0.793)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_StandardScaler_2_SavitzkyGolay_3']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_StandardScaler_2_SavitzkyGolay_3']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_StandardScaler_2_SavitzkyGolay_3'], min=-6.489, max=2.151, mean=0.064, var=0.793)\n",
      "Targets: (samples=189, targets=1, processings=['numeric', 'numeric_MinMaxScaler4'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "- numeric_MinMaxScaler4: min=-0.006, max=1.0, mean=0.228\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_StandardScaler_2_SavitzkyGolay_3']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_StandardScaler_2_SavitzkyGolay_3']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (PLSRegression) ⠋✅ PLSRegression_5 - test: mse=0.0189↓ (mae: 0.1034)\n",
      "✅ PLSRegression_8 - test: mse=0.0142↓ (mae: 0.0998)\n",
      "✅ PLSRegression_11 - test: mse=0.0187↓ (mae: 0.1049)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: fold (config_533c9c31) - mse=225.8209↓\n",
      "\u001b[94m✅ Pipeline config_533c9c31 completed successfully on dataset regression\u001b[0m\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_d69b2949 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1'], min=0.0, max=1.128, mean=0.801, var=0.033)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': ['sklearn.preprocessing._data.StandardScaler', ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.signal.Gaussian'], ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.SavitzkyGolay']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation ⠋\u001b[96m   ▶ Sub-step 2.1: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.2: ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.signal.Gaussian']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.3: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.4: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.SavitzkyGolay']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_StandardScaler_2'], min=-6.489, max=2.151, mean=0.064, var=0.793)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_StandardScaler_2']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_StandardScaler_2']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_StandardScaler_2'], min=-6.489, max=2.151, mean=0.064, var=0.793)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_StandardScaler_2']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_StandardScaler_2']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_1_StandardScaler_2'], min=-6.489, max=2.151, mean=0.064, var=0.793)\n",
      "Targets: (samples=189, targets=1, processings=['numeric', 'numeric_MinMaxScaler3'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "- numeric_MinMaxScaler3: min=-0.006, max=1.0, mean=0.228\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_1_StandardScaler_2']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_1_StandardScaler_2']: 59 samples\n",
      "Folds: [(97, 33), (97, 33), (97, 33)]\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (PLSRegression) ⠋✅ PLSRegression_4 - test: mse=0.0146↓ (mae: 0.0986)\n",
      "✅ PLSRegression_7 - test: mse=0.0227↓ (mae: 0.1244)\n",
      "✅ PLSRegression_10 - test: mse=0.0145↓ (mae: 0.0928)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: fold (config_d69b2949) - mse=231.8504↓\n",
      "\u001b[94m✅ Pipeline config_d69b2949 completed successfully on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best from this run: fold (config_533c9c31_PLSRegression_8_test) - mse=225.8209↓\n",
      "🥇 Best overall: fold (config_533c9c31_PLSRegression_8_test) - mse=225.8209↓\n",
      "\n",
      "=== TRAINING METADATA CHECK ===\n",
      "Step binaries tracked: 5 steps\n",
      "Sample step binaries: {'1_0': ['1_0_MinMaxScaler_1.pkl'], '2_1': ['2_1_0_StandardScaler_2.pkl'], '3_0': ['3_folds_ShuffleSplit.csv']}\n",
      "\n",
      "=== TOP 5 RESULTS ===\n",
      "1. results\\regression\\config_533c9c31 - RMSE: 15.027338, R²: 0.505548, MAE: 12.599274 ✅\n",
      "2. results\\regression\\config_d69b2949 - RMSE: 15.226635, R²: 0.467121, MAE: 11.715890 ✅\n",
      "3. results\\regression\\config_d69b2949 - RMSE: 15.237708, R²: 0.710659, MAE: 12.448704 ✅\n",
      "4. results\\regression\\config_a08494a0 - RMSE: 15.391987, R²: -0.246827, MAE: 12.506934 ✅\n",
      "5. results\\regression\\config_a08494a0 - RMSE: 16.420442, R²: 0.277163, MAE: 13.758281 ✅\n",
      "\n",
      "=== TESTING PREDICTION ===\n",
      "Using best model from: results\\regression\\config_533c9c31\n",
      "✅ Loaded pipeline(s) with 1 configuration(s).\n",
      "📦 Available binaries for 11 operations across 6 steps\n",
      "========================================================================================================================================================================================================\n",
      "📥 Loaded 15 predictions from results\\regression\\regression_predictions.json\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_533c9c31 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler'}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[97mUpdate: 📊 Dataset: regression\n",
      "Features (samples=189, sources=1):\n",
      "- Source 0: (189, 1, 2151), processings=['raw_MinMaxScaler_pred'], min=0.0, max=1.128, mean=0.801, var=0.033)\n",
      "Targets: (samples=189, targets=1, processings=['numeric'])\n",
      "- numeric: min=1.33, max=128.31, mean=30.779\n",
      "Indexes:\n",
      "- \"train\", ['raw_MinMaxScaler_pred']: 130 samples\n",
      "- \"test\", ['raw_MinMaxScaler_pred']: 59 samples\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': [['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.SavitzkyGolay'], ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'nirs4all.operators.transformations.nirs.Haar'], ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Gaussian']]}\u001b[0m\n",
      "🔄 Skipping step 2 in prediction mode\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}}\u001b[0m\n",
      "Type mismatch: <class 'float'> != <class 'NoneType'>\n",
      "🔄 Skipping step 3 in prediction mode\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔄 Skipping step 4 in prediction mode\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🎯 Using all available data for prediction\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: 1 (config_533c9c31) - mse=1439.4390↓\n",
      "\u001b[94m✅ Pipeline config_533c9c31 completed successfully on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best from this run: 1 (config_533c9c31_PLSRegression) - mse=1439.4390↓\n",
      "🥇 Best overall: fold (config_533c9c31_PLSRegression_8_test) - mse=225.8209↓\n",
      "✅ Prediction completed successfully\n",
      "✅ Prediction successful!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from nirs4all.operators.transformations import Gaussian, SavitzkyGolay, StandardNormalVariate, Haar\n",
    "from nirs4all.pipeline.config import PipelineConfigs\n",
    "from nirs4all.dataset.dataset_config import DatasetConfigs\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from nirs4all.dataset.prediction_visualizer import PredictionVisualizer\n",
    "\n",
    "# Clear old results to ensure fresh training with metadata\n",
    "results_path = Path(\"./results\")\n",
    "if results_path.exists():\n",
    "    shutil.rmtree(results_path)\n",
    "    print(\"🧹 Cleared old results to ensure fresh training\")\n",
    "\n",
    "pipeline = [\n",
    "    # Normalize the spectra reflectance\n",
    "    MinMaxScaler(),\n",
    "\n",
    "    # Generate 5 version of feature augmentation combinations (3 elements with size 1 to 2, ie. [SG, [SNV, GS], Haar])\n",
    "    {\n",
    "        \"feature_augmentation\": {\n",
    "            \"_or_\": [\n",
    "                Gaussian, StandardNormalVariate, SavitzkyGolay, Haar,\n",
    "            ],\n",
    "            \"size\": [3, (1,2)],\n",
    "            \"count\": 5,\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Split the dataset in train and validation\n",
    "    ShuffleSplit(n_splits=3, test_size=.25),\n",
    "\n",
    "    # Normalize the y values\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "    {\"model\": PLSRegression(10)},\n",
    "]\n",
    "\n",
    "p_configs = PipelineConfigs(pipeline)\n",
    "\n",
    "# path = ['../../sample_data/regression', '../../sample_data/classification', '../../sample_data/binary']\n",
    "path = '../../sample_data/regression'\n",
    "d_configs = DatasetConfigs(path)\n",
    "\n",
    "# Train with explicit settings to ensure metadata is saved\n",
    "runner = PipelineRunner(save_files=True, verbose=0)  # Set verbose=0 to reduce output\n",
    "predictions, results = runner.run(p_configs, d_configs)\n",
    "\n",
    "print(f\"\\n=== TRAINING METADATA CHECK ===\")\n",
    "print(f\"Step binaries tracked: {len(runner.step_binaries)} steps\")\n",
    "print(f\"Sample step binaries: {dict(list(runner.step_binaries.items())[:3])}\")\n",
    "\n",
    "visualizer = PredictionVisualizer(predictions, dataset_name_override=\"dataset\")\n",
    "top_5 = visualizer.get_top_k(5, 'rmse') ##TODO get_top_1\n",
    "\n",
    "print(f\"\\n=== TOP 5 RESULTS ===\")\n",
    "for i, model in enumerate(top_5, 1):\n",
    "    print(f\"{i}. {model['path']} - RMSE: {model['rmse']:.6f}, R²: {model['r2']:.6f}, MAE: {model['mae']:.6f} {'✅' if has_metadata else '❌'}\")\n",
    "\n",
    "print(f\"\\n=== TESTING PREDICTION ===\")\n",
    "best_path = top_5[0]['path']\n",
    "print(f\"Using best model from: {best_path}\")\n",
    "\n",
    "try:\n",
    "    predictions = PipelineRunner.predict(\n",
    "        path=best_path,\n",
    "        dataset=d_configs,\n",
    "        # model=my_model,##TODO\n",
    "        best_model=False,##TODO quand on veut prédire sur tous les modèles\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"✅ Prediction successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Prediction failed: {e}\")\n",
    "    # Show which step failed\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f00386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 5 RESULTS ===\n",
      "1. results\\regression\\config_533c9c31 - RMSE: 15.027338, R²: 0.505548, MAE: 12.599274 ✅\n",
      "2. results\\regression\\config_d69b2949 - RMSE: 15.226635, R²: 0.467121, MAE: 11.715890 ✅\n",
      "3. results\\regression\\config_d69b2949 - RMSE: 15.237708, R²: 0.710659, MAE: 12.448704 ✅\n",
      "4. results\\regression\\config_a08494a0 - RMSE: 15.391987, R²: -0.246827, MAE: 12.506934 ✅\n",
      "5. results\\regression\\config_a08494a0 - RMSE: 16.420442, R²: 0.277163, MAE: 13.758281 ✅\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n=== TOP 5 RESULTS ===\")\n",
    "for i, model in enumerate(top_5, 1):\n",
    "    print(f\"{i}. {model['path']} - RMSE: {model['rmse']:.6f}, R²: {model['r2']:.6f}, MAE: {model['mae']:.6f} {'✅' if has_metadata else '❌'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
