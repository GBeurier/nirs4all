{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed6e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Cleared old results to ensure fresh training\n",
      "🚀 Starting pipeline run with 5 pipeline configuration(s) on 1 dataset configuration(s) (5 total runs).\n",
      "========================================================================================================================================================================================================\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_92995c02 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "🔄 TransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.Haar', ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.nirs.SavitzkyGolay']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation\n",
      "\u001b[96m   ▶ Sub-step 2.1: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "🔄 TransformerMixin (StandardScaler)\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "\u001b[96m   ▶ Sub-step 2.3: ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.nirs.SavitzkyGolay']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.4: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "\u001b[96m   ▶ Sub-step 2.5: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "🔄 TransformerMixin (SavitzkyGolay)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "🔄 YTransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (test: (59, 1)) (PLSRegression)\n",
      "[DEBUG] Model config: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}, 'model_instance': PLSRegression(n_components=10)}\n",
      "[DEBUG] CV config: CVConfig(mode=<CVMode.SIMPLE: 'simple'>, param_strategy=<ParamStrategy.PER_FOLD_BEST: 'per_fold_best'>, inner_cv=None, outer_cv=None, use_full_train_for_final=False, n_folds=5)\n",
      "✅ PLSRegression_fold0 - test: mse=0.0107↓ (mae: 0.0852) (fold:0)\n",
      "✅ PLSRegression_fold1 - test: mse=0.0112↓ (mae: 0.0834) (fold:1)\n",
      "✅ PLSRegression_fold2 - test: mse=0.0126↓ (mae: 0.0872) (fold:2)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: UnknownModel_4_fold0 - mse=0.0107↓\n",
      "\u001b[94m✅ Pipeline config_92995c02 completed successfully on dataset regression\u001b[0m\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_3c49bc04 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "🔄 TransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': [['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.signal.Gaussian'], ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'nirs4all.operators.transformations.nirs.Haar'], ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation\n",
      "\u001b[96m   ▶ Sub-step 2.1: ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.signal.Gaussian']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.2: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "🔄 TransformerMixin (StandardScaler)\n",
      "\u001b[96m   ▶ Sub-step 2.3: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "🔄 TransformerMixin (Gaussian)\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.SavitzkyGolay', 'nirs4all.operators.transformations.nirs.Haar']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "🔄 TransformerMixin (SavitzkyGolay)\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "\u001b[96m   ▶ Sub-step 2.2: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "🔄 TransformerMixin (StandardScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "🔄 YTransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (test: (59, 1)) (PLSRegression)\n",
      "[DEBUG] Model config: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}, 'model_instance': PLSRegression(n_components=10)}\n",
      "[DEBUG] CV config: CVConfig(mode=<CVMode.SIMPLE: 'simple'>, param_strategy=<ParamStrategy.PER_FOLD_BEST: 'per_fold_best'>, inner_cv=None, outer_cv=None, use_full_train_for_final=False, n_folds=5)\n",
      "✅ PLSRegression_fold0 - test: mse=0.0133↓ (mae: 0.0916) (fold:0)\n",
      "✅ PLSRegression_fold1 - test: mse=0.0159↓ (mae: 0.0981) (fold:1)\n",
      "✅ PLSRegression_fold2 - test: mse=0.0130↓ (mae: 0.0882) (fold:2)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: UnknownModel_11_fold2 - mse=0.0130↓\n",
      "\u001b[94m✅ Pipeline config_3c49bc04 completed successfully on dataset regression\u001b[0m\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_95e3259a on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "🔄 TransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.Haar', ['nirs4all.operators.transformations.signal.Gaussian', 'nirs4all.operators.transformations.nirs.Haar']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation\n",
      "\u001b[96m   ▶ Sub-step 2.1: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "🔄 TransformerMixin (StandardScaler)\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "\u001b[96m   ▶ Sub-step 2.3: ['nirs4all.operators.transformations.signal.Gaussian', 'nirs4all.operators.transformations.nirs.Haar']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.4: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "🔄 TransformerMixin (Gaussian)\n",
      "\u001b[96m   ▶ Sub-step 2.5: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "🔄 YTransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (test: (59, 1)) (PLSRegression)\n",
      "[DEBUG] Model config: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}, 'model_instance': PLSRegression(n_components=10)}\n",
      "[DEBUG] CV config: CVConfig(mode=<CVMode.SIMPLE: 'simple'>, param_strategy=<ParamStrategy.PER_FOLD_BEST: 'per_fold_best'>, inner_cv=None, outer_cv=None, use_full_train_for_final=False, n_folds=5)\n",
      "✅ PLSRegression_fold0 - test: mse=0.0112↓ (mae: 0.0856) (fold:0)\n",
      "✅ PLSRegression_fold1 - test: mse=0.0113↓ (mae: 0.0856) (fold:1)\n",
      "✅ PLSRegression_fold2 - test: mse=0.0157↓ (mae: 0.1020) (fold:2)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: UnknownModel_4_fold0 - mse=0.0112↓\n",
      "\u001b[94m✅ Pipeline config_95e3259a completed successfully on dataset regression\u001b[0m\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_76c9595c on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "🔄 TransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': [['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.SavitzkyGolay'], ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.Haar'], ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation\n",
      "\u001b[96m   ▶ Sub-step 2.1: ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.SavitzkyGolay']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.2: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "🔄 TransformerMixin (StandardScaler)\n",
      "\u001b[96m   ▶ Sub-step 2.3: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "🔄 TransformerMixin (SavitzkyGolay)\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['sklearn.preprocessing._data.StandardScaler', 'nirs4all.operators.transformations.nirs.Haar']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "🔄 TransformerMixin (StandardScaler)\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.Haar', 'sklearn.preprocessing._data.StandardScaler']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "\u001b[96m   ▶ Sub-step 2.2: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "🔄 TransformerMixin (StandardScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "🔄 YTransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (test: (59, 1)) (PLSRegression)\n",
      "[DEBUG] Model config: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}, 'model_instance': PLSRegression(n_components=10)}\n",
      "[DEBUG] CV config: CVConfig(mode=<CVMode.SIMPLE: 'simple'>, param_strategy=<ParamStrategy.PER_FOLD_BEST: 'per_fold_best'>, inner_cv=None, outer_cv=None, use_full_train_for_final=False, n_folds=5)\n",
      "✅ PLSRegression_fold0 - test: mse=0.0141↓ (mae: 0.0971) (fold:0)\n",
      "✅ PLSRegression_fold1 - test: mse=0.0150↓ (mae: 0.0990) (fold:1)\n",
      "✅ PLSRegression_fold2 - test: mse=0.0138↓ (mae: 0.0878) (fold:2)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: UnknownModel_11_fold2 - mse=0.0138↓\n",
      "\u001b[94m✅ Pipeline config_76c9595c completed successfully on dataset regression\u001b[0m\n",
      "✅ Loaded dataset 'regression' with 130 training and 59 test samples.\n",
      "========================================================================================================================================================================================================\n",
      "\u001b[94m🚀 Starting pipeline config_46b78da9 on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 1: {'class': 'sklearn.preprocessing._data.MinMaxScaler', '_runtime_instance': MinMaxScaler()}\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator MinMaxScaler\n",
      "🔄 TransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 2: {'feature_augmentation': ['sklearn.preprocessing._data.StandardScaler', ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Gaussian'], ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.nirs.SavitzkyGolay']]}\u001b[0m\n",
      "🔹 Executing controller FeatureAugmentationController without operator\n",
      "🔄 FeatureAugmentation\n",
      "\u001b[96m   ▶ Sub-step 2.1: sklearn.preprocessing._data.StandardScaler\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator StandardScaler\n",
      "🔄 TransformerMixin (StandardScaler)\n",
      "\u001b[96m   ▶ Sub-step 2.2: ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.signal.Gaussian']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.3: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "\u001b[96m   ▶ Sub-step 2.4: nirs4all.operators.transformations.signal.Gaussian\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Gaussian\n",
      "🔄 TransformerMixin (Gaussian)\n",
      "\u001b[96m   ▶ Sub-step 2.0: ['nirs4all.operators.transformations.nirs.Haar', 'nirs4all.operators.transformations.nirs.SavitzkyGolay']\u001b[0m\n",
      "\u001b[96m   ▶ Sub-step 2.1: nirs4all.operators.transformations.nirs.Haar\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator Haar\n",
      "🔄 TransformerMixin (Haar)\n",
      "\u001b[96m   ▶ Sub-step 2.2: nirs4all.operators.transformations.nirs.SavitzkyGolay\u001b[0m\n",
      "🔹 Executing controller TransformerMixinController with operator SavitzkyGolay\n",
      "🔄 TransformerMixin (SavitzkyGolay)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 3: {'class': 'sklearn.model_selection._split.ShuffleSplit', 'params': {'n_splits': 3, 'test_size': 0.25}, '_runtime_instance': ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)}\u001b[0m\n",
      "🔹 Executing controller CrossValidatorController with operator ShuffleSplit\n",
      "Generated 3 folds.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 4: {'y_processing': {'class': 'sklearn.preprocessing._data.MinMaxScaler'}}\u001b[0m\n",
      "🔹 Executing controller YTransformerMixinController with operator MinMaxScaler\n",
      "🔄 YTransformerMixin (MinMaxScaler)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[92m🔷 Step 5: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}}\u001b[0m\n",
      "🔹 Executing controller SklearnModelController with operator PLSRegression\n",
      "🔄 SklearnModel (test: (59, 1)) (PLSRegression)\n",
      "[DEBUG] Model config: {'model': {'class': 'sklearn.cross_decomposition._pls.PLSRegression', 'params': {'n_components': 10}, '_runtime_instance': PLSRegression(n_components=10)}, 'model_instance': PLSRegression(n_components=10)}\n",
      "[DEBUG] CV config: CVConfig(mode=<CVMode.SIMPLE: 'simple'>, param_strategy=<ParamStrategy.PER_FOLD_BEST: 'per_fold_best'>, inner_cv=None, outer_cv=None, use_full_train_for_final=False, n_folds=5)\n",
      "✅ PLSRegression_fold0 - test: mse=0.0129↓ (mae: 0.0923) (fold:0)\n",
      "✅ PLSRegression_fold1 - test: mse=0.0106↓ (mae: 0.0812) (fold:1)\n",
      "✅ PLSRegression_fold2 - test: mse=0.0120↓ (mae: 0.0913) (fold:2)\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best for config: UnknownModel_7_fold1 - mse=0.0106↓\n",
      "\u001b[94m✅ Pipeline config_46b78da9 completed successfully on dataset regression\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "🏆 Best from this run: UnknownModel_7_fold1 (46b78da9_UnknownModel_7) - mse=0.0106↓\n",
      "🥇 Best overall: UnknownModel_7_fold1 (46b78da9_UnknownModel_7) - mse=0.0106↓\n",
      "📊 Tab report saved: best_score_report_UnknownModel_fold1.csv\n",
      "|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|-----------------|\n",
      "|          | Nsample  | Nfeature | Mean     | Median   | Min      | Max      | SD       | CV       | R²       | RMSE     | MSE      | SEP      | MAE      | RPD      | Bias     | Q-Value  | Consistency (%) |\n",
      "|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|-----------------|\n",
      "| Cros Val |          | 2151     |          |          |          |          |          |          |          |          |          |          |          |          |          |          |                 |\n",
      "| Train    |          |          |          |          |          |          |          |          |          |          |          |          |          |          |          |          |                 |\n",
      "| Test     |          |          |          |          |          |          |          |          |          |          |          |          |          |          |          |          |                 |\n",
      "|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|-----------------|\n",
      "========================================================================================================================\n",
      "\n",
      "=== TRAINING METADATA CHECK ===\n",
      "Step binaries tracked: 5 steps\n",
      "Sample step binaries: {'1_0': ['1_0_MinMaxScaler_1.pkl'], '2_1': ['2_1_0_StandardScaler_2.pkl'], '3_0': ['3_folds_ShuffleSplit.csv']}\n",
      "\n",
      "=== TOP 5 RESULTS ===\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rmse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== TOP 5 RESULTS ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(top_5, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m✅\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mhas_metadata\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m❌\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== TESTING PREDICTION ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m best_path \u001b[38;5;241m=\u001b[39m top_5[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rmse'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from nirs4all.operators.transformations import Gaussian, SavitzkyGolay, StandardNormalVariate, Haar\n",
    "from nirs4all.pipeline.config import PipelineConfigs\n",
    "from nirs4all.dataset.dataset_config import DatasetConfigs\n",
    "from nirs4all.pipeline.runner import PipelineRunner\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from nirs4all.dataset.prediction_analyzer import PredictionAnalyzer\n",
    "# Clear old results to ensure fresh training with metadata\n",
    "results_path = Path(\"./results\")\n",
    "if results_path.exists():\n",
    "    shutil.rmtree(results_path)\n",
    "    print(\"🧹 Cleared old results to ensure fresh training\")\n",
    "\n",
    "pipeline = [\n",
    "    # Normalize the spectra reflectance\n",
    "    MinMaxScaler(),\n",
    "\n",
    "    # Generate 5 version of feature augmentation combinations (3 elements with size 1 to 2, ie. [SG, [SNV, GS], Haar])\n",
    "    {\n",
    "        \"feature_augmentation\": {\n",
    "            \"_or_\": [\n",
    "                Gaussian, StandardNormalVariate, SavitzkyGolay, Haar,\n",
    "            ],\n",
    "            \"size\": [3, (1,2)],\n",
    "            \"count\": 5,\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Split the dataset in train and validation\n",
    "    ShuffleSplit(n_splits=3, test_size=.25),\n",
    "\n",
    "    # Normalize the y values\n",
    "    {\"y_processing\": MinMaxScaler},\n",
    "    {\"model\": PLSRegression(10)},\n",
    "]\n",
    "\n",
    "p_configs = PipelineConfigs(pipeline)\n",
    "\n",
    "# path = ['../../sample_data/regression', '../../sample_data/classification', '../../sample_data/binary']\n",
    "path = '../../sample_data/regression'\n",
    "d_configs = DatasetConfigs(path)\n",
    "\n",
    "# Train with explicit settings to ensure metadata is saved\n",
    "runner = PipelineRunner(save_files=True, verbose=0)  # Set verbose=0 to reduce output\n",
    "predictions, results = runner.run(p_configs, d_configs)\n",
    "\n",
    "print(f\"\\n=== TRAINING METADATA CHECK ===\")\n",
    "print(f\"Step binaries tracked: {len(runner.step_binaries)} steps\")\n",
    "print(f\"Sample step binaries: {dict(list(runner.step_binaries.items())[:3])}\")\n",
    "\n",
    "visualizer = PredictionAnalyzer(predictions, dataset_name_override=\"dataset\")\n",
    "top_5 = visualizer.get_top_k(5, 'rmse') ##TODO get_top_1\n",
    "\n",
    "# print(f\"\\n=== TOP 5 RESULTS ===\")\n",
    "# for i, model in enumerate(top_5, 1):\n",
    "#     print(f\"{i}. {model['path']} - RMSE: {model['rmse']:.6f}, R²: {model['r2']:.6f}, MAE: {model['mae']:.6f} {'✅' if has_metadata else '❌'}\")\n",
    "\n",
    "print(f\"\\n=== TESTING PREDICTION ===\")\n",
    "best_path = top_5[0]['path']\n",
    "print(f\"Using best model from: {best_path}\")\n",
    "\n",
    "try:\n",
    "    predictions = PipelineRunner.predict(\n",
    "        path=best_path,\n",
    "        dataset=d_configs,\n",
    "        # model=my_model,##TODO\n",
    "        best_model=False,##TODO quand on veut prédire sur tous les modèles\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"✅ Prediction successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Prediction failed: {e}\")\n",
    "    # Show which step failed\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f00386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 5 RESULTS ===\n",
      "1. results\\regression\\config_533c9c31 - RMSE: 15.027338, R²: 0.505548, MAE: 12.599274 ✅\n",
      "2. results\\regression\\config_d69b2949 - RMSE: 15.226635, R²: 0.467121, MAE: 11.715890 ✅\n",
      "3. results\\regression\\config_d69b2949 - RMSE: 15.237708, R²: 0.710659, MAE: 12.448704 ✅\n",
      "4. results\\regression\\config_a08494a0 - RMSE: 15.391987, R²: -0.246827, MAE: 12.506934 ✅\n",
      "5. results\\regression\\config_a08494a0 - RMSE: 16.420442, R²: 0.277163, MAE: 13.758281 ✅\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n=== TOP 5 RESULTS ===\")\n",
    "for i, model in enumerate(top_5, 1):\n",
    "    print(f\"{i}. {model['path']} - RMSE: {model['rmse']:.6f}, R²: {model['r2']:.6f}, MAE: {model['mae']:.6f} {'✅' if has_metadata else '❌'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
