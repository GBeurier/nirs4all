*[train / finetune]
*[save]
print result,
save tf in tf format
store predictions and display prediction summaries
[predict / load]
[verify binary and classification]
Manage save for dataset and globally
[generator]
[bin with bounds or count + warning class assymetry]
[CLI]
[augmentation]

#### BUGS in SPECS

- branching in index does not allow different features size in feature sources (ie different samples with different feature size)

- Split operators:
  - If solo split (test set) > warning if test exists > val
  - Fold + Split - operator
- Balanced augmentation (groups)
- Model sklearn: train, finetune, predict
- Model tf: train, finetune, predict
- Model torch: train, finetune, predict
- metadata and update of group fold with meta fold, and balanced meta augmentation
- Sauvegarde:
   - results
   - params
   - binaries and pipeline
- Prediction
- Transfert
- Branch, Scope, filter controller
- Merge / Split source
- Save controller
- Generator
- Test
- ClusterMixin controller
- shap controller + Shap visualization
- CLI
- dataviz controller



- tutorial:
dataset
config

all types of processings,
folding
charts
model
train / finetune
predict
generator
save
custom controller
custom operator
custom models



##################
ARCHIVES
##################



# Verifier test_dataset_loader avec NA en Y

############### CLARIFIER VAL / TEST et warning m√©chant quand le test est utilis√© en VAL .

Use case 1: Denis: generator >> PENTESTER
Use case 2: user lambda - train et voir le meilleur > barplot par dataset et modele, residu par experiment > output graphique sur les scenario >> NOOB USER
- split robustess.
Use case 3: Jeux de donn√©es r√©fractaires. Bruits / classification >> DEV INTENSIVE

- Export experiment to do predict(export, dataset)

- GroupBy / Filter  step >
- y, x sanity_check step
- dataviz step

- virer les extremum pour la robustesse (encore un split ou groupby/filter)

- header / Verifier syntax avec folder loading.

Xn Ym Metak
***

jit > multiple outputs with 1 model per output.
- multiplexer model > Multiple source le modele s'adapte
 >>>>> genre 500 wl ou 2500wl > small-nicon, nicon


--- FUSION - multi sources ou separated source in multi source . Options:
- multiple source or source separation
- pre pipeline fusion | None
- -- | multiple pipeline || single pipeline
- -- | post pipeline fusion || multi model || single model with early / mid / late fusion
- -- | -------------------- || stack, weight, best || ---

# In progress


Config serialization:

Each part of the config is serializable. Config can be obj, class, method, dict or str usually.



---------------------------------------------------------------------------------

# NIRS4ALL - Project TODO & Roadmap

This document organizes and details the main features, improvements, and priorities for the nirs4all library. Each item is tagged with its **Importance** (‚≠êÔ∏è = critical, üî∂ = important, üîπ = nice-to-have).


---

## 1. Command-Line Executable (`nirs4all` CLI) ‚≠êÔ∏è

- **Goal:** Make nirs4all usable from the command line for training, prediction, and evaluation.
- **Tasks:**
  - [ ] Create a CLI entry point (`nirs4all`).
  - [ ] Support commands: `train`, `predict`, `finetune`, and other new commands to appear
  - [ ] Allow passing config files, model presets, and data paths as arguments.
  - [ ] Provide help and usage documentation.
  - [ ] Add CLI tests and examples.

---

## 2. Easy Prediction on New Data ‚≠êÔ∏è

- **Goal:** Allow users to run predictions on new datasets (folders or files) with a single command or function call.
- **Tasks:**
  - [ ] Implement a `predict` CLI and Python API that:
    - Loads a trained model and its pipeline. (either the hascode, the path or the config)
    - Applies all necessary preprocessing/transformations to a dataset to predict.
    - Handles various input formats (CSV, folder, etc.).
    - Outputs predictions in a user-friendly format (CSV, JSON, etc.).
  - [ ] Document the prediction workflow for end-users.

---

## 3. Config Presets & Command-Line Options ‚≠êÔ∏è

- **Goal:** Provide ready-to-use configuration presets for common tasks and models.
- **Tasks:**
  - [ ] Define a library of config presets (YAML/JSON/Python) for:
    - Regression/classification/binary tasks.
    - Popular models (PLS, RF, NICON, etc.).
    - Typical pipelines (scaling, SNV, SG, etc.).
  - [ ] Allow CLI/API to select and override presets.
  - [ ] Document available presets and how to customize them.

---

## 4. PyTorch Integration üî∂

- **Goal:** Support PyTorch models in the same way as scikit-learn and TensorFlow.
- **Tasks:**
  - [ ] Finalize PyTorch model builder and manager.
  - [ ] Ensure pipelines, training, prediction, and finetuning work for PyTorch.
  - [ ] Add tests and examples for PyTorch models.
  - [ ] Document PyTorch integration and usage.

---

## 5. Stacking & Model Ensembling üî∂

- **Goal:** Enable stacking/ensembling of multiple models (meta-models trained on predictions of base models).
- **Tasks:**
  - [ ] Implement stacking pipeline (scikit-learn style, but compatible with nirs4all configs).
  - [ ] Allow stacking of heterogeneous models (sklearn, TF, PyTorch).
  - [ ] Support cross-validation and meta-model training.
  - [ ] Add config options and CLI support for stacking.
  - [ ] Provide examples and documentation.

---

## 6. Results Browser & Visualization üî∂

- **Goal:** Provide tools to browse, compare, and visualize experiment results.
- **Tasks:**
  - [ ] Develop a results browser (CLI, notebook, or web-based).
  - [ ] Visualize metrics, predictions, confusion matrices, feature importances, etc.
  - [ ] Allow filtering/sorting by dataset, model, metric, etc.
  - [ ] Export visualizations and reports.
  - [ ] Integrate with experiment folders and centralized results.

---

## 7. Data Visualization (Dataviz) for Results & Data üî∂

- **Goal:** Offer advanced visualization for datasets and model outputs.
- **Tasks:**
  - [ ] Plot spectra, mean/variance, class distributions, correlations, etc.
  - [ ] Visualize transformation effects (before/after).
  - [ ] Show prediction vs. actual, residuals, feature importances.
  - [ ] Integrate with results browser and CLI.

---

## 8. Group Management (Loading & Splitting) üî∂

- **Goal:** Support group columns for stratified/grouped splitting and analysis.
- **Tasks:**
  - [ ] Enhance data loader to recognize and load group columns.
  - [ ] Allow group-based splitting in pipelines and splitters.
  - [ ] Document group usage and best practices.

---

## 9. Config Generator (Combinatorial Experiment Generator) üî∂

- **Goal:** Automatically generate combinations of models, preprocessings, and parameters for large-scale experiments.
- **Tasks:**
  - [ ] Implement a config generator (Python API and CLI).
  - [ ] Allow grid/random search over models, pipelines, and hyperparameters.
  - [ ] Integrate with experiment runner and results browser.
  - [ ] Document usage and provide templates.

---

## 10. Parametric Augmentation (Advanced Data Augmentation) üîπ

- **Goal:** Support parametric and customizable data augmentation strategies.
- **Tasks:**
  - [ ] Implement parametric augmentation operators (e.g., noise, warping, mixup).
  - [ ] Allow augmentation parameters to be tuned or randomized.
  - [ ] Integrate with pipelines and config generator.
  - [ ] Document available augmentations and usage.

---

## 11. Enhanced Data Loading & CSV Loader üî∂

- **Goal:** Robustly support all common data formats and flexible CSV parsing.
- **Tasks:**
  - [ ] Support CSV, TSV, Excel, NPY, and other formats.
  - [ ] Enhance CSV loader for:
    - Flexible header/column detection.
    - Multiple delimiters and decimal separators.
    - NA/missing value handling.
    - Group/label column detection.
  - [ ] Add tests for edge cases and large files.
  - [ ] Document data loading options.

---

## 12. Multiple File Sources & Data Fusion üîπ

- **Goal:** Allow loading and combining data from multiple files/sources (concatenation, fusion, or multi-layer).
- **Tasks:**
  - [ ] Support loading multiple files as separate layers or concatenated features.
  - [ ] Allow fusion strategies (early, late, hierarchical).
  - [ ] Document use cases and provide examples.

---

## 13. General Improvements & Maintenance

- [ ] Refactor code for clarity, modularity, and testability.
- [ ] Improve error messages and user feedback.
- [ ] Expand and improve documentation and tutorials.
- [ ] Add more unit and integration tests.
- [ ] Ensure compatibility with latest versions of dependencies.

---

## 14. Future Ideas (Exploratory) üîπ

- [ ] Web-based GUI for experiment setup and results browsing.
- [ ] AutoML integration for automated model and pipeline search.
- [ ] Cloud deployment and distributed training support.
- [ ] Integration with external data sources (databases, APIs).

---

## 15. Conda & Docker install

- **Goal:** Make nirs4all available on conda and docker.
- **Tasks:** to be defined


---

# Legend

- ‚≠êÔ∏è **Critical**: Must-have for usability and core workflow.
- üî∂ **Important**: Major features for advanced users and workflows.
- üîπ **Nice-to-have**: Useful enhancements, not blocking for main usage.

---

**Contributions and suggestions are welcome! Please open issues or pull requests for discussion.**